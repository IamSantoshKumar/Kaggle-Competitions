{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import albumentations as aug\n",
    "import efficientnet_pytorch\n",
    "import random\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torch.cuda import amp\n",
    "import pretrainedmodels\n",
    "from sklearn.metrics import accuracy_score\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import timm\n",
    "\n",
    "import hashlib\n",
    "import joblib\n",
    "import Cassava\n",
    "import Tracker\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "TRAIN_FILE = 'D:\\\\Dataset\\\\Cassava Competiton\\\\train.csv'\n",
    "TEST_FILE = 'D:\\\\Dataset\\\\Cassava Competiton\\\\test_images\\\\'\n",
    "\n",
    "HOME_PATH = 'D:\\\\cassava_competition'\n",
    "\n",
    "IMAGE_SIZE_AUG = 128\n",
    "\n",
    "p=0.5\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger_init(path):\n",
    "    from importlib import reload  # Not needed in Python 2\n",
    "    reload(logging)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s,%(name)s,%(message)s')\n",
    "\n",
    "    file_handler = logging.FileHandler(path, mode='w')\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    file_handler.setFormatter(formatter)\n",
    " \n",
    "    logger.addHandler(file_handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger_init_all(path):\n",
    "        reload(logging)\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.setLevel(logging.INFO)\n",
    "\n",
    "        formatter = logging.Formatter('%(asctime)s,%(name)s,%(message)s')\n",
    "\n",
    "        file_handler = logging.FileHandler(path, mode='a')\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_handler.setFormatter(formatter)\n",
    " \n",
    "        logger.addHandler(file_handler)\n",
    "        return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = aug.Compose(\n",
    "        [     \n",
    "        aug.RandomResizedCrop(IMAGE_SIZE_AUG, IMAGE_SIZE_AUG),\n",
    "        aug.Transpose(p=p),\n",
    "        aug.HorizontalFlip(p=p),\n",
    "        aug.VerticalFlip(p=p),\n",
    "        aug.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, brightness_by_max=True, always_apply=True, p=1),\n",
    "        aug.ShiftScaleRotate(p=p),\n",
    "        aug.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),  \n",
    "        ]\n",
    "    )\n",
    "\n",
    "valid_aug = aug.Compose(\n",
    "       [    \n",
    "        aug.CenterCrop(IMAGE_SIZE_AUG, IMAGE_SIZE_AUG, p=1.0),\n",
    "        aug.Resize(IMAGE_SIZE_AUG, IMAGE_SIZE_AUG),\n",
    "        aug.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),  \n",
    "       ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameter = {\n",
    "    \n",
    "    'EPOCHS' : 20,\n",
    "    'BATCH_SIZE' : 16,\n",
    "    'LEARNING_RATE' : 1e-3,\n",
    "    'WEIGHT_DECAY' : 1e-5,\n",
    "    'NFOLDS' : 5,\n",
    "    'EARLY_STOPPING_STEPS': 5,\n",
    "    'EARLY_STOP' : False,\n",
    "    'IMAGE_SIZE' : IMAGE_SIZE_AUG,\n",
    "    'ACCU_STEPS' : 1,\n",
    "    'train_aug' : train_aug,\n",
    "    'valid_aug' : valid_aug,\n",
    "    'SMOOTHING' : 0.05\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_FILE)\n",
    "test_images = [i for i in glob.glob(f'{TEST_FILE}\\*')]\n",
    "test_images_sub = [os.path.basename(i) for i in glob.glob(f'{TEST_FILE}\\*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_path='D:\\\\Dataset\\\\Cassava Competiton\\\\'\n",
    "    train_df[\"fold\"] = -1\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    y = train_df.label.values\n",
    "    skf = model_selection.StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "    for fold,(idxT,idxV) in enumerate(skf.split(X=train_df, y=y)):\n",
    "        train_df.loc[idxV, \"fold\"] = fold\n",
    "    train_df.to_csv(os.path.join(input_path, \"train_folds.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.features = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b4')\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(1792, 5)\n",
    "             \n",
    "    def forward(self, image, targets=None):    \n",
    "        batch_size, _, _, _ = image.shape\n",
    "        x = self.features.extract_features(image)   \n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
    "        x_ = self.out(self.dropout(x))\n",
    "        \n",
    "        return x_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEResNext50_32x4d(nn.Module):\n",
    "    def __init__(self, pretrained=\"imagenet\"):\n",
    "        super(SEResNext50_32x4d, self).__init__()\n",
    "        self.model = pretrainedmodels.__dict__[\n",
    "            \"se_resnext50_32x4d\"\n",
    "        ](pretrained=pretrained)\n",
    "\n",
    "        self.out = nn.Linear(2048, 5)\n",
    "    \n",
    "    def forward(self, image, targets=None):\n",
    "        bs, _, _, _ = image.shape\n",
    "        x = self.model.features(image)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = x.reshape(bs, -1)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class densenet121(nn.Module):\n",
    "    def __init__(self, pretrained=\"imagenet\"):\n",
    "        super(densenet121, self).__init__()\n",
    "        self.model = pretrainedmodels.__dict__[\n",
    "            \"densenet121\"\n",
    "        ](pretrained=pretrained)\n",
    "\n",
    "        self.out = nn.Linear(1024, 5)\n",
    "    \n",
    "    def forward(self, image, targets=None):\n",
    "        bs, _, _, _ = image.shape\n",
    "        x = self.model.features(image)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = x.reshape(bs, -1)\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        self.base_model = timm.create_model(f\"tf_efficientnet_b4_ns\", pretrained=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.out = nn.Linear(\n",
    "            in_features=1792, \n",
    "            out_features=5, \n",
    "            bias=True\n",
    "        )\n",
    "        \n",
    "    def forward(self, image, targets=None):\n",
    "        batch_size, _, _, _ = image.shape\n",
    "        \n",
    "        x = self.base_model.forward_features(image) \n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
    "        out = self.out(self.dropout(x))  \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_combination(x, y, epsilon): \n",
    "    return epsilon*x + (1-epsilon)*y\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon:float=0.01, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, preds, target):\n",
    "        n = preds.size()[-1]\n",
    "        log_preds = F.log_softmax(preds, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return linear_combination(loss/n, nll, self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=hyper_parameter['SMOOTHING']):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth_one_hot(targets:torch.Tensor, n_classes:int, smoothing=hyper_parameter['SMOOTHING']):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = torch.empty(size=(targets.size(0), n_classes),\n",
    "                    device=targets.device) \\\n",
    "                .fill_(smoothing /(n_classes-1)) \\\n",
    "                .scatter_(1, targets.data.unsqueeze(1), 1.-smoothing)\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss._smooth_one_hot(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device, accumulation_steps=1):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    scaler = amp.GradScaler()\n",
    "    tk0 = tqdm(dataloader, total = len(dataloader))           \n",
    "    for b_idx, data in enumerate(tk0):\n",
    "        if accumulation_steps > 1:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        inputs, targets = data['image'].to(device), data['targets'].to(device)\n",
    "        with amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "        if accumulation_steps ==1 and b_idx==0:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        with torch.set_grad_enabled(True):\n",
    "            scaler.scale(loss).backward()\n",
    "            if (b_idx + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                if b_idx > 0:\n",
    "                    optimizer.zero_grad()\n",
    "        losses.update(loss.item(), dataloader.batch_size)\n",
    "        tk0.set_postfix(loss=losses.avg)\n",
    "    tk0.close()\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    valid_preds = []\n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(dataloader, total = len(dataloader))           \n",
    "        for b_idx, data in enumerate(tk0):     \n",
    "            inputs, targets = data['image'].to(device), data['targets'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "            losses.update(loss.item(), dataloader.batch_size)\n",
    "            tk0.set_postfix(loss=losses.avg)\n",
    "        valid_preds = np.concatenate(valid_preds)\n",
    "        tk0.close()\n",
    "    return losses.avg, valid_preds\n",
    "\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = [] \n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(dataloader, total=len(dataloader))\n",
    "        for data in tk0:\n",
    "            inputs = data['image'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    training_data_path = 'D:\\\\Dataset\\\\Cassava Competiton\\\\train_images\\\\'\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    resize = (hyper_parameter['IMAGE_SIZE'],hyper_parameter['IMAGE_SIZE'])\n",
    "\n",
    "    train = pd.read_csv(input_path+'train_folds.csv')\n",
    "                  \n",
    "    trn_idx = train[train['fold'] != fold].index\n",
    "    val_idx = train[train['fold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['fold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_images = train_df.image_id.values.tolist()\n",
    "    train_images = [os.path.join(training_data_path, i) for i in train_images]\n",
    "    train_targets = train_df.label.values\n",
    "\n",
    "    valid_images = valid_df.image_id.values.tolist()\n",
    "    valid_images = [os.path.join(training_data_path, i) for i in valid_images]\n",
    "    valid_targets = valid_df.label.values               \n",
    "        \n",
    "    train_dataset = Cassava.Cassava_Train_DS(train_images, train_targets, resize = resize, augmentations = train_aug)\n",
    "    valid_dataset = Cassava.Cassava_Train_DS(valid_images, valid_targets, resize = resize, augmentations = valid_aug)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=hyper_parameter['BATCH_SIZE'], shuffle=True, num_workers=4)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=hyper_parameter['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
    "        \n",
    "    model = EfficientNet()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hyper_parameter['LEARNING_RATE'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
    "    )\n",
    "    #loss_tr_fn = SmoothCrossEntropyLoss()\n",
    "    loss_fn = SmoothCrossEntropyLoss()\n",
    "    \n",
    "    early_stopping_steps = hyper_parameter['EARLY_STOPPING_STEPS']\n",
    "    early_step = 0\n",
    "   \n",
    "    oof = np.zeros((len(train), 5))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(hyper_parameter['EPOCHS']):\n",
    "                \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE, accumulation_steps=hyper_parameter['ACCU_STEPS'])\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")        \n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        score = accuracy_score(valid_targets, valid_preds.argmax(1))\n",
    "        print(f\"fold: {fold} Accuracy: {score}\")\n",
    "                \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"{HOME_PATH}\\\\{cassava_init.exper_dict}\\\\artefacts\\\\model\\\\{fold}_{seed}.pth\")\n",
    "        \n",
    "        elif(hyper_parameter['EARLY_STOP'] == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "                \n",
    "        logger.info(f\"{cassava_init.exper_dict}{fold},{epoch},{train_loss},{valid_loss},{best_loss},{score},{hyper_parameter['EPOCHS']},{hyper_parameter['BATCH_SIZE']},{hyper_parameter['LEARNING_RATE']},{hyper_parameter['WEIGHT_DECAY']},{hyper_parameter['NFOLDS']},{hyper_parameter['EARLY_STOPPING_STEPS']},{hyper_parameter['EARLY_STOP']}, {hyper_parameter['IMAGE_SIZE']},{hyper_parameter['ACCU_STEPS']}\")\n",
    "        logger_all.info(f\"{cassava_init.exper_dict},{fold},{epoch},{train_loss},{valid_loss},{best_loss},{score},{hyper_parameter['EPOCHS']},{hyper_parameter['BATCH_SIZE']},{hyper_parameter['LEARNING_RATE']},{hyper_parameter['WEIGHT_DECAY']},{hyper_parameter['NFOLDS']},{hyper_parameter['EARLY_STOPPING_STEPS']},{hyper_parameter['EARLY_STOP']}, {hyper_parameter['IMAGE_SIZE']},{hyper_parameter['ACCU_STEPS']}\")\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    testdataset = Cassava.Cassava_Test_DS(test_images, resize = resize , augmentations = train_aug)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=hyper_parameter['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = EfficientNet()\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"{HOME_PATH}\\\\{cassava_init.exper_dict}\\\\artefacts\\\\model\\\\{fold}_{seed}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_images), 5))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train_df), 5))\n",
    "    predictions = np.zeros((len(test_images), 5))\n",
    "        \n",
    "    for fold in range(hyper_parameter['NFOLDS']):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / hyper_parameter['NFOLDS']\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████▌     | 983/1070 [07:57<01:11,  1.21it/s, loss=0.994]"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "SEED = [42,] #<-- Update\n",
    "oof = np.zeros((len(train_df), 5))\n",
    "predictions = np.zeros((len(test_images), 5))\n",
    "\n",
    "logging.shutdown()\n",
    "cassava_init = Tracker.Init(hyper_parameter, project_name='cassava_competition', parent_dir='D:\\\\' , is_sub=True, sub_directory=['model','config','logger'])\n",
    "logger = logger_init(cassava_init.path+'\\\\logger\\\\logging.log')\n",
    "logger_all = logger_init_all(os.path.join(cassava_init.parent_dir, cassava_init.project_name)+'\\\\logging.log')\n",
    "\n",
    "logger.info('experiment,fold,epoch,train_loss,valid_loss,best_loss,accuracy,epochs,batch_size,learning_rate,weight_decay,nfolds,early_stopping_steps,early_stop,image_size,accu_steps')\n",
    "    \n",
    "if os.path.getsize('D:\\\\cassava_competition\\\\logging.log')==0:\n",
    "    logger_all.info('experiment,fold,epoch,train_loss,valid_loss,best_loss,accuracy,epochs,batch_size,learning_rate,weight_decay,nfolds,early_stopping_steps,early_stop,image_size,accu_steps')\n",
    "\n",
    "##for seed in SEED:\n",
    "    \n",
    "oof_, predictions_ = run_training(0, 42)\n",
    "#oof += oof_ / len(SEED)\n",
    "#predictions += predictions_ / len(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
