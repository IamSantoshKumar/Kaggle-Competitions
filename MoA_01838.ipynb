{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from joblib import dump, load\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\train_features.csv')\n",
    "train_targets_scored = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\test_features.csv')\n",
    "sample_submission = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "transformer.fit(train_features.loc[:, GENES + CELLS])\n",
    "train_features[GENES + CELLS] = transformer.transform(train_features.loc[:, GENES + CELLS])\n",
    "\n",
    "dump(transformer, 'rank_1838_5fold_sub.bin', compress=True)\n",
    "\n",
    "\n",
    "test_features[GENES + CELLS] = transformer.transform(test_features.loc[:, GENES + CELLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 600  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "pca_genes = PCA(n_components=n_comp, random_state=42)\n",
    "data2 = pca_genes.fit_transform(data[GENES])\n",
    "\n",
    "dump(pca_genes, '1838_5fold_genes_sub.bin', compress=True)\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "pca_cells = PCA(n_components=n_comp, random_state=42)\n",
    "data2 = pca_cells.fit_transform(data[CELLS])\n",
    "\n",
    "dump(pca_cells, '1838_5fold_cells_sub.bin', compress=True)\n",
    "\n",
    "\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1040)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "var_thresh = VarianceThreshold(0.8)  #<-- Update\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "dump(var_thresh, 'var_1838_5fold_sub.bin', compress=True)\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "drug = pd.read_csv('D://Dataset//MOA//train_drug.csv')\n",
    "\n",
    "#train = train.merge(drug, on='sig_id')\n",
    "\n",
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train.merge(drug, on='sig_id')\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_folds(num_starts, num_splits, trn):\n",
    "\n",
    "    folds = []\n",
    "    scored = trn.copy()\n",
    "    #targets_ = scored.loc[:, train_targets_scored.columns].columns[1:].tolist()\n",
    "    #train_cols = train_features.columns.tolist() + ['fold','drug_id']\n",
    "    #train_cols = [col for col in train_cols if col!='cp_type']\n",
    "    # LOCATE DRUGS\n",
    "    vc = scored.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc <= 18].index.sort_values()\n",
    "    vc2 = vc.loc[vc > 18].index.sort_values()\n",
    "    \n",
    "    for seed in range(num_starts):\n",
    "    \n",
    "        # STRATIFY DRUGS 18X OR LESS\n",
    "        dct1 = {}; dct2 = {}\n",
    "        skf = KFold(n_splits = num_splits, shuffle = True, random_state = seed)\n",
    "        tmp = scored.groupby('drug_id')[target_cols].mean().loc[vc1]\n",
    "        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "            dd = {k:fold for k in tmp.index[idxV].values}\n",
    "            dct1.update(dd)\n",
    "    \n",
    "        # STRATIFY DRUGS MORE THAN 18X\n",
    "        skf = KFold(n_splits = num_splits, shuffle = True, random_state = seed)\n",
    "        tmp = scored.loc[scored.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "            dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "            dct2.update(dd)\n",
    "    \n",
    "        # ASSIGN FOLDS\n",
    "        scored['fold'] = scored.drug_id.map(dct1)\n",
    "        scored.loc[scored.fold.isna(),'fold'] =\\\n",
    "            scored.loc[scored.fold.isna(),'sig_id'].map(dct2)\n",
    "        scored.fold = scored.fold.astype('int8')\n",
    "        folds.append(scored.fold.values)\n",
    "        #train_cols = train_feats.columns.tolist() + ['fold','drug_id']\n",
    "        #train_feats_main = train_feats_.merge(scored, on='sig_id', how='left')\n",
    "        #train_feats_main['fold'] = train_feats_main['fold'].astype(int)\n",
    "        \n",
    "    return scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds= create_folds(1, 5, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>drug_id</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>-1.364787</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b68db1d53</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>df89a8e5a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18bb41b2c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>-2.288417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8c7f86626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>-0.375501</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7cbed3131</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.237856</td>\n",
       "      <td>-1.228203</td>\n",
       "      <td>0.218376</td>\n",
       "      <td>-0.365976</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>-0.150978</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6c3a459be</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>0.735603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>df1d0a5a1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>-0.304313</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ecf3b6b74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8b87a7a83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>-1.622462</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>972f41291</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 1247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  1.134849  0.907687 -0.416385 -0.966814   \n",
       "1      id_000779bfc      72      D1  0.119282  0.681738  0.272399  0.080113   \n",
       "2      id_000a6266a      48      D1  0.779973  0.946463  1.425350 -0.132928   \n",
       "3      id_0015fd391      48      D1 -0.734910 -0.274641 -0.438509  0.759097   \n",
       "4      id_001626bd3      72      D2 -0.452718 -0.477513  0.972316  0.970731   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1  0.237856 -1.228203  0.218376 -0.365976   \n",
       "21944  id_fffb1ceed      24      D2  0.209361 -0.022389 -0.235888 -0.796989   \n",
       "21945  id_fffb70c0c      24      D2 -1.911021  0.587228 -0.588417  1.296405   \n",
       "21946  id_fffcb9e7c      24      D1  0.816407  0.417618  0.431631  0.300617   \n",
       "21947  id_ffffdd77b      72      D1 -1.243096  1.567730 -0.269573  1.083636   \n",
       "\n",
       "              4         5         6  ...  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0     -0.254723 -1.017473 -1.364787  ...                0                  0   \n",
       "1      1.205169  0.686517  0.313396  ...                0                  0   \n",
       "2     -0.006122  1.492493  0.235577  ...                0                  0   \n",
       "3      2.346330 -0.858153 -2.288417  ...                0                  0   \n",
       "4      1.463427 -0.869555 -0.375501  ...                0                  0   \n",
       "...         ...       ...       ...  ...              ...                ...   \n",
       "21943 -0.330177  0.569243 -0.150978  ...                0                  0   \n",
       "21944 -0.674009  0.919312  0.735603  ...                0                  0   \n",
       "21945 -1.002640  0.850589 -0.304313  ...                0                  0   \n",
       "21946  1.070346 -0.024189  0.048942  ...                0                  0   \n",
       "21947 -0.511235 -2.099634 -1.622462  ...                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "21943                          0                                      0   \n",
       "21944                          0                                      0   \n",
       "21945                          0                                      0   \n",
       "21946                          0                                      0   \n",
       "21947                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0                    0          0                           0              0   \n",
       "1                    0          0                           0              0   \n",
       "2                    0          0                           0              0   \n",
       "3                    0          0                           0              0   \n",
       "4                    0          0                           0              0   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943                0          0                           0              0   \n",
       "21944                0          0                           0              0   \n",
       "21945                0          0                           0              0   \n",
       "21946                0          0                           0              0   \n",
       "21947                0          0                           0              0   \n",
       "\n",
       "         drug_id  fold  \n",
       "0      b68db1d53     4  \n",
       "1      df89a8e5a     1  \n",
       "2      18bb41b2c     0  \n",
       "3      8c7f86626     1  \n",
       "4      7cbed3131     3  \n",
       "...          ...   ...  \n",
       "21943  6c3a459be     2  \n",
       "21944  df1d0a5a1     4  \n",
       "21945  ecf3b6b74     0  \n",
       "21946  8b87a7a83     0  \n",
       "21947  972f41291     3  \n",
       "\n",
       "[21948 rows x 1247 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1246)\n",
      "(21948, 1247)\n",
      "(3624, 1039)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.5, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.register_buffer('noise', torch.tensor(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.expand(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit, logit\n",
    "\n",
    "y = train_targets_scored.iloc[:, 1:].values.astype('float32')\n",
    "output_bias = torch.from_numpy(logit(y.mean(0))).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.Linear(num_features, hidden_size)\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.2619422201258426)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.2619422201258426)\n",
    "        self.dense3 = nn.Linear(hidden_size, num_targets)\n",
    "        self.gaussian = GaussianNoise()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        x = self.gaussian(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x) \n",
    "        #print(output_bias)\n",
    "        return x\n",
    "    \n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['fold','sig_id','drug_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1838_5fold_feature_cols_sub.bin']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(target_cols, '1838_5fold_target_cols_sub.bin')\n",
    "dump(feature_cols, '1838_5fold_feature_cols_sub.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = load('1838_7fold_feature_cols.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5           \n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['fold'] != fold].index\n",
    "    val_idx = train[train['fold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['fold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "   \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"D:\\\\MOA_Pretrained_Models\\\\1835_moa_submission\\\\FOLD{fold}_{seed}.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"D:\\\\MOA_Pretrained_Models\\\\1835_moa_submission\\\\FOLD{fold}_{seed}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), len(target_cols)))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.6766013688799264\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.3061637920992715\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.05545177756120329\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.021790798061660357\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023691343548505203\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.020642712605851037\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.02278568135385496\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.021501189470291136\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.021670935162599537\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01925069040485791\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.02017013229213763\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018957637277032646\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.019615344716694908\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.018628311183835778\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.019924251173717388\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.019174408433692797\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.019670880764074947\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018842984523091997\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.019349242101652897\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.018814460294587273\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.019406863839190075\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.018792470305093695\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.019424177962692753\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.018754145662699426\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.019454907382959904\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018898320703634192\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.019538048654794693\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.018933118533875262\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.019648018671010715\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01906900086573192\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019640236202141514\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.019103028465594564\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01960009985697874\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.019044865587992326\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01972763222115843\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01910345434610333\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.019710955547465794\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01899489848209279\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.019706709310412407\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.019081569569451468\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.019779773752974426\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018904490768909453\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.019651951659740746\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.01905053673045976\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01970160139751607\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01906158019389425\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.019747774805063786\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.019199432751962116\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.01970418846315664\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01892385948449373\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.01973489357455485\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.019404550375682967\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.019624332020032234\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.019446455341364657\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.01957740048891392\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01876311307506902\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.01939007390182519\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.019020326808094977\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.019335891525058643\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018793536962143014\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.019296879853135433\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.018767997941800525\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.019057934266933495\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.018696085949029242\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.01896205463487169\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.01869216710329056\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.01881529968501865\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.01875223094331367\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.01857206778789776\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.018423805332609584\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.0183533299781814\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.018610746972262858\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.01812828893003904\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.01837845053523779\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.01784106647676748\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.01845155738826309\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.017447867491484984\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.018692087621561118\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.017050393634354292\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.018624669340040003\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.016477516636360382\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.01853068172931671\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.015943112371462412\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.01851975154131651\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.015329699376193077\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.018689609452017714\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.014604801494304253\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.01873053051531315\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.013837168155157047\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.018793832936457224\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.01315511973655742\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.01883724451597248\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.012576524512437374\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.018901010363229682\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.012197594273079565\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.018940723580973488\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.01199513019831932\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.018932787728096756\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.011895779972437067\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.01894574984908104\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6779936506365337\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.3132939466408321\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.05518505737239862\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020579827364001956\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.023778828459173222\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.020162539716277805\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.023147442248942208\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.018546519268836294\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02132618977912586\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.0184674755270992\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.020061972163563226\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.018892369738646917\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.019920211829190706\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.0188299936907632\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.0198304892864323\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01838216254753726\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.019489067762981364\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01856956593692303\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.019380081621726063\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.018752695513623102\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01945519804900145\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.018453736550041608\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.019458863571503737\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018635798884289605\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.019600454677086678\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.018560207688382693\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.0196395106613636\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01868359286870275\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019665758254645515\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.018461141868361404\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019802183579028087\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018350005415933474\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.019723275961884616\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.018405544757843017\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01978134832949969\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.018441812108669964\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.019795852951216\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.018752025493553707\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01981065407340979\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.018543919335518563\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.019934870696959706\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.018386542105248996\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.019802159242277597\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01861949461911406\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.019786672979375742\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01864421788070883\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01984938900292355\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018532360345125197\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.019812819092486895\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.0185156023395913\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.019784775039140324\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.018693389424255916\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.0197675219553448\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.018604568392038345\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.01970762207451528\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.01854430852191789\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.01952524988973228\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01862153293831008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 29, train_loss: 0.019463858043734173\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.018327917131994453\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.019363344041970525\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.018260551722986358\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.019218356736058737\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.01851314173213073\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.019076334013447275\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018375047083411897\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.01880918999277327\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.018520838208496572\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.018643408979758296\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.01841570373092379\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.018465572138772392\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.018434720113873482\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.0180838421585351\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.018317454361489842\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.017789483627807485\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.018435605402503694\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.017438489821379202\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.018361234558480127\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.016932077318375562\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.018594124168157578\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.016532221326373355\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.018469433965427533\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.01591192552289606\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.01864807344973087\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.01528053974093747\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.018648850119539668\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.01454591014198143\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.018627291545271873\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.013792756571006166\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.0188019866922072\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.013202307888571798\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.01874992230108806\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.012624435786185039\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.018878610698240143\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.012254403910878366\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.0188929019761937\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.012051945157947332\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.01892520481986659\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.01195194043327857\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.01894744469651154\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6770551997250405\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.31075765575681413\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.054388795412429004\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.01993606122476714\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023702447896526344\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019305769513760295\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.02444627333054508\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.30704470010740414\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.023925506577327633\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018658635765314104\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.0214825096823599\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.018275789703641618\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.020985263318795223\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018416447698005607\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020708415751763874\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018183844217232296\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020367048491818317\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01803085117467812\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.02027035815020402\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.018278551953179494\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.020147776865548847\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.018203986196645667\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.020140006800816544\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018022871177111353\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.020081422251203785\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018026858594800743\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.020052127027209255\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01790330380733524\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.02012033076228007\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018168916047683784\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.020166043934506783\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017979664036205836\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.020162395620043728\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.018159312009811402\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.02015475487417501\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.017940312251448633\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.020160359526188044\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01824395036590951\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.02017756492115449\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.018006508930453233\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.02010177150098742\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01794027483889035\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.020101736259201298\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.017999265901744367\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.02009881889798503\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01814787443727255\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.020098904660646465\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.018147060541169983\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.020074692433295044\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.0178357187126364\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.02002353326457998\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.018002173171511718\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.019943916400813538\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.017858646783445564\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.019998597656039223\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.018339671034898076\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.019886821886335594\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.017957085876592567\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.019698057161725086\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.017597179487347604\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.019642468042455723\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.017733116847063815\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.019472119033984516\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.0177145048177668\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.01930890704734602\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017731762331511292\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.01922396470563135\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017585401662758418\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.018944232454658417\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.017551830889923233\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.01875636804902899\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.017466548191649573\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.018464105757142323\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.01755546544279371\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.018203457453004692\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.01761869833405529\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.017853455496547016\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.017591137917978422\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.017482109043909157\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.017427742720714637\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.01701738963416521\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.01746185983398131\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.016540135270443516\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.017659192798393113\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.015898482266651547\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.017704387408282077\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.015317569972704287\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.01765869337001017\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.014717612658505854\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.01784261967986822\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.014116624201499466\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017778833396732807\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.013557813123570404\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.01784238408186606\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.013151004721505054\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.017860079476875918\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.01289511596163114\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.01788789230797972\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.01275356279929047\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.017915496150297777\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6766128723604091\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.3084678027559729\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.054294783149616443\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.019430348759188372\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02375397609843724\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01848620839197846\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.022572597785704376\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017980771851451957\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.02170548929522435\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.01759681697277462\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.020442341656788536\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01759281480575309\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020334067430509174\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017435178407193982\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.019893051894462627\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017510639804908457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 8, train_loss: 0.01980561927716801\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01747887855505242\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.019745587789710018\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017613860531984007\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01972319830910883\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017462148358497548\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.019802537652245468\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017667016343158835\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019914073721114277\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01762766675914035\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.019899881242409996\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017581640140098685\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.019931914865214756\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01803025241722079\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.02002073686731898\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01769740183782928\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.02001200085910766\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017396341954522273\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.020074239797026352\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017488349557799453\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.020170710683948753\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017564896740676725\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.020103173424908215\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.017563059432979894\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.02008184998471668\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01751694069517886\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.020164317680873733\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017728208372478977\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.020112549913102303\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01775745379135889\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020041531383775284\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017569111002718702\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020132789023868416\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017745971186634374\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.020122520760565563\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.017619850168771604\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.020023624851381865\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.017564834889901036\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.019942831315532112\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.01773717826889718\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.019841387989404408\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.017478167545050383\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.019745771179272644\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.01765791025451001\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.01957446393435416\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.017500346745638287\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.01957133369844245\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.01725893174572026\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.019357338534209175\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.017287230858688846\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.01917970312786275\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.01737780819701798\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.01900790990802689\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.01728249982218532\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.018727101588054844\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.01721411050461671\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.018519841390999332\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.01716451160609722\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.018257838916843353\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.01737708121757297\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.017874404700283987\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.017180887133102205\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.017454394739985033\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.017182572963921464\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.01696478005876576\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017263024223639685\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.01638538118424839\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.017315912745235598\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.015865106041124767\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.017392445273478243\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.015203121469180653\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.017379079315373126\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.01455570666956297\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.017422598074464238\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.013860475265191517\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.01741881306995364\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.01337506749626735\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.01744511824868181\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.01300190150251855\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.01744450768455863\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.012759884859880676\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.017433836617890525\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.01265029406067038\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.0174369343337329\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6764136453469595\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.32635510734149387\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.055633782976023526\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.021427128570420402\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.028007904297091823\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.022194093891552517\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.024239056811168575\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.019420487646545682\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.022412302998313004\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018665621589337076\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.021018304349179718\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.018231546000710554\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02021039881999942\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.018502912696983134\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.020006528853074364\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.018118750969214097\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.019845036290370037\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.018232798975493226\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.019496612763707188\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018140598626009054\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.019300635917571144\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01811359439577375\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.019356980690381664\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01802533053393875\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.019324920950052532\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.018129320895033222\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.019270093436690346\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01820497132305588\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01949813869525341\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.018117877202374594\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.019551226410312927\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.018182540658329215\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01949065246119879\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.018200802324073655\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01959164679536353\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.018358619431299822\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01960708219827949\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.018747623318008014\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.019690902039840603\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.018581025728157587\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01977090434967608\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.018505812329905374\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.019585780299984028\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01818411336945636\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.019636562256061512\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01838209115500961\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01960314055769772\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01799860479576247\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.019650351957998413\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.018355655883039747\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.01947091397680882\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.018213061881916865\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.01940399164036996\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.018159679057342667\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.01934357642776508\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.018267385901084968\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.01934768569966157\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.017746772351009504\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.01933283213040103\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.018276056540863856\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.01932108608762855\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.017912766842969826\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.018989103846251965\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.018099967150815896\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.018909079495115555\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.01788949788148914\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.018625872337893732\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.017861439367490156\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.01843688994700062\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.0179089771051492\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.01830557941634586\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.017834655222083842\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.017917658802985712\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.01797186875981944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4, EPOCH: 37, train_loss: 0.01757574403334571\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.01795235097940479\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.017031658832253754\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017734343159411636\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.01651288391482355\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.017757127966199604\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.0160039731071911\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.017883742307978016\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.015311354676774446\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.01802949176302978\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.014540898080483295\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.018103335638131414\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.013781111059791368\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.017996754789991038\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.012982863777627548\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.018251048560653415\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.012304670946753544\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.018181293856884752\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.01162255341457068\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.0182798370718956\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.011188457686238098\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.018329241978270665\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.011011803306747173\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.018304651310401304\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.010938398769476276\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.018294554496450083\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6760010511978812\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.3191192959036146\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.05418537449145663\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.022223813299621854\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023734150427407112\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.020837476370590073\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.022537074092289677\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.02031723851604121\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.02088000362172075\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.019028433412313462\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.019895803547747757\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.019092785779918943\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.019520226906499138\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.020674956323845046\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.021012002345768437\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01906795645398753\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.019879653428991634\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018913377475525652\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.019695551755527656\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01880320959857532\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.019660294568841007\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01943606436252594\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.019722975291095783\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01878244568194662\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01957064703700767\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01882171809141125\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.019678860592345398\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.018921451110924994\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01974936462668837\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01901823173144034\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019734057975743992\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.01900579125753471\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01973391534841579\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.0189102867352111\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01976501357242249\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01908877832548959\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.019843959425022636\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.0190637527565871\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.019786717721085617\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.018948147339480265\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.019819698242497616\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018997388758829663\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.019799301603242107\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.01949181386402675\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.0198169419730919\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.0188345714073096\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.019870795269051323\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.018780003088925565\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.0197020773033517\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01884667593985796\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.019761433635932812\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.01883506431643452\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.019637303602328335\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.018780297839215823\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.019583594013491402\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.018883896858564446\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.01947496936697027\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.018631109808172498\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.019427074544617663\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018775572760828904\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.019356834904655167\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.018618058972060682\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.019238276002199753\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.018934681319764682\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.019082422786648724\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.018826663786811488\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.01883598574963601\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.018760378818426814\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.018655237201871216\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.018698671061013427\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.01844672619810571\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.018619798123836517\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.01811674643523883\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.018569849830652987\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.01792687839032083\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.01854062197463853\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.017542977736372013\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.018571991606482437\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.017093073380976053\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.01847143072102751\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.016614107469069786\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.01859294114900487\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.016057105687703344\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.018726501959775176\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.015440974425038567\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.01871208074901785\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.0147843054374275\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.0187711681372353\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.014105222943792309\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.018816762364336423\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.013453200088300999\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.018792699383837836\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.012994257470025965\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.018884401928101268\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.012614807950845663\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.01886025896029813\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.012380278763779696\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.01887599416077137\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.012286263194097124\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.01888225365962301\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6778557818301403\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.32781111342566355\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.05616770525646471\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.0208707723234381\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.023772716277489697\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.019513719475695065\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.02267875191993522\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.02009116794381823\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.022456260166899132\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01954279738877501\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.020793189668524874\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01933399412248816\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.021520088351991054\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.018596546298691206\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01999390376799733\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01834659901048456\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.019716067729096343\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01870248264500073\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.019661829297016136\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.018364579656294414\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.019597948182129513\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01841396316885948\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.019633565220410806\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018702826808605875\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01971311568126191\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01838641172008855\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01965949436935195\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01856390466647489\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01978021488953246\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.018384477230054992\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019723470615100686\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018619256732719285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 16, train_loss: 0.019848944823237232\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01834251768887043\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01974400350429716\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01857247150370053\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.019861996812868293\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.018834499908345088\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.019834494789260148\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.018707631794469697\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01988156795175406\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.018393647324826037\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.019845735376877505\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.018411326142294068\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.019832389918665816\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.018800001431788716\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.019822951188705265\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01850156874528953\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.0197619441896677\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.018628939241170882\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.01980803757362122\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.018452027067542075\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.01965838771340621\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.018464971014431546\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.01960313604315267\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.018380968485559736\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.01951095605962468\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01856686802847045\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.019475190879872244\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.018320748742137637\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.019319422706200257\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.018382528104952403\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.019194995998031032\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018564614174621446\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.019051841997208385\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018227046515260425\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.018849854255570984\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.01849034811769213\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.018630722972707157\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.01813462573502745\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.01836471354085816\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.01848280153104237\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.01814207742602503\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.018378759760941776\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.01784281421072074\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.018445642398936406\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.01740878720489079\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.0183311133778521\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.01703709015881058\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.01841982768050262\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.01654144870049327\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.018393388177667346\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.01597553781186142\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.018505691151533808\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.01527753793192606\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.0185664029525859\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.014606570879364535\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.018664864503911565\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.013913631248865684\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.018642298557928632\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.013251052836268923\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.018717202916741373\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.01270944722350279\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.018779219633766584\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.01227370850796247\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.018828181070940836\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.012026635501669707\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.018842572612421855\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.01192078628597686\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.018856207547443254\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6762470920448718\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.31531626326697215\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.05431512963242721\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019990009441971778\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023413068128992683\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019323707478387016\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.02359822080673083\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.021766869883452142\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.022969232993605343\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018245693109929562\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02243344194215277\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.018391842554722513\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.020803999020785526\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017874802010399954\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.02015260451108865\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01809482007686581\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01998460009370161\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017808980122208596\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01998079267155001\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017734416228319918\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.019781228222384834\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017811275087296963\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.019889713480960632\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018084610892193657\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01989631623407637\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018185845203697683\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019882520296327446\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01827701564346041\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01995662024811558\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018007202579506807\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.02002647434077833\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017913855080093657\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.019981216855239178\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.0180265731045178\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.020020900375169258\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01806194255394595\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.020016137645512386\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01832557964537825\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.020131514232227768\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01781740648938077\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.020026119925297688\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01787011069910867\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.02008022222182025\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.018299605191818304\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.020056530927726322\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018276615121534893\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.02002383196267529\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01797803235905511\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.019972592268301094\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018010340364915983\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.019977261703731358\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.017849270440638065\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.019950676263998383\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01780534881566252\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.019845090954955937\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.017757196724414826\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.019720108275288258\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.01774733385869435\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.019723629174025162\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.01786563689155238\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.019562928640432117\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.017838241984801634\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.019377134254445202\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.01788384776030268\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.01929971686415914\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017791499570012092\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.01908390142995378\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.01749198277081762\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.018837139671803383\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.017699870946151868\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.018685015890261402\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.017675341213388103\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.018347991117532703\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.017479547379272323\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.018084550370880657\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.017623477588806835\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.017721560068320538\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.017601887695491314\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.017247114944663168\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.017710186301597527\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.016768596486013004\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.017631553752081735\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.016221268473705953\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.01782315538397857\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.01555009886784398\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.01783539554370301\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.014912315644323826\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.017737799191049168\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.014178877446692491\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.01787826269865036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 45, train_loss: 0.013517713450921186\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017970624140330724\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.0129397703550648\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.018014641638313022\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.012583841974644558\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.018030545301735403\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.012407754743606716\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.017991512162344795\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.012265567998469307\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.017979180733008044\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.674565684536229\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.306183884249014\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.05391123449510854\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020103671697570998\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.024307179467185684\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018853623474783757\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.023036708717868812\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018101021373534903\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.0215910982772492\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.018199752358829275\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.02051103418773931\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017545486992115483\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.021268129132796024\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017565539490212414\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02048656407851672\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017365258104880068\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.0200527751872289\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01752218310995137\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01997250703203937\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01762623227584888\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.019929273175480572\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017494344755130654\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01999518570854612\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017515473423854393\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.01992580420135156\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01762339483727427\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.02007304536907569\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017781866385656243\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.020052319676007912\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017544457086307162\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.020104835174329903\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017745740519946113\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.02007812922955423\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017674371874069467\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.0201464733513801\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01772184234441203\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.020197868468644825\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01767116045469747\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.02015197070558434\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.017691001131692353\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020152385319596615\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01770728864871404\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.02016673145302828\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017607891685603297\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.020145839336665645\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017569206271539715\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020211478128381397\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01746532803072649\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.02008979910633702\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01759523876449641\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.02006477965176969\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.017551055808058557\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.019999174401164055\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.01754321064800024\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.019933054237154083\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.017674346865319154\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.0198979869187958\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.017472892807906166\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.01981038727082204\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.017732934423667544\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.019691665616372356\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.01757536833996282\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.01950794689870183\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.01750621941926725\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.019381818307590656\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.01743651825167677\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.01925702870863935\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.017498945954310542\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.019000087527261265\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.017555306501248303\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.018794801167171936\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.01714416387874414\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.01851805146324678\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.01746228720773669\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.018214360675842003\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017411344712052274\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.017874455632830875\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.0173801531576935\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.017460637091510536\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.01733330437256133\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.016952132650961477\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017272434416500962\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.016519458201862333\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.017343410592087927\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.01585815611389884\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.017406666870502865\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.015181975324462721\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.017369389890090507\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.014534795346359411\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.01739864221171421\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.013903081545309313\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.017432776142788285\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.013320047847008791\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.017442869214231476\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.012994308982962284\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.017521655844414934\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.012715467852472828\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.017499836189124512\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.012606584460245094\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.017494739964604378\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6763004949991254\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.3157673963478633\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.0547439716351421\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020578388337578093\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.024083776224026646\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.02231020751808371\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.02336566582106162\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01906243163560118\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.022893448886664017\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01924606795821871\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.02147134697145742\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.018069991150072642\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02076864381577226\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01958096149776663\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.02016633628881064\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.018301923173878874\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.019846626827358337\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.018745143392256327\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.019862992648521195\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018252894441996303\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.019790427529833454\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01792241848473038\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.019792803954603016\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.018300839114402022\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.019934133221597775\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.018186560086905956\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.01980535849334969\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.018091054792915073\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.019964545168846413\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01789449027606419\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01992882298224646\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.01814073087381465\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01991474210028199\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01831509569393737\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.020067825360034687\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.018218049007867065\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.020091874659925266\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.018399424026054996\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.020130510927866333\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01838139383388417\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.020109929387336193\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.018137157069785255\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.02003051333831272\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.018455588391848972\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.020099670869176803\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01818809046276978\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.02006672027156405\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.018060769752732346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4, EPOCH: 24, train_loss: 0.02007309177323528\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01805654035082885\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.019956868222874145\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.018153140214937073\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.019921625991338406\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.018025029929620878\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.01979846765111754\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.018090302576976164\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.01966799748386594\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.017971634971243995\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.019710444804766903\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.018003396929374763\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.019601603268065315\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.018051466931189808\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.01944632812038712\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.01772721093147993\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.01935976569581291\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017827286837356432\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.019161957788510597\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.017869977466762065\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.01888983601542271\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.017811953569097178\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.018601607855247414\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.01777502056211233\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.018392242221296696\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.01765238828957081\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.0181137604193519\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.017950221550251756\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.017851230809869972\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017732736308659826\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.017389847370593445\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.01781937565122332\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.016918400127062763\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.017698203160294464\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.016354543987013723\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.01771859744829791\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.015800090985831575\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.017764415645173618\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.015103183916189533\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.017859111087662832\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.014502606962038122\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.017867693810590675\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.013883618948360285\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.017880385874637535\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.01340509766874754\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.017955551269863333\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.012953647601323715\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.01797100334827389\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.01278875849844105\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.017950970652912346\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.012724620850243862\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.017923995080803123\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6747576013423394\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.318509714944022\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.05258601875570805\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.021676448466522353\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.02334914257938879\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.02059919270021575\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.023206779200151777\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.020341110761676516\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.02199051838260198\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.04445489905774593\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.022304164880103824\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.019668891493763243\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.020586206186292828\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.019182104537529606\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.02023042118905679\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.018971412841762816\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020109628907580307\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01885304336569139\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.02002123983549899\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01874918464039053\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.019937986602493817\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01916535906493664\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.019937294197903164\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.018906851299107075\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01993107320605845\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018871038806225572\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.020006270066875477\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01897035323615585\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.019930594195814236\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.018832272184746607\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019901167101942112\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.018911662538136753\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.019945426493127277\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.019221846173916545\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.019931850064059963\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.018815213362021105\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.019820932339390984\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.019022973547024386\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.019924345885174\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.019073008692690303\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.019949756211776665\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.01877379497247083\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01991619156214638\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.018927857226559094\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.019918507005533447\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.019103102891572885\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.019826994817434013\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.018797533214092256\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.019849115064826565\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.019316441140004567\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.019790392396026764\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.01861484936837639\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.019696608590690987\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.018796819342034202\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.019645998632346375\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.018996921208287987\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.019571844582864338\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.018792618278946197\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.019413431890416836\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018818796585713116\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.019320804234324158\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.018789484591356344\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.019215674072072125\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.01887874241386141\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.019143942439847666\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.018628747601594244\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.01891500103300896\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.018683183592345033\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.018694378435611725\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.018395543258105006\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.018426047894509807\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.018529353716543743\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.018265879375563152\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.018575977480837277\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.017904706454525392\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.018637281017644065\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.017594586767634188\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.018519247429711477\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.01715681103962487\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.018477120782647814\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.016730299138504524\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.018587161121623858\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.016197556623028242\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.01863306231264557\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.015630201962978943\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.018682013664926802\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.014945000005157097\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.018565413994448526\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.014325779194579176\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.01879276196871485\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.013689478508372238\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.01883589598749365\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.01314863068578036\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.01883173356098788\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.012771914017967123\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.0188552338629961\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.012497076123574938\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.018857137326683315\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.012466272305481243\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.01885520477912256\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6761310322441324\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.3213152919496809\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.05537372953972242\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.021025891548820903\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.023747521432211798\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.024398448903645786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 3, train_loss: 0.022949714431144894\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01943450713796275\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.021459991724169167\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.02115807118160384\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.021155745171717484\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01850868926516601\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.021291694936961154\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01826388609728643\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.019967488523056038\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.018623598718217442\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01969299464058267\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.018408524191805293\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.01966637889616681\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.018486377330763\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.019546426261646033\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.018314441187041147\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.019582369031697293\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018844955042004584\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.019588473681224523\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.018460792782051223\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01961755177454792\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.018598904141357966\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01963834710636713\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01858656390437058\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01977156021081618\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01846226996609143\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.019811416275962425\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.018806832656264306\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.019813818523973008\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.018572986072727612\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.019847395048089272\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01859745638711112\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01979522169125776\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01853411336030279\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01986897702797921\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01857934796384403\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.019832057416112752\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01856185219117573\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01989356231243506\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01855748338358743\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01979329209965076\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018356860322611673\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.019741490306536647\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.018602856301835606\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.019768180189667826\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.018389220642192023\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.01975836668734568\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.018622723913618498\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.01964614918305926\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.01854363435081073\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.01950949801635133\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.018344421737960408\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.019451682353868103\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.01844434237905911\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.019328082374630184\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.01859892319355692\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.01918486713764876\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018314185472471375\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.019039372118176336\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018377923060740743\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.0187066144846978\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.01841540176953588\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.018660500985536264\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.01846178195306233\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.01838788348012162\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.018254913203418256\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.01816467160399813\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.018309802136250903\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.017796764592130254\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.01827231070825032\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.017347393163146763\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.018327749094792775\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.017017880243922236\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.018185891157814434\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.016453300086087988\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.018516124997820172\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.01591106791076434\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.018518813539828573\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.015243970945368718\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.018579078199607985\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.014575992724484337\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.018613137996622495\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.013853510590202182\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.01872652316732066\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.013197162174993622\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.018764137476682662\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.012666118018546679\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.01879782671374934\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.01230758009138551\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.018828609851854188\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.01209878217918377\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.018844115095479147\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.011971851450520276\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.01883554495871067\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.676126446844875\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.32769872205598016\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.05494828832646211\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.02089138227914061\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02417449662596851\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019723744690418245\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.023089521672522675\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.019674977819834436\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.02216813636376806\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.021736168169549534\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.022675104452756004\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.02011877851826804\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.020625207748642002\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017972281229283127\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020102772173350273\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017666942360145706\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01987852974106436\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01782696840486356\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.019769058387348618\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01776476978723492\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.0197177745833777\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01787425202450582\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.01980930084929518\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018085340969264507\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01986405071195053\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018080321672771658\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019868081489550896\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.018097911349364688\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019851889231822628\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017894226738384793\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.019983976377525192\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.018036970709051404\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.019992222429077694\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.018199301431221622\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.019999266332150368\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.018070198435868535\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.02006558061617872\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01773014297442777\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.019981011950775333\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01836716162839106\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.02016153830387022\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01812162689332451\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.019999397243710533\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.017907708936503956\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.020038041178191055\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018050785761858736\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.020026376092995422\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.017985367083123753\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.020026129508472008\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018053078039416245\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.01997669143737226\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.01793319268950394\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01991524913118801\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.018039102932172164\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.01986663372836251\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.017676734285695214\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.01983042717303919\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.017789029090532236\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.019627724072315555\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.017678665236702987\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.01962177858998378\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.01780705348189388\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.019386576029701508\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.01762653405645064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 32, train_loss: 0.01932211568498093\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017758780691240515\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.019123070549381817\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017669317977769033\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.018907955274039854\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.017799473234585354\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.018749667790488922\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.01762808414974383\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.018426223091133263\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.017622278204986026\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.018137659432123535\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.017585484816559725\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.01781591857392071\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.01758052267666374\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.017417321143590885\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.01755132150969335\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.016947862644936296\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.017736727611294814\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.0164523398625138\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.017500156137560095\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.01584375751596214\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.01775200433496918\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.015256843421662199\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.017692556338650838\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.014579316688890474\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017789345500724658\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.014020508364436851\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017802458629012106\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.013501472453978182\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.01785782410630158\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.01312091167125365\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.017868850380182266\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.012910335749873648\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.017847166157194547\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.012861364224142786\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.01785610666764634\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6756682976864387\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.3192037887432996\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.05392567335587481\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01975185193997972\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.023745131071494972\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018977347432690507\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.0229900350821191\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01806515855166842\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.021135893272424953\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017604012781863704\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.0213227023276082\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.02120481212349499\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.022206377899409203\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017567539121955633\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020468345019912373\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017640800626181504\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.020234289417124313\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01748806210782598\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020143074037480183\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01757860301500734\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.020027643204599186\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017665863749297225\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.02004736239441495\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01788889624945381\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019976266308863094\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01762982800274211\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.02001729247200748\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017656443147536588\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.020078243681000196\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017704702037222245\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.020159675888177277\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01737315925386022\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.02018571260344723\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01780338305979967\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.020151850983392502\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01780614339034347\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.020224078693359657\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017933758961803773\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.02017179937304362\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01776748931254534\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020157412828310677\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017662109040162143\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.02017831706536421\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017533484408084082\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.020187099396750546\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017553670824888873\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020133567380084507\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017340216155656996\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020131988491377106\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01757737358703333\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.020057762136169964\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.017539934556492987\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.020001858310854954\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.017571525456493393\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.02000037908716046\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.017977961393840173\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.019901371007596237\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01747051582616918\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.019729538739699383\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.01742351085276288\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.01971618860852027\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.017324091537910348\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.019544520064432552\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.017304081798476333\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.01939037875474795\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.01758858350598637\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.01915228989083266\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.01727774183211081\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.019022153501493343\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.017420665963607675\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.018776413215243298\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.017430271706817782\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.01853846669521021\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.01728570510578506\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.018253823634291042\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017163422314778846\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.017898799554593323\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.017304816557204023\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.01742178348797387\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.01714955530512859\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.016981198162218367\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017163435462862253\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.01644986014192303\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.01734503670869505\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.015764130603360092\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.017370754935066488\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.015106497629397158\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.017370490001185852\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.014355780529803124\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.017423249835915425\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.013728370822534182\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.01747305318713188\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.013150417826313904\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.017508200397167134\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.012736402377756178\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.017475755364798447\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.012522367733544197\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.017447131713304448\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.012428073003294243\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.017486290294019616\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.675874589793924\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.3110287734440395\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.054113152760850346\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020903749231781277\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023883981279272964\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.019377975751246723\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.022500453017436077\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.027556701110942022\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.022057807842350525\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.020456770488194057\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.021259631259717804\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.018046052833752973\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02006204342604547\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.018462054511266094\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.01995696190852618\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01803036177796977\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.019706773760634056\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.018193701042660645\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01973605467060554\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018110733266387666\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01963943831514621\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.018072158683623586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4, EPOCH: 11, train_loss: 0.019656618665633858\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01841193408306156\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.019821962476640507\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.018231223044650895\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.019775609566789608\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.018220795744231768\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.020000432044321646\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.0181307920387813\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.019853334509484146\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.018310093586998328\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.0199079931565169\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.018106446947370257\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.019962403140422226\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.018165058616016593\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.020021593211677628\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.018129368286047665\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.019946904043140617\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.018151541240513325\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.020066709730072296\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01803082719977413\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.02007373852952235\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.018298342265188693\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.020163276921147884\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.018124613165855407\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01995605201986821\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.018188203844640937\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.020013564522715584\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.018112016203148024\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.01997962170213029\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.018134357753608908\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.020000611742337544\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.018097349469150814\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.019834975860473038\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.01836123833698886\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.01984437572621349\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.01815907670451062\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.019657482393085957\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.018023980621780667\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.019516552312542564\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.0179949482104608\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.019473291204675384\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.018074185747121062\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.0192786051446329\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.01798427538680179\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.01914547788033235\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.01785001273133925\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.018829261101242424\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.01770927429731403\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.018748814753000286\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.017575884956334317\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.018472065622715847\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.0177511618871774\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.01828489329773879\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.017868515822504247\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.017855647998605517\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017601347315524304\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.017378150100779276\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.01765740266335862\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.017092252426875242\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.017618044864918504\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.016517160426609327\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.017713039315172603\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.01599973933501304\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.017688251951975483\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.015369139389013466\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.017763386320854935\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.014795892574972864\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.01776593543056931\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.0141606906266964\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.01783181806760175\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.013747132794958527\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.01782463945980583\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.013371700447970543\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.017890836484730242\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.013181858992986921\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.0178945159007396\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.013119564040739468\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.017900807916053703\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6786252979351126\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.3397769587380545\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.05534287921382465\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.021823987364768982\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023611289111600407\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.020946217381528447\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.023343242029996887\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.020058638096920083\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.021449410235104355\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.03661691227129527\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.021868951726650845\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.019450285498585018\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02058900643032098\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01913725494274071\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020074002296272396\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01886877731553146\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.019820933500169845\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018765616523368018\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.01984855493503636\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.018848323609147753\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.019728680505700733\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.018783581629395484\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.019728702425524807\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.018888892446245465\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.019819844608613545\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018999212607741355\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01970624573447782\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.019188192806073597\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.019867502071935196\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.018865055830350943\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.01979148726694394\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.018981211845363888\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.019835717382206432\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01920367404818535\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01978668898506009\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01878992249923093\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.01989130327559036\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.0188760994002223\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.019909918834657772\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.018741394419755253\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.0198760827112457\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018812495762748377\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.019875749149292275\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.018916774727404117\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01982381251519141\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.018947761026876314\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.019788821983704533\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01900193563529423\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.019793911769554234\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.018951540546757833\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.01966283552726542\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.018947998487523623\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.019686709792501686\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.018726947185184275\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.01965377610716699\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.018835130307291236\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.019508490379413834\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.018900135212710927\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.01950525935145392\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018900331136371407\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.019366546149325113\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.01886257699557713\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.019255503883882277\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.018715842786644187\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.019109268726754017\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.01884739361703396\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.018924834206700325\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.018567008312259402\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.018725359609917454\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.018665438065571444\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.018484150585920914\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.01835239284804889\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.018161846453027018\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.01845113177384649\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.01793749077056629\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.01845584022147315\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.017610848847560694\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.018560057931712694\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.01724374023657562\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.018476462444024427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 40, train_loss: 0.016717301850355623\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.018545388084437165\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.01618149863097115\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.018635889195970128\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.01559916424119602\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.018678793337728296\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.014930622483455185\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.018777239003351757\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.014288307241825522\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.0187438609876803\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.01366256206444856\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.018761075447712626\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.013132118802193714\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.018831813628120083\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.012707800476177446\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.018872408435813018\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.012481322734738174\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.01886364317366055\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.01237517284175408\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.018879277578422\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6782592811288625\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.3225834948675973\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.0548618866579376\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020396739031587327\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.023586051511394715\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.02022555662052972\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.022675704510107527\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.018670811716999327\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.022555015682086458\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.018351116137845177\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02067079297164931\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01864735132881573\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.0200390265778686\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.018408104298370226\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.019697795873575837\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.018247225348438534\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.019570138427789194\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.018387613019772937\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.01950860409623515\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01855370295899255\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01954632187194198\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.018479708156415395\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01957303095255455\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018709118823919978\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.019632381393852896\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.018482520537717\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.019591626772371522\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01872217772262437\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019713237772892862\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01865786271435874\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019669201891243892\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018696581412638937\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.019783460405947518\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.018560474658651013\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.019832542342861203\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.018157660402357577\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.019846930651225312\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01848161028964179\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.019945471649513626\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01867266861455781\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.019877616452039594\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.0185233794684921\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.0198134228750302\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01877223194709846\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.019908811298817615\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01850384974053928\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.019922620936358063\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018858151670013156\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.01976940544308537\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01849603253815855\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.019784722463601696\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.0187215299478599\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.019702890044907585\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.018647160860044615\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.01962246726790484\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.0185421208185809\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.019581270003079496\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01836545259824821\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.01941091638656646\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.0184231056698731\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.019396934970995806\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.01845164533172335\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.019177496949904158\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018258609888809067\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.01900217894220004\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018613237248999732\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.01881197864448067\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.018404266610741616\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.01865418479662307\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.01816844737955502\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.018387957979129614\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.018212782910891942\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.01812878413547347\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.018243274571640152\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.01781771550920323\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.0184658519923687\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.017425603430419073\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.018241183779069355\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.01697140586746\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.018354073273284095\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.01645894467585931\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.018388921288507325\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.01591232644706747\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.018452298694423268\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.015225638016840837\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.01858964828508241\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.014477884655233718\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.018532548312629973\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.013774136679559729\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.018726176608886036\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.013117570599989735\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.018773720413446427\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.012558521186239529\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.01886597430067403\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.012182679775096204\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.018862180465034076\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.011940591336384306\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.01886446571775845\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.011872097353593711\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.01885723780308451\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6778792801542558\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.31830807413373674\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.05573048342721186\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.0202236393732684\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023873960126893246\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.021696473604866436\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.023261821977254273\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.020025201514363287\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.021393074154637863\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.1069577841354268\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02226050994426444\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.0179355455030288\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.02070222344195497\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018150591743843897\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020230774700209713\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017899636019553456\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020071344247654728\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017886816364313874\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.019887548601389794\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.018127146576132094\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.01987636812787125\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017884037350969655\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.019880479444628178\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017836597003042697\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01989062583964804\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01794647199234792\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019915122741266438\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01786354500800371\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01994530245175828\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017912183648773602\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.019906291522193646\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.018125015763299807\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01994056648750236\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.018124012702277727\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.019954685337733532\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.018129172761525425\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.02004369108033353\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01799035726913384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 19, train_loss: 0.020115990461646648\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.018003930151462556\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.020059081901242767\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.017971029771225795\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.020141620634366638\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.018030231579073838\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.020026268639966198\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018272304401866026\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.0200230591269075\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.018032666721514292\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.019992084971264652\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018067128637007306\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.019933829839894737\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.018124332944197314\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01987203376610642\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.018057990739388127\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.01984419324097858\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.017911322734185626\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.019795321980896202\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.01786988747439214\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.019639129628953728\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.017804597743919917\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.019523832123672615\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.017864168914301055\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.019363539644341538\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.017784556640045985\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.019242381096642086\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017763854749500752\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.019051824844833733\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.01772712849612747\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.018867771168225918\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.017747811494129045\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.018639376515225656\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.017619523272982666\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.018365418767907482\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.01758594736456871\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.017974949192147757\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.017562056705355645\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.017622071460051382\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.017513112643999712\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.017230650079369112\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.017383827295686518\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.016718339843108602\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.017564869565623146\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.016159414988605007\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.017604715031172547\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.015517238048377676\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.017649867571890354\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.01477631722725388\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.017817628330418042\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.014117699622622003\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017824041710368225\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.013485933397559153\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.01787368333233254\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.012951166132815939\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.017926467103617533\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.012548031184174444\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.01798984565372978\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.012237282240412373\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.017993344872125557\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.012212601382339346\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.017992436619741575\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6768304185158964\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.325297871056725\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.05531352053841819\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.021371443865492064\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02397671490367772\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.019391717170091236\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.022958829364590885\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01835283067296533\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.02234088823847149\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.018334166201598504\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.021605434503568256\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017716866890516353\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.02076563289038081\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017661324263933825\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02019204309993032\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017371295704780257\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.019953159169982308\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01772733569583472\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.02001161603392034\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017534069360836464\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.019977176561951637\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01767394130172975\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.019981137760307476\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017507475992555126\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.01998781329155832\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017435701125684905\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.019944455312645954\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017408419345669886\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.020053004225095112\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017711187082835856\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.020114860807855923\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.018180288593558705\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.0201142361468595\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.018031299251186496\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.02009864722419044\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017573126619133878\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.0201407504281488\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017813542364713025\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.02017621029222357\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.017540551256388426\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020191061472439247\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01773871256805518\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.02017928778693296\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017596542040872222\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.02021190899329773\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01771990193382782\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020172664855161438\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017505767919561443\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020142804142897545\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01755316706155153\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.0200708181583795\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.017385383739190942\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.019990405054304047\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.01746148125761572\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.01995686660318271\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.017519320416099885\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.01986641551543405\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.017530643600313103\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.019777708781370217\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.017387237454600194\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.019672451284376606\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.01745550665894852\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.019541189074516296\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.017275823417174464\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.019411988623872185\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.017477748532067326\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.019182991681863434\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.017355113618952388\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.019020980338741472\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.017208003110307103\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.018773880368773487\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.017298563986140138\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.01848124002740867\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.017291717340841013\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.018245763503069033\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017209524069638812\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.017894309607968815\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.01722472706152236\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.017459594462390825\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.017247029443216676\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.016999319830126522\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017239325515487614\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.016435070375007563\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.01734498712946387\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.015806874510008787\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.01746989121003186\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.015149590896739475\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.017286560689920887\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.014438695955913568\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.01742294756695628\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.013797209672359884\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.01740765604464447\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.013313749204457237\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.01744264060193125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 47, train_loss: 0.012868832776565914\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.017456290229935858\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.012643851994442335\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.017447854145703948\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.012552715122591759\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.017454313963432524\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6767838055240936\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.30860788311277115\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.054999526941042015\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.02062981804566724\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023725491826948913\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.02280989730996745\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.023043832485226616\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.022349045585308758\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.022000140564489193\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018202593523476807\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.021519032522928024\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01803433160696711\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020375598451473576\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.018882441201380322\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.01985894362239734\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01807334731732096\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.019668346986282562\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01857153507215636\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01973613671472539\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018032151247773853\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01974077007152896\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.018142255369041647\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.0196811823255342\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.018620346752660614\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01968775572174269\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01798848576311554\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.019722977801617504\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.018170405684837274\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01973121260981197\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.018456224937524114\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01980255905241854\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.018385886879903928\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01980803661264371\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01837632501763957\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.0198804609666484\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01817780238177095\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.019816344968326714\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.018114591895469597\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.019886762619126534\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.018118876511497156\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.019876305378325607\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.018217971974185534\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.019905804683440838\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01838538758456707\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.019877713160130425\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.018124675883778505\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.0198990020469047\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.018153624369629792\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.019867557613853958\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.018502187941755566\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.019891558525462944\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.0182066841849259\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.01978541725733574\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.017836884941373553\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.019841998640069927\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.018126060467745578\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.019607424621294806\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.018015028642756597\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.019539882415446682\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.018024102970957755\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.019438850072522957\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.017796624105955873\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.019323548814956692\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.017981598313365665\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.019168346877331318\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017783619756145137\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.018962956006652203\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.017785444562988622\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.01883621254692907\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.017584562594337123\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.01853599305521103\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.017785516088562353\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.01824539997007536\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.01779257527419499\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.017920064976087946\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.017670741703893458\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.01760377192977762\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017712803610733577\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.01717752014435288\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.01791732795536518\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.016737542918248884\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.01761982526097979\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.016162155904685675\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.01776760835200548\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.015513647833596106\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.017856767613972938\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.014835027572901352\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.017790099925228526\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.014158904977628717\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.01792172422366483\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.013410558282951082\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.017962463732276644\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.012864007796768261\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.017980426230600904\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.01246512411972103\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.018033323303929396\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.012221228533788868\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.01804950364998409\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.012114868749041056\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.018116019160619803\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6767187440308972\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.3143712929316929\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.054654299160060676\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.021317114414913314\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023036390381014866\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.022307444789579935\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.02216401316927395\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.019922487597380367\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.02082128847098869\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.8249946102499962\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.024162704273518444\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01981648212032659\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02117230913237385\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.019497058327708927\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020509443826217583\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.019030346242444856\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020200542012310547\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01907913104764053\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020047643478365913\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01881039006901639\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.01981106225023235\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.019245637128395693\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01989974224589009\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.018946512043476103\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.019801973608200966\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.019011645976986204\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.019803206085402897\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01907069645822048\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01977565989870092\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.019192747079900332\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019800243642775044\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.018895392465804305\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.019852060055279213\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01933179676000561\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.019870038967633594\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.018822535526539598\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.019775080062664936\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.018808830875371184\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.019837569283402485\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01875428751643215\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01979515081325519\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018808767465608462\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.019801858137699142\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.018828113776232516\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.019801337298923645\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.019080754050186704\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.019759782050074875\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01885586112205471\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.019706724144086456\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.0191731849153127\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.019698570705140413\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.01894116284591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 26, train_loss: 0.019708434538240883\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.01922242979386023\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.019663823714506798\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.018810350421283928\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.01953485462328662\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.018755327218345233\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.019355053298067356\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018856388569942543\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.019287692058993423\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.0188028858974576\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.019298264662316746\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.01887429588075195\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.01900373292627974\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.01852206074233566\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.01878045573560656\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.018701794663710254\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.018689106832649828\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.018679419638855117\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.01835288519066745\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.01867796185293368\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.018125180593705263\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.01857613769492933\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.01786139887501148\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.018582090682217053\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.01753668545110934\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.018521527866167682\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.017089172759079847\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.01867888407515628\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.016617684321397024\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.018697973234312874\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.01601470099168195\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.01861960400960275\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.015372033102734797\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.018720315875751632\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.014671196391725021\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.018783972572003094\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.013958497357595226\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.0188319575839809\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.013338601614847996\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.01891028034899916\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.012725039000582436\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.018942411722881452\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.012277030095835959\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.01899972158883299\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.012110293215221685\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.018976972012647562\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.01199943363747519\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.018995476860020843\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6770400333143499\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.31924052493912836\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.05496639891588775\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020785089316112653\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.024168498922873587\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.021218595068369595\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.022674326220676846\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.019441542242254528\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.021780795043837415\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.018295334971376826\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02056320133979303\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.018377578311732836\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.01987365067657763\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.018286631788526263\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01964852561915878\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.018538742565682956\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.019553941259854032\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01837480717471668\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.019557452638273257\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01840044999761241\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01944092946657299\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.018567442734326634\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01957511904574659\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01834915349526065\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.019636687081660668\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01848486236163548\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.019602058400964215\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.018940121307969092\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019678778049066988\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.018632685180221285\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01972939789186429\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018789889982768468\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.019777588858982943\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.018535943755081722\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.019824402651538814\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.018368556084377426\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.019787517695748894\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.018648447788187434\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01981071044221847\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01867894402572087\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.019854001932009292\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01831842777984483\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.019944999176655372\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01849193929561547\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01986198464449305\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.018642978529844964\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01983327341068835\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018373712205461093\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.019761894333319072\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.018505668906228883\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.0197843520147522\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.01833006021167551\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.01973489690979902\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.01832375491836241\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.01962054866182543\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.018559312394687107\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.019555583745785005\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.018309898514832768\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.01945159043165019\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.018517803507191795\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.01937452153078396\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.018289222940802576\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.019214095860502146\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.01832485587469169\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.019040880439272764\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018462391889521052\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.018816054791864687\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.01846181952527591\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.018623743988029712\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.01842090780181544\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.018435689430330356\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.018343887690986906\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.018108173443453154\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.018329873574631554\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.017798328282733034\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.018509111819522722\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.01742583265813598\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.01835826512958322\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.016980428438987175\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.018334648651736122\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.016458960338393704\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.018496422522834368\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.01594600411145574\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.01852797456085682\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.015281664601860255\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.018590767309069632\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.014614416469894621\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.018526999333075115\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.01385439020737897\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.018689335297260967\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.013291546755409153\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.018708872369357518\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.012742866000609242\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.018771904653736522\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.012346872250909788\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.018761558937174933\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.012132135111104399\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.018785161791103226\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.012047076013183942\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.0188034823430436\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6765914295894512\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.31108723964009966\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.05549330130705367\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020401616607393536\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.024236090319312138\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019129130191036632\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.022437147539702877\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.018941330217889376\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.021947426060079666\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.023389515333942006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 5, train_loss: 0.02170131270490263\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017875923136515277\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.02016440733079461\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018000720707433564\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020089040793802426\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018102311742092883\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.019755187066460865\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017560768739453385\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.019749720972301304\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017824135534465314\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.01983052585273981\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01815195424216134\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.019798467867076397\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017938031016715934\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.019792323689097942\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017991009620683535\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.01990306967248519\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.018088809081486294\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019849621987753155\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018203917518258096\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.019894430265370487\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.018135743561599936\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.0199506267959225\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.018182838016322683\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.019976152336575848\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.0179762191804392\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.020000193052101826\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01780975285385336\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.02005618416528771\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.018132881367845195\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.020076286142179066\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.017941187535013472\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.02001734474754852\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.017967949914080756\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.019967984219176182\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018174623857651437\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.02000426348514747\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01780991242932422\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.019978220061655495\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01818862118359123\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.02002543055762847\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.018169260903128554\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01984971538995919\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.018069180846214294\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.019831873355028423\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.017977627047470638\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.019808672692464745\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.018064572821770396\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.019701732471045376\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.017804259780262198\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.019577395170927048\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.017678409894662243\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.01943171638455512\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.01773671734013728\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.01929393762965565\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017825601595853058\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.01910769924575436\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017548836741064278\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.01888983783757557\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.017709435309682574\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.018613831801474957\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.017601408463503634\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.018386354737415695\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.01766695808619261\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.01805780562099771\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.017527479013162\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.017711016686930172\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.01750224166150604\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.017253250241333593\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.017731159340058054\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.016760409222510847\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.017588746920228004\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.016247975538768198\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.017634124841008868\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.015656038261680067\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.017777636886707374\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.014981670149912437\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.017804288704480444\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.014321428399695002\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017868981776492935\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.013676948453961075\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.01783730826739754\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.013150797630457775\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.017918794016752924\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.012767013587543497\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.01789336039551667\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.012519744224846363\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.01798391935548612\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.012429437093922625\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.017962590897721904\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6748077806787215\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.3135181709247477\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.054605646841767906\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01997580790125272\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.024287929893403813\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01884991127778502\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.024260603728285736\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018154226544806185\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.021778954759888027\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017895652939948964\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.020692521922182346\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017530746237539193\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.02068231793363457\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017441002679440903\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020054976563846718\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01771270064637065\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.02000483232077913\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01739266251816469\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01982700480553119\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017402206903652233\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.019822354414972706\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017323736977927825\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.019912946010953274\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017518517479081366\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019929726162682408\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017668365418691847\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.01991280322165593\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017421020030537072\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.019990344045926697\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.0175069162129041\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.020098419994979664\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017753703957971406\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.020122250663521496\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017734803314156392\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.0201223389097098\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.018043591805240688\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.020202908125044643\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017415254568571552\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.020140044863565243\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01796232065295472\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020113602928493336\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017542379990439203\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.020174443991719814\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01751114326693556\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.02016897692574539\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01747542537529679\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.02004834083651287\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017717144397251746\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020128214745309906\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017795334433150643\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.02008672945363366\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.017718428855433184\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.02002872764200404\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.017636016038629937\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.019953134280723938\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.017451318610897836\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.019899070276406364\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01768924484905951\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.019746621098855267\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.017479127985151374\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.019661561518475628\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.017363752101493234\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.019515297821034557\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.017492167925571695\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.019338411953894123\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.017352410975624535\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.01925143479383078\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.0173987422741073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 34, train_loss: 0.01903677297135194\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.01735223750309909\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.01882965168983176\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.017248539911473498\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.018544355920259502\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.017261099152486113\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.018242018972186073\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017205150304910016\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.017937919617617044\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.017384942100547692\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.017513434483629207\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.017280646736788398\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.017073391194360844\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017315109013853705\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.016554407498704782\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.017261113834512586\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.01594383211509473\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.01729267942445243\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.015344669104324303\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.01732677188428009\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.014688303977574991\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.01738358584835249\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.014126466323986002\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.017376153894207057\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.013641144749640987\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.017407198902219534\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.0132724288041177\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.01738796763889053\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.012984414672667997\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.017425622051472172\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.01294119596697282\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.017430049011155087\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6755610021992006\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.315274578332901\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.05474330150130866\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020071565679141454\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023721260909477005\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.022872271282332286\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.023626538155519444\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.019028395973145963\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.024486401847199253\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.042574358518634524\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.02657509635648002\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01951841451227665\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.022306483954299187\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01881483771971294\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.021471284046445206\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01877466371016843\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.02123163250423428\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.019925088967595782\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.02110012775907914\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01821878387459687\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.02076385330165858\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01845210093472685\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.020582641609876915\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01876557203275817\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.020529940994321438\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.018174284191003868\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.020495767705142498\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.0181920502068741\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.020390624477379563\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.018249130328851088\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.02046053073760392\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.018260960839688777\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.020396105459202892\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.018478264899126122\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.020294472656172256\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.018258777952619962\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.020351298517830994\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.018429323019725937\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.020269880989107533\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.018719661980867386\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.020287103154629036\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01859391459396907\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.02022494845416235\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01800942729626383\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.020261724506491337\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01810256532792534\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.0202480001591038\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.018275856359728743\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.02009726555991\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.018025731109082697\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.020167208047232765\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.018185092668448175\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.02004944855698209\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.01794171684554645\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.019946835435710956\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.017966287503285067\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.019835757840748713\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.017844945139118603\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.019760353841643402\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.018135964923671314\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.019756923402673092\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.017847280097859245\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.019526679068803787\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.017882414082331318\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.019382436206375343\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017824478607092586\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.01924690435492042\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.01808414209101881\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.01915108373361653\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.017642702987151485\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.018882735227437122\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.017615722598774093\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.01863961777501348\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.017646517737635543\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.018315783445385918\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.017809993188296045\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.018041771694855845\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017822872341743536\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.017771052662283182\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.017767066322267055\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.01735051398071042\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.01766143584890025\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.016907967674289492\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.01769782134464809\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.016375758712166462\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.017665414166237625\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.015929021676867338\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.017751271969505718\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.015231005962182215\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.017803907953202726\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.014710372070903364\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.017756210959383418\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.014227206447580154\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.01788462224815573\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.013797125522641169\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.017845324905855314\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.013548715694712988\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.01788013997886862\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.013449297030118929\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.01789956534547465\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6769502165092938\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.3143006409917559\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.05400611229402864\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.021749355271458624\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.02402633492011523\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.023289717840296882\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.022238054650201313\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.019762735600982392\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.021338410014151665\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.022691168077290057\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.020395685378732025\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018826529676360743\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01969556499650513\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.019178716678704535\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.019563530868702175\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01911687222974641\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.019425269999149918\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.019274312390812804\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.019386380033540554\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.018983603907482965\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.019369644720269287\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.018835027595715863\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01945186660800507\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.019285506808332034\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.019508763850815056\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.019059323625905174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 13, train_loss: 0.019470083621748978\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.019011588234986578\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.019514511258381863\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.018787083136183876\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019662817481203354\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.019036832052682126\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.019757923886071945\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.018857442694050926\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01971726879423511\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.0191289575238313\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.019751283596607223\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01887447562600885\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.019752178354647713\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.018953311310282776\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.019821188142658142\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.019640945589968137\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.019780685288318688\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.018830265903047153\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01974987275088611\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.018996240331658296\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.019777923538956955\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01874536502041987\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.019680164133509\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.018901560349123818\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.019627538644641205\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.018717227397220475\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.019573091050151033\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.018923851874257838\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.01959778731553883\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01894879623183182\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.019424006099934162\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01894619997058596\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.0194581875955497\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018868488898234708\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.01931149619159059\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.018726187891193798\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.01913243456595186\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.01873858387448958\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.019016681819398334\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.01856380392398153\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.018837897808871407\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.018759773964328427\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.018551880979667538\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.01860978723104511\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.018364859886629427\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.018558854290417263\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.018104001751466505\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.018345555689718043\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.017887831490108932\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.018791121377476624\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.017469789265938427\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.018553329738123077\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.016983112677985777\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.018559844020221913\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.016522180262035217\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.018556045474750656\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.015951247217700533\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.01859820918845279\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.015362601848724096\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.018830329765166555\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.014626921012835659\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.018765231621052536\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.013989236347539269\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.01886377315968275\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.013362067576119865\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.018929272118423667\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.012794878057109705\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.018962094054690428\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.012393507283126963\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.01896017717995814\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.012186489162453707\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.01897001958319119\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.012043057630459467\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.019010218339306967\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6779513335140952\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.3181059300899506\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.05607732665473527\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.0211168500993933\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02370245242151466\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.019797792711428234\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.023449134978934798\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.021319181738155227\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.023282355866836805\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.018680325097271373\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.021208471815734015\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.019010784476995467\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020318416171591646\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.018279406960521424\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.019879260134414163\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.018469222156064852\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.019637009088140336\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01856192834675312\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.019540752807672878\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.018403399496206216\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01956390473910057\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.018273297271558218\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.019495414420418494\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018512660477842603\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01954195772154923\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01887469408767564\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.019612161034758945\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01862183271774224\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019648006552979894\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.018466855585575103\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019692397656014365\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018645492568612098\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01969399063909141\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01865772966827665\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.019764789985152926\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01870910860598087\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.0197826567901312\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.018951629368322235\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.019820009229065728\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.019113263487815856\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01981516239525628\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.018384635501674244\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.019836117465891978\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.018592530701841626\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.019802750706890204\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01851066915052278\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.019808314890213258\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018451640169535363\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.01969340685619055\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.018425675109028816\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.019754474601932685\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.018525465471403938\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.019679432095837418\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.018528687847512108\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.019599197214863598\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.01857573741248676\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.01950640662362541\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.018366154496158874\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.019399469113317285\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.018350205410804066\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.01929747910123237\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.018480176318969047\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.01920793138879494\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018277638112860067\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.018917792007653384\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.01848880143037864\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.018714672063280195\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.018344373255968095\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.01852430660875827\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.018234872525291785\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.018349226530179057\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.01809635077204023\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.018042808779290993\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.018437328668577332\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.01770294163321709\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.01821655801364354\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.017363847614041646\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.018433989797319684\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.016825045526952204\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.018533139995166235\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.01632243124972077\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.018372307771018573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 41, train_loss: 0.015757827808822157\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.018604112256850516\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.014999902032206964\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.01867970430425235\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.014236205549788302\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.018709572457841463\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.013511823565039757\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.01872632530118738\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.012868109349514881\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.01885780692100525\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.01229229740064292\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.01886797323822975\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.011869693453675204\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.018915297197444097\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.011620414266566726\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.01892669030598232\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.01153530895601224\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.01896680582846914\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6762483556201493\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.31044076425688605\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.054134717359598995\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020709183226738658\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023802080799056137\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019802167053733555\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.02318478074680636\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.026611371710896493\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.02221408242062814\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018446487108511583\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02064713623806618\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01771178088550057\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.01979436993976866\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.01803167143038341\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.01967185557536457\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01862138919532299\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.02030470961893814\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017851494571992328\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01974414536000594\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01765204000153712\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.019685672461122707\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017846976619746005\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.019757475933410984\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01792830431035587\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.019767862197983523\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01800594891288451\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019786914540589718\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.018024590771113125\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019839593344300552\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017905641719698905\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01990611903855334\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017975426438663688\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.02002474232374326\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017936004671667304\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.020015212437272934\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.018290337707315172\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.019996312001477116\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.0179507921316794\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.01999589339222597\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.018195674461977823\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.019992807434628838\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.018113806444619383\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.019990398831989453\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.018488584857966218\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.02003870944937934\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.017921668610402515\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.020040898165409115\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01827143223157951\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.020024148436884086\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018062505019562584\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.019933733198305836\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.017973537210907255\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01982691635688146\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01802539617887565\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.01979358676497055\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.017765597626566886\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.019734313266108864\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.017900145825530803\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.0195899603591449\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.017834187112748624\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.019552915235576424\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.017885460864220347\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.019482157490067722\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.017816590012184212\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.01924202742352002\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017839018734438078\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.019069845018827396\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017678320141775266\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.018998760925740866\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.01765145819102015\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.018640860091840874\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.01772290494825159\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.01843068949824226\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.01763020892228399\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.01809199636910057\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.01769409081233399\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.017658439431123545\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.017509285200919423\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.017355062168739412\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.017688861223203796\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.01683627566376674\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.01763104341392006\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.01626753541843399\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.0174889385966318\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.015656439499740583\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.017754196375608444\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.014987820617692627\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.017781894813690868\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.014310870245369017\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017861763068607876\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.01365985943382417\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017900451458990572\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.013133089159331892\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.01789657659828663\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.012760510701902103\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.01799205363328968\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.012531935412814652\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.017957747887287823\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.012417470212971819\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.017940233541386467\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6774929919536563\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.32278556946445913\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.054336660906024604\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.019582665087107348\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.023881008956527363\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01865121185341302\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.023201200301232544\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017975081854006824\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.022786775752362133\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017785487066516104\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.021826691763556522\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017801449798485813\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020683263522991234\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01754958081223509\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020069165249773556\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017318678088486195\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.020054901896071606\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01741430861875415\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.019890598736811375\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017824394984499496\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01993711620731198\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017504472504643834\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.019927112723066322\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017395956688286626\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019993189816781574\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017583037507446372\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.020025746491940125\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017584197387537536\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.020006168863155704\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017591373721028074\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.020128681661858074\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017818473991664016\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.020131273397608944\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01758464631241034\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.020125541957500187\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017821819055825472\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.020107608463993107\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017468450317049727\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.02011864033082257\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01771948650917586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 20, train_loss: 0.02014535635817742\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017609353423775995\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.02019441513803558\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017575977397534776\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.020180090020100277\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01774791644557434\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.02008703672259614\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017794334904893357\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020148488449985565\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017531400190337616\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.020082098620849243\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.0175291559768512\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.020047549509267876\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.017727662699625772\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.019954579531390598\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.017426974550985238\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.019866980774247128\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.017947769312955\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.019843041842830353\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.01734959742273478\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.019682611284804516\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.017264708383556676\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.019544660815618176\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.01729192121830933\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.01937686175485884\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.017482675310662565\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.019234796540568703\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.017395056674585622\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.01908170919109514\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.01768641351886532\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.018816835327964763\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.017278675482991862\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.018496660873347868\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.017399203388349098\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.018219716738963474\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017238127451170895\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.017805680598847677\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.017382069162147885\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.017489498440662155\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.017220129176755163\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.016965334573625656\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017275884391411263\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.016455011253339657\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.017387069049565232\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.015837326173441135\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.017386280876748702\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.015120927426640106\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.017412729479153368\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.014477036650414053\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.017368893330807194\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.013828813469550316\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.017382671180016854\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.013275229358586712\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.017435556524159276\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.012881451853267525\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.017417027286308652\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.012599824637552534\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.01743764879510683\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.012508899891290112\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.01742663757656427\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6777634329122045\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.31093047857284545\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.05511358790639518\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020491314200418335\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.02396014442100473\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.02249575757554599\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.023381264974781567\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.029872149708015577\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.0234935629060087\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.022429726805005754\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.021811613556591496\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.019687347007649285\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020889605584459892\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.018815263413957187\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.020525357186578323\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01796312050095626\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.019916895399059074\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017951817358178752\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01981618069112301\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018119508560214725\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.019935876360514027\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01866871759827648\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.019934251459072464\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.018541182737265315\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01995094012523043\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.018184169355247703\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.01992876236529454\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.018308137304016522\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.019956628630018753\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01876264682837895\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.019943093705544437\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.018387184105813505\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.02000000065975431\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.018129197055740016\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.02000641385498254\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.018072718621364663\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.020095155020986778\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01832880662488086\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.020039518903670967\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.018291955015489032\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.020090027185885803\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.018728227274758476\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.0200828834693285\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.018291557686669485\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.01995298625442429\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.018086209733571324\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.019957240191760702\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.018265281644250665\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.020008136558791866\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01809432708791324\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.019832250149245712\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.017991775487150464\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.02000173678000768\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.018213889082627638\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.019869414860031742\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.018317584640213422\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.01973364822080602\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.017980073073080607\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.01970473024994135\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01788238324224949\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.019538302109509274\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.017928197979927063\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.019291812392032665\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.017865474256021637\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.019192523626691622\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017980537457125526\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.019102635266988174\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.017701403929718904\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.01892137746124164\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.017793197158191887\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.01869441706525243\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.018013002670236995\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.018462538125290386\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.01765565930732659\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.018203595707166023\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.01764115872127669\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.01770382319185613\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017802653514913152\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.01740878951344369\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.017531950319451945\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.016874175849438146\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.017760513616459712\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.016389774084361135\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.017611458232360228\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.015858456431685583\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.01783799095345395\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.015121607710539864\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.017764649779668875\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.014523279596714006\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.01783567565892424\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.013937160588692928\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.017840928717383315\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.013470164803869051\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.017935911432972976\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.013072836732464855\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.018000640134726253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4, EPOCH: 48, train_loss: 0.012831644094346659\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.018064929199005875\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.012753013298725304\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.017985009614910397\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.675166663484297\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.2995499449116843\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.054272661484993885\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02139638103544712\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023486029910112637\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.023408527033669607\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.02285077417458313\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.019832041966063637\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.021299422556615395\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.03627440519630909\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.02287986507450325\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01945325072322573\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.020445218282765236\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.018883735686540604\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.02007048246383235\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.019273293976272855\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.019750492708028658\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018918451347521372\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.019670733763579872\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.018930221109517982\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.019676948587099712\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01880115917218583\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.019693370881503906\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.018855719827115536\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.019586115738080032\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.019272347326789584\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.019651048992207085\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.018909026682376862\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01969729745895534\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.019181507054184165\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.01982812179873387\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.019163792873067517\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.019737380232823933\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.0188168464494603\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01981858033146979\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.018871882770742688\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.019781443776319855\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01900656401578869\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.019790798965571583\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.018962538135903224\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.019762725177882374\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018755053728818895\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.019783455811009026\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.019008678596998965\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.019773249433416386\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.019053131953946183\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.019780716575358227\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.018946372132216182\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.019776724778331707\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.018860944360494614\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.019757040492866352\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.01894933772938592\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.01958332563062077\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.01883140437837158\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.01965736030884411\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01898440143891743\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.019492882337637137\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.018690596973257406\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.019376149630524975\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018718007020652294\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.01924671328532091\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.018755394566271986\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.019147766808020897\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.018773761019110678\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.019026354063248287\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.018778668849595954\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.01888635716792466\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.018606419914535113\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.018724724366936996\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.01863164601049253\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.01837567590932915\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.01857237536460161\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.01813150464516619\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.01837699945483889\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.01786802318352072\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.01854151218597378\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.017496707194579252\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.018601938017777035\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.017137886079001255\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.01863599523369755\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.016620740395687197\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.01849635536117213\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.016000504214046658\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.018704670986958914\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.015448542399520891\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.01854284642530339\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.014725984857026218\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.018777493999472688\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.014082096429352743\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.0187347891873547\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.013466041116718796\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.01882515594895397\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.012932344926926105\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.01882927553462131\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.01251140239554039\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.018881392212850706\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.012272503442954327\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.01886826955846378\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.012178432061404421\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.018909760378301145\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6774537082571183\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.3195808257375445\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.055496040391769724\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020649263156311853\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02376840426756518\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.019335049976195607\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.023702559788731762\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01914302674787385\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02136651607379861\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.018974917701312474\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.019917643323105617\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.018221467626946312\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020339278028394185\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01847393193415233\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.019715697484186095\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.018665521112935884\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01944834467050803\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.018203136484537807\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.019367725309664314\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.018999023256557328\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.019414914839894232\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.018607250547834804\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.019521646296782214\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01865657690380301\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.019545548615881998\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.018485598851527486\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01955837377068335\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01884551788015025\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019577785932125835\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.018539556009428842\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019694600417448655\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018714301394564765\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01975473051849943\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01868306307920388\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.019735659003584056\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01873375145452363\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.019819147300219882\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.0184704616399748\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.019828245900299427\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.018435481456773622\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.019843143227435377\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.018495096692017148\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01984797554077023\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.018691341312868256\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01983060879483275\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.018449486419558524\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.019854139740558437\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018622065441949026\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.01974918345247742\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.018660774507692882\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.01966850485407958\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.018311938696673937\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.01969665551327006\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.01867307014763355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 27, train_loss: 0.019651643646350744\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.018452953600457737\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.01949085144285303\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01855756076318877\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.01937561376142676\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.01829811999840396\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.019268990514704782\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.01849545905632632\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.019183122627709034\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018400405773094722\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.019049808450967726\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018400150431053978\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.018854111772927926\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.01835743673145771\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.018618911572725234\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.01814040185085365\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.018400672218170915\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.018616147924746786\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.018122325304650914\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.018350180823888097\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.017781319375401432\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.018350859438734397\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.01740051350508728\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.01835765963686364\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.01691577533246392\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.018397809405411993\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.016430099991007443\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.01844173999769347\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.01581460270133332\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.01864674160523074\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.015138722242393198\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.018543557077646256\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.01443984955005402\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.01865517044706004\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.013710450782121098\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.018803429284266062\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.01308178040368931\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.018782484052436692\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.012537645502355846\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.018866634528551782\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.012124560467463776\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.01887391869510923\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.011931397517068978\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.018898750149777956\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.011825240659017633\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.018905796110630035\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6762761376474214\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.3065630435943604\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.05483933713665043\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019890714064240457\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023616783860800922\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.02065517966236387\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.022964985906213955\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01855379571872098\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.02199130124695923\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018224059524280686\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02050934484957353\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017718680282788616\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.019911107094283554\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017607116805655614\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.019846013774150524\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01769793765353305\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01963303790198288\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01790593641677073\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.019702728621769642\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017762530728110244\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.019697427709141502\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017797367727117878\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.01971600226302078\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017745431539203438\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01973113096386626\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018196887815637247\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.0197409192721049\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.018446287140250206\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01988688440642495\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018035750037857463\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.019908358572401863\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.018076759789671215\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.019903567808585754\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01808700231569154\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.019933835427830185\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.018155342899262905\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.019965000342631687\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.018016573786735535\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.020019989244747852\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01775604100631816\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.02003461418106504\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01806794644466468\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.020004865065540955\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.018003770549382483\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.020040402863768562\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.017941969579883983\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.019951388536803963\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.017951042018830778\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.020052965743926125\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018197064474225044\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.019863829678059487\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.018023634515702724\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.019790810667842194\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.017756333388388158\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.0197458582241898\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.0178612031308668\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.01971971062079504\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.018035772229943958\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.019678097555710785\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.017740193089204177\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.019472166396461536\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.017680692273591245\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.019405072743909946\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.017440863139927387\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.01928990469246671\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017645741812884808\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.01905063714535124\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017401615902781487\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.01885568139993626\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.01759859054748501\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.01859185407343118\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.017630011907645633\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.018353243169469246\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.017463928434465613\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.018047055236293352\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.0174737347556012\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.017652033241060766\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.01751123634832246\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.0172589893952228\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.01745712887495756\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.0167804602128656\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.01754946732627494\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.016215229845619288\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.01769129184207746\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.015633569375706324\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.017744004699800697\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.014960740294739388\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.01767498395804848\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.014245771296808252\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017833600352917398\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.013652168781213139\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017859331145882607\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.013151598581369373\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.017910229813839707\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.012815121203606976\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.01792830830173833\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.012543355661403873\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.017908340798957006\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.012440594048171804\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.017909820803574155\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6765947549239449\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.31703047892626596\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.054344955845263554\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020173831788056037\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.023856467553886814\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018609216217609012\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.02288037600616614\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.0180252613773679\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.020992987141337082\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017251735854455653\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.0200851134200027\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01728053656680619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 6, train_loss: 0.019907911254120045\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01745713658302146\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01990327922006448\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01758488656624275\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.019684335041413273\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017679646748172885\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01957848433243192\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017774593249401626\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.019658338494490887\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01735991403898772\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01972248498350382\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017429772737052512\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019736933805372402\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01747547514627085\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.019845070006946724\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.0176958518979304\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.019943354921280475\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01761919301112785\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.019917824319091396\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01767862421076964\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01998911715666021\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.018082086763837758\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.020166754506636356\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017667185241246924\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.020042972909151646\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017598053440451622\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.02004714806874593\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.017638408058487317\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020179397858463337\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017399524393327096\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.020082415257027184\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017739177626722\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.02006588603599348\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017748802242910162\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020095679868498573\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017532537663903308\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020103153786149578\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017714572659529308\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.020060667592654194\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.01746206985348288\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.019967243709749935\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.017732548801337972\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.019926344786865124\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.017603016814545673\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.01986281764086174\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.017790380974902827\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.019715877371313778\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.017519928268430865\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.01955567101907471\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.0174060980515445\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.01949494742396949\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.01721686458982089\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.0192760835280237\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.017372962580445933\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.019195543541370527\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.017519970561432487\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.019005080766004066\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.017359884510583738\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.01876290355120664\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.017517860376221293\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.018508112786904625\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.017419738722417283\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.01813357849807843\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017451727105414167\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.017811435160051653\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.01732468668042737\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.017357690104593832\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.017386676277965307\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.016893327897549538\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017302888034678558\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.016295468421194\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.017283434322213426\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.01574376645916398\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.017384412616272184\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.01499491971175092\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.017332385978935397\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.014334203844107147\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.017454183304353672\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.01373643994304365\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.017418752260067883\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.013185896566542595\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.017387642114258865\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.01279843040485529\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.017427361707257873\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.012590611690952293\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.01744966271936017\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.012515994261248388\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.017477123943321845\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6765633815008661\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.3403767330305917\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.05433670674329218\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.021156473138502666\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.024010764178482517\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.019548257333891733\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.022635464178587215\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.02046571874192783\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.022496853968587475\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018375501010034767\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.020392472302352173\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.02049584537744522\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020143617066028324\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017828316268111977\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.019840336269766525\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.018278589019817965\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.01982653030342814\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.018090268171259336\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.019804822739915573\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01818548941186496\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.019699384107429913\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01860389948955604\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.019831030508098396\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01807800547352859\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.019798573066035042\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.018473881110548974\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.019708370344470375\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01843020280024835\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.0198501142659697\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01926276114370142\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.020085261689256066\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.018035035553787437\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.019932927995704224\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017785254599792615\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.02004384350679491\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.018358712191028255\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.020099134116932964\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.018614003168685094\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.020087752207789734\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.018323419163269655\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.020010616232141638\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01798288013253893\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.019968925232904545\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.018175861212824072\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.02004566212333199\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.018236152322164603\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.020053985353181328\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.018009323147790773\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.020029433071613312\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.018306431573416507\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.02000084163054176\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.01828108754541193\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.019841738328661606\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.01822601311973163\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.019819629324627094\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.018100876680442263\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.019651439088140276\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.01801700879420553\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.019570556766205074\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01803980248847178\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.019547141562013523\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.018066254417811123\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.01943591453027034\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.017904069993112767\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.01923809052053569\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017725673876702784\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.019088764438756567\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.017844258701162678\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.01883705087222051\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.01802957539579698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4, EPOCH: 35, train_loss: 0.018623976617295673\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.017822241969406606\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.018413183697755787\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.017630799008267268\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.018125555383554405\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.017942858806678227\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.01769485195720757\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017720654074634825\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.017275539503527292\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.017820251653237\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.01687312984596128\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.017781148398561136\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.01630286142176044\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.017799791267939975\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.01571030067819832\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.017827174812555312\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.015036994375396465\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.017756720978234497\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.014417102762862392\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.017851134575903416\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.013817857309797968\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.017924933082291056\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.01326681072216319\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.017935279171381678\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.0129096744298611\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.017891623292650496\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.012612472538012957\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.017962525545486382\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.012530800292565338\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.017991659604012965\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\\n       'acat_inhibitor', 'acetylcholine_receptor_agonist',\\n       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\\n       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\\n       'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist',\\n       ...\\n       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\\n       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\\n       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\\n       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\\n      dtype='object', length=206)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-57f6ff99c54b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2933\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2934\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2935\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2964\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2965\u001b[0m                 indexer = self.loc._get_listlike_indexer(\n\u001b[1;32m-> 2966\u001b[1;33m                     \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2967\u001b[0m                 )[1]\n\u001b[0;32m   2968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\\n       'acat_inhibitor', 'acetylcholine_receptor_agonist',\\n       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\\n       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\\n       'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist',\\n       ...\\n       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\\n       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\\n       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\\n       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\\n      dtype='object', length=206)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0,1,2,3,4,5,6] #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "pred1 = np.load('moa_oof_01844.npy')\n",
    "pred2 = np.load('model_oof_01840.npy')\n",
    "pred3 = np.load('moa_oof_01858.npy')\n",
    "pred4 = np.load('moa_oof_xgb.npy')\n",
    "pred5 = np.load('model_newcv_oof_01835.npy')\n",
    "pred6 = np.load('moa_oof_newcv_01844.npy')\n",
    "pred7= np.load('moa_oof_newcv_01858_opt.npy')\n",
    "\n",
    "pred8 = np.load('model_newcv_oof_01835.npy')\n",
    "pred9 = np.load('moa_oof_newcv_01858_7folds.npy')\n",
    "pred10 = np.load('moa_oof_newcv_01838_7folds.npy')\n",
    "pred11 = np.load('moa_oof_newcv_01858.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.45717721e-03, 1.35532549e-03, 8.05951970e-04, ...,\n",
       "        1.64518212e-03, 3.17708929e-04, 1.98489587e-03],\n",
       "       [2.96254625e-04, 4.14825874e-04, 1.65013833e-03, ...,\n",
       "        2.28889545e-03, 3.75037021e-03, 3.05411140e-03],\n",
       "       [1.71655422e-03, 1.96005346e-03, 6.99006123e-04, ...,\n",
       "        1.34017773e-03, 1.94973886e-04, 1.06534110e-03],\n",
       "       ...,\n",
       "       [4.47388428e-04, 5.07364375e-04, 2.09519803e-03, ...,\n",
       "        1.27740188e-03, 9.25638009e-03, 2.40041744e-03],\n",
       "       [3.89067912e-04, 4.29120133e-04, 3.46576999e-04, ...,\n",
       "        3.40592320e-04, 1.82173591e-04, 6.86126863e-04],\n",
       "       [4.97435224e-04, 5.07766864e-04, 7.50074915e-04, ...,\n",
       "        5.78129455e-04, 7.74010126e-05, 2.08420327e-04]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[target_cols] = (pred8 * 5 + pred11 * 2 + pred9)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00178458, 0.00145417, 0.00095003, ..., 0.00175713, 0.00058458,\n",
       "        0.00162759],\n",
       "       [0.00127926, 0.00110549, 0.00242534, ..., 0.00381091, 0.00153891,\n",
       "        0.0031033 ],\n",
       "       [0.00179724, 0.00240839, 0.00141167, ..., 0.00124529, 0.00061229,\n",
       "        0.00223328],\n",
       "       ...,\n",
       "       [0.00071043, 0.00117841, 0.00432172, ..., 0.00228528, 0.00329333,\n",
       "        0.0029959 ],\n",
       "       [0.0007111 , 0.00068154, 0.00064038, ..., 0.00043908, 0.00069466,\n",
       "        0.00098637],\n",
       "       [0.00054111, 0.0010432 , 0.00138893, ..., 0.00097929, 0.00055558,\n",
       "        0.00106453]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.015510270095556066\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_metric(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for _target in train_targets_scored.columns:\n",
    "        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels = [0,1]))\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in target_cols:\n",
    "    test[i]=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.load('moa_01844.npy')\n",
    "pred2 = np.load('model_newcv_01835.npy')\n",
    "pred3 = np.load('moa_01844.npy')\n",
    "pred4 = np.load('model_01840.npy')\n",
    "pred5 = np.load('moa_01858.npy')\n",
    "pred6 = np.load('moa_xgb.npy')\n",
    "pred7 = np.load('moa_newcv_01844.npy')\n",
    "#np.save('moa_oof_newcv_01858',oof)\n",
    "\n",
    "pred8 = np.load('moa_newcv_01858.npy')\n",
    "\n",
    "pred9 = np.load('model_newcv_01835_7folds.npy')\n",
    "pred10 = np.load('model_newcv_01835.npy')\n",
    "pred11 = np.load('moa_newcv_01858_7folds.npy')\n",
    "\n",
    "pred11 = np.load('moa_oof_newcv_01858_label.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('moa_oof_newcv_01838_7folds',oof)\n",
    "np.save('moa_newcv_01838_7folds',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.10278240e-03, 6.82594264e-04, 1.19356830e-03, ...,\n",
       "        1.54084741e-03, 2.05626534e-04, 1.37703803e-03],\n",
       "       [4.42528811e-04, 5.94025032e-04, 1.21270533e-03, ...,\n",
       "        2.35788353e-03, 1.52770092e-03, 3.52004101e-03],\n",
       "       [1.20766341e-03, 1.49467286e-03, 6.83186440e-04, ...,\n",
       "        3.10085644e-04, 2.16352449e-04, 8.38998438e-04],\n",
       "       ...,\n",
       "       [6.28481503e-04, 8.00978810e-04, 2.28777167e-03, ...,\n",
       "        2.62276130e-03, 2.43461723e-03, 3.83292825e-03],\n",
       "       [2.17310975e-04, 1.92161797e-04, 4.54758270e-04, ...,\n",
       "        3.91382387e-04, 2.26230154e-04, 4.60107481e-04],\n",
       "       [4.39636961e-04, 7.01002098e-04, 5.53188666e-04, ...,\n",
       "        4.54896814e-04, 9.08720964e-05, 3.88511750e-04]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target_cols]=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00115784, 0.00141058, 0.00380903, ..., 0.00219696, 0.01388766,\n",
       "        0.00216653],\n",
       "       [0.00088531, 0.00112943, 0.00178357, ..., 0.0016953 , 0.00121521,\n",
       "        0.00259553],\n",
       "       [0.00137658, 0.00127005, 0.00187087, ..., 0.00196184, 0.00109692,\n",
       "        0.00234351],\n",
       "       ...,\n",
       "       [0.00169075, 0.00122805, 0.00113446, ..., 0.00157153, 0.00063667,\n",
       "        0.00161928],\n",
       "       [0.00223496, 0.00143427, 0.00143444, ..., 0.00240236, 0.00094376,\n",
       "        0.00353015],\n",
       "       [0.00090402, 0.0012361 , 0.00144127, ..., 0.00230748, 0.00088142,\n",
       "        0.00193124]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission_25_11_2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.016010</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.006694</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.006214</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.022603</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>0.017298</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.006136</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.146953</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.013573</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.001113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>0.021460</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.001875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>0.035949</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.029621</td>\n",
       "      <td>0.028549</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.006328</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.003530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.014669</td>\n",
       "      <td>0.016592</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.001931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001158                0.001411   \n",
       "1     id_001897cda                     0.000885                0.001129   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001377                0.001270   \n",
       "4     id_0027f1083                     0.002491                0.001491   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001151                0.001213   \n",
       "3978  id_ff925dd0d                     0.004390                0.002331   \n",
       "3979  id_ffb710450                     0.001691                0.001228   \n",
       "3980  id_ffbb869f2                     0.002235                0.001434   \n",
       "3981  id_ffd5800b6                     0.000904                0.001236   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.003809                        0.016010   \n",
       "1           0.001784                        0.002563   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.001871                        0.011482   \n",
       "4           0.002126                        0.019063   \n",
       "...              ...                             ...   \n",
       "3977        0.001232                        0.001703   \n",
       "3978        0.001147                        0.007570   \n",
       "3979        0.001134                        0.012340   \n",
       "3980        0.001434                        0.029621   \n",
       "3981        0.001441                        0.014669   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.014587                        0.003848   \n",
       "1                              0.001704                        0.001912   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.019169                        0.005683   \n",
       "4                              0.017298                        0.003556   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.006136                        0.002078   \n",
       "3978                           0.021460                        0.006598   \n",
       "3979                           0.035949                        0.006084   \n",
       "3980                           0.028549                        0.006522   \n",
       "3981                           0.016592                        0.005466   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002600                       0.006484   \n",
       "1                       0.007053                       0.006694   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.003351                       0.004011   \n",
       "4                       0.005589                       0.002137   \n",
       "...                          ...                            ...   \n",
       "3977                    0.000898                       0.001514   \n",
       "3978                    0.005212                       0.003664   \n",
       "3979                    0.003588                       0.003468   \n",
       "3980                    0.006328                       0.003200   \n",
       "3981                    0.002347                       0.004346   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000710  ...                               0.001353   \n",
       "1                       0.007641  ...                               0.001199   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.000631  ...                               0.001053   \n",
       "4                       0.000955  ...                               0.001430   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.000527  ...                               0.000830   \n",
       "3978                    0.001059  ...                               0.000928   \n",
       "3979                    0.000538  ...                               0.000970   \n",
       "3980                    0.000787  ...                               0.001060   \n",
       "3981                    0.000492  ...                               0.001032   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001472         0.006305           0.001744   \n",
       "1         0.001292         0.006214           0.001119   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001324         0.003028           0.022603   \n",
       "4         0.000966         0.003337           0.002487   \n",
       "...            ...              ...                ...   \n",
       "3977      0.004818         0.001818           0.146953   \n",
       "3978      0.001362         0.003895           0.003344   \n",
       "3979      0.000825         0.003330           0.001697   \n",
       "3980      0.000859         0.002755           0.002374   \n",
       "3981      0.001542         0.002233           0.008121   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.000909                               0.001119   \n",
       "1                      0.011754                               0.001107   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.004680                               0.001113   \n",
       "4                      0.002143                               0.001215   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.006884                               0.001322   \n",
       "3978                   0.003401                               0.001317   \n",
       "3979                   0.001604                               0.000919   \n",
       "3980                   0.002036                               0.001006   \n",
       "3981                   0.001795                               0.001137   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.000851   0.002197                    0.013888       0.002167  \n",
       "1            0.020860   0.001695                    0.001215       0.002596  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.002146   0.001962                    0.001097       0.002344  \n",
       "4            0.001660   0.001963                    0.000591       0.002316  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.013573   0.001566                    0.000777       0.001113  \n",
       "3978         0.003540   0.001936                    0.000741       0.001875  \n",
       "3979         0.001054   0.001572                    0.000637       0.001619  \n",
       "3980         0.001587   0.002402                    0.000944       0.003530  \n",
       "3981         0.000957   0.002307                    0.000881       0.001931  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model_newcv_01838_5folds', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model_newcv_oof_01838_5folds', oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21948, 206)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
