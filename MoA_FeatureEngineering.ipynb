{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\train_features.csv')\n",
    "train_targets_scored = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\train_targets_nonscored.csv')\n",
    "drug = pd.read_csv('D://Dataset//MOA//train_drug.csv')\n",
    "\n",
    "test_features = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\test_features.csv')\n",
    "sample_submission = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "transformer.fit(train_features.loc[:, GENES + CELLS])\n",
    "train_features[GENES + CELLS] = transformer.transform(train_features.loc[:, GENES + CELLS])\n",
    "\n",
    "dump(transformer, 'rank_1844_5fold.bin', compress=True)\n",
    "\n",
    "\n",
    "test_features[GENES + CELLS] = transformer.transform(test_features.loc[:, GENES + CELLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 600  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "pca_genes = PCA(n_components=n_comp, random_state=42)\n",
    "data2 = pca_genes.fit_transform(data[GENES])\n",
    "\n",
    "dump(pca_genes, 'pca_1844_5fold_genes.bin', compress=True)\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "pca_cells = PCA(n_components=n_comp, random_state=42)\n",
    "data2 = pca_cells.fit_transform(data[CELLS])\n",
    "\n",
    "dump(pca_cells, 'pca_1844_5fold_cells.bin', compress=True)\n",
    "\n",
    "\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1040)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "var_thresh = VarianceThreshold(0.8)  #<-- Update\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "dump(var_thresh, 'var_1844_5fold.bin', compress=True)\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from joblib import dump , load\n",
    "\n",
    "def fe_cluster(train, test, n_clusters_g = 35, n_clusters_c = 5, SEED = 123):\n",
    "    \n",
    "    features_g = list(train.columns[4:776])\n",
    "    features_c = list(train.columns[776:876])\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        #train_ = train[features].copy()\n",
    "        #test_ = test[features].copy()\n",
    "        #data = pd.concat([train_, test_], axis = 0)\n",
    "        #kmeans = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        #dump(kmeans, f'Kmeans_feat{kind}.bin', compress=True)\n",
    "        km = load(f'Kmeans_feat{kind}.bin')\n",
    "        train[f'clusters_{kind}'] = km.labels_[:train.shape[0]]\n",
    "        test[f'clusters_{kind}'] = km.labels_[train.shape[0]:]\n",
    "        #print(test)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features ,test_features=fe_cluster(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 1080) (3982, 1080)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 1080) (3982, 1080)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "\n",
    "#train = train.merge(drug, on='sig_id')\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "\n",
    "def create_folds(num_starts, num_splits, trn):\n",
    "\n",
    "    folds = []\n",
    "    scored = trn.copy()\n",
    "    #targets_ = scored.loc[:, train_targets_scored.columns].columns[1:].tolist()\n",
    "    #train_cols = train_features.columns.tolist() + ['fold','drug_id']\n",
    "    #train_cols = [col for col in train_cols if col!='cp_type']\n",
    "    # LOCATE DRUGS\n",
    "    vc = scored.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc <= 18].index.sort_values()\n",
    "    vc2 = vc.loc[vc > 18].index.sort_values()\n",
    "    \n",
    "    for seed in range(num_starts):\n",
    "    \n",
    "        # STRATIFY DRUGS 18X OR LESS\n",
    "        dct1 = {}; dct2 = {}\n",
    "        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state = seed)\n",
    "        tmp = scored.groupby('drug_id')[target_cols].mean().loc[vc1]\n",
    "        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "            dd = {k:fold for k in tmp.index[idxV].values}\n",
    "            dct1.update(dd)\n",
    "    \n",
    "        # STRATIFY DRUGS MORE THAN 18X\n",
    "        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state = seed)\n",
    "        tmp = scored.loc[scored.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "            dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "            dct2.update(dd)\n",
    "    \n",
    "        # ASSIGN FOLDS\n",
    "        scored['fold'] = scored.drug_id.map(dct1)\n",
    "        scored.loc[scored.fold.isna(),'fold'] =\\\n",
    "            scored.loc[scored.fold.isna(),'sig_id'].map(dct2)\n",
    "        scored.fold = scored.fold.astype('int8')\n",
    "        folds.append(scored.fold.values)\n",
    "        #train_cols = train_feats.columns.tolist() + ['fold','drug_id']\n",
    "        #train_feats_main = train_feats_.merge(scored, on='sig_id', how='left')\n",
    "        #train_feats_main['fold'] = train_feats_main['fold'].astype(int)\n",
    "        \n",
    "    return scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>-1.364787</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>-2.288417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>-0.375501</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.237856</td>\n",
       "      <td>-1.228203</td>\n",
       "      <td>0.218376</td>\n",
       "      <td>-0.365976</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>-0.150978</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>0.735603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>-0.304313</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>-1.622462</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 1286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  1.134849  0.907687 -0.416385 -0.966814   \n",
       "1      id_000779bfc      72      D1  0.119282  0.681738  0.272399  0.080113   \n",
       "2      id_000a6266a      48      D1  0.779973  0.946463  1.425350 -0.132928   \n",
       "3      id_0015fd391      48      D1 -0.734910 -0.274641 -0.438509  0.759097   \n",
       "4      id_001626bd3      72      D2 -0.452718 -0.477513  0.972316  0.970731   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1  0.237856 -1.228203  0.218376 -0.365976   \n",
       "21944  id_fffb1ceed      24      D2  0.209361 -0.022389 -0.235888 -0.796989   \n",
       "21945  id_fffb70c0c      24      D2 -1.911021  0.587228 -0.588417  1.296405   \n",
       "21946  id_fffcb9e7c      24      D1  0.816407  0.417618  0.431631  0.300617   \n",
       "21947  id_ffffdd77b      72      D1 -1.243096  1.567730 -0.269573  1.083636   \n",
       "\n",
       "              4         5         6  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0     -0.254723 -1.017473 -1.364787  ...             0                0   \n",
       "1      1.205169  0.686517  0.313396  ...             0                0   \n",
       "2     -0.006122  1.492493  0.235577  ...             0                0   \n",
       "3      2.346330 -0.858153 -2.288417  ...             0                0   \n",
       "4      1.463427 -0.869555 -0.375501  ...             0                0   \n",
       "...         ...       ...       ...  ...           ...              ...   \n",
       "21943 -0.330177  0.569243 -0.150978  ...             0                0   \n",
       "21944 -0.674009  0.919312  0.735603  ...             0                0   \n",
       "21945 -1.002640  0.850589 -0.304313  ...             0                0   \n",
       "21946  1.070346 -0.024189  0.048942  ...             0                0   \n",
       "21947 -0.511235 -2.099634 -1.622462  ...             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  kfold  \n",
       "0                               0              0      0  \n",
       "1                               0              0      2  \n",
       "2                               0              0      1  \n",
       "3                               0              0      2  \n",
       "4                               0              0      2  \n",
       "...                           ...            ...    ...  \n",
       "21943                           0              0      0  \n",
       "21944                           0              0      4  \n",
       "21945                           0              0      0  \n",
       "21946                           0              0      1  \n",
       "21947                           0              0      2  \n",
       "\n",
       "[21948 rows x 1286 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1285)\n",
      "(21948, 1286)\n",
      "(3624, 1079)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):      # <-- Update\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1844_5fold_feature_cols.bin']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(target_cols, '1844_5fold_target_cols.bin')\n",
    "dump(feature_cols, '1844_5fold_feature_cols.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5            #<-- Update\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"D:\\\\MOA_Pretrained_Models\\\\MoA_Model_01844\\\\FOLD{fold}_{seed}.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"D:\\\\MOA_Pretrained_Models\\\\MoA_Model_01844\\\\FOLD{fold}_{seed}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 0, FOLD: 0, EPOCH: 0, train_loss: 0.4936551513501268\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 0, valid_loss: 0.029317243237580573\n",
      "SEED: 0, FOLD: 0, EPOCH: 1, train_loss: 0.025618759766760944\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02045668379536697\n",
      "SEED: 0, FOLD: 0, EPOCH: 2, train_loss: 0.022699603513962982\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018587393686175346\n",
      "SEED: 0, FOLD: 0, EPOCH: 3, train_loss: 0.021392317947702133\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017748841270804405\n",
      "SEED: 0, FOLD: 0, EPOCH: 4, train_loss: 0.02056247222682704\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01754064065005098\n",
      "SEED: 0, FOLD: 0, EPOCH: 5, train_loss: 0.020253552866262802\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017490540152149542\n",
      "SEED: 0, FOLD: 0, EPOCH: 6, train_loss: 0.020219797160530437\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01720952128193208\n",
      "SEED: 0, FOLD: 0, EPOCH: 7, train_loss: 0.020241124029068844\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 7, valid_loss: 0.0173496438190341\n",
      "SEED: 0, FOLD: 0, EPOCH: 8, train_loss: 0.020315751838295357\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017300145168389593\n",
      "SEED: 0, FOLD: 0, EPOCH: 9, train_loss: 0.020349194309201794\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017439103232962744\n",
      "SEED: 0, FOLD: 0, EPOCH: 10, train_loss: 0.020333428381253845\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017297211262796607\n",
      "SEED: 0, FOLD: 0, EPOCH: 11, train_loss: 0.020308162382655384\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01718796898743936\n",
      "SEED: 0, FOLD: 0, EPOCH: 12, train_loss: 0.020215531595159267\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017118672520986627\n",
      "SEED: 0, FOLD: 0, EPOCH: 13, train_loss: 0.020157263074340164\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01692202314734459\n",
      "SEED: 0, FOLD: 0, EPOCH: 14, train_loss: 0.02001562617395235\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016867913332368645\n",
      "SEED: 0, FOLD: 0, EPOCH: 15, train_loss: 0.019812225350651188\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016742636183542863\n",
      "SEED: 0, FOLD: 0, EPOCH: 16, train_loss: 0.019689394444551155\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016698254245732513\n",
      "SEED: 0, FOLD: 0, EPOCH: 17, train_loss: 0.019466904329432957\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016530828630285602\n",
      "SEED: 0, FOLD: 0, EPOCH: 18, train_loss: 0.01925381173150263\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016505658466901097\n",
      "SEED: 0, FOLD: 0, EPOCH: 19, train_loss: 0.018890565429962633\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016392602558646885\n",
      "SEED: 0, FOLD: 0, EPOCH: 20, train_loss: 0.018569055782712025\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01621656830289534\n",
      "SEED: 0, FOLD: 0, EPOCH: 21, train_loss: 0.018158730031733496\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016225215340299266\n",
      "SEED: 0, FOLD: 0, EPOCH: 22, train_loss: 0.017795884151659582\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016118002523268973\n",
      "SEED: 0, FOLD: 0, EPOCH: 23, train_loss: 0.017459297431227955\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016115650215319226\n",
      "SEED: 0, FOLD: 0, EPOCH: 24, train_loss: 0.017296611965782402\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01610724540161235\n",
      "SEED: 0, FOLD: 1, EPOCH: 0, train_loss: 0.4922056594134673\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 0, valid_loss: 0.0255696391420705\n",
      "SEED: 0, FOLD: 1, EPOCH: 1, train_loss: 0.024495977530444878\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 1, valid_loss: 0.022668086630957467\n",
      "SEED: 0, FOLD: 1, EPOCH: 2, train_loss: 0.022528124136337334\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018711694702506065\n",
      "SEED: 0, FOLD: 1, EPOCH: 3, train_loss: 0.021132025219824\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017656697758606503\n",
      "SEED: 0, FOLD: 1, EPOCH: 4, train_loss: 0.020564459993139557\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017387624217995574\n",
      "SEED: 0, FOLD: 1, EPOCH: 5, train_loss: 0.020167694791503574\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017154513326074396\n",
      "SEED: 0, FOLD: 1, EPOCH: 6, train_loss: 0.020183016370604004\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017172849604061673\n",
      "SEED: 0, FOLD: 1, EPOCH: 7, train_loss: 0.020214881532002186\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017163825913199357\n",
      "SEED: 0, FOLD: 1, EPOCH: 8, train_loss: 0.020369805665551754\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017184244096279146\n",
      "SEED: 0, FOLD: 1, EPOCH: 9, train_loss: 0.020366777476949104\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017240518890321254\n",
      "SEED: 0, FOLD: 1, EPOCH: 10, train_loss: 0.020293913093274055\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017328007625682013\n",
      "SEED: 0, FOLD: 1, EPOCH: 11, train_loss: 0.020284453649883686\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01703297628888062\n",
      "SEED: 0, FOLD: 1, EPOCH: 12, train_loss: 0.020205650856529457\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016997024177440576\n",
      "SEED: 0, FOLD: 1, EPOCH: 13, train_loss: 0.020053332064138805\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016995871945151262\n",
      "SEED: 0, FOLD: 1, EPOCH: 14, train_loss: 0.019968791540874088\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01694309961582933\n",
      "SEED: 0, FOLD: 1, EPOCH: 15, train_loss: 0.019785075488945713\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016777929823313442\n",
      "SEED: 0, FOLD: 1, EPOCH: 16, train_loss: 0.019754792226181515\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016928458852427348\n",
      "SEED: 0, FOLD: 1, EPOCH: 17, train_loss: 0.019492773757572624\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016641948611608573\n",
      "SEED: 0, FOLD: 1, EPOCH: 18, train_loss: 0.019196786728782066\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016579970637602467\n",
      "SEED: 0, FOLD: 1, EPOCH: 19, train_loss: 0.018879921553467495\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016410061583987303\n",
      "SEED: 0, FOLD: 1, EPOCH: 20, train_loss: 0.018580682609446238\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016266262770763467\n",
      "SEED: 0, FOLD: 1, EPOCH: 21, train_loss: 0.018135607930953087\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01624255246881928\n",
      "SEED: 0, FOLD: 1, EPOCH: 22, train_loss: 0.01780175214525366\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016145106591284274\n",
      "SEED: 0, FOLD: 1, EPOCH: 23, train_loss: 0.017411446637487497\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016170285988066878\n",
      "SEED: 0, FOLD: 1, EPOCH: 24, train_loss: 0.017276723666683487\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016183787264994212\n",
      "SEED: 0, FOLD: 2, EPOCH: 0, train_loss: 0.49285539687759633\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 0, valid_loss: 0.024605646516595567\n",
      "SEED: 0, FOLD: 2, EPOCH: 1, train_loss: 0.024533224670027477\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 1, valid_loss: 0.020286709868482182\n",
      "SEED: 0, FOLD: 2, EPOCH: 2, train_loss: 0.02235281382403944\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018557074985333852\n",
      "SEED: 0, FOLD: 2, EPOCH: 3, train_loss: 0.021208304129001022\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017566808978361742\n",
      "SEED: 0, FOLD: 2, EPOCH: 4, train_loss: 0.020556043536550758\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01724081076681614\n",
      "SEED: 0, FOLD: 2, EPOCH: 5, train_loss: 0.020275605559025123\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017281693486230713\n",
      "SEED: 0, FOLD: 2, EPOCH: 6, train_loss: 0.02028207942519499\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017101514738585268\n",
      "SEED: 0, FOLD: 2, EPOCH: 7, train_loss: 0.020210901369759136\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01736832931637764\n",
      "SEED: 0, FOLD: 2, EPOCH: 8, train_loss: 0.020322337584651035\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017190114169248514\n",
      "SEED: 0, FOLD: 2, EPOCH: 9, train_loss: 0.02034686574631411\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01724537459335157\n",
      "SEED: 0, FOLD: 2, EPOCH: 10, train_loss: 0.02030541566942913\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017171340089823517\n",
      "SEED: 0, FOLD: 2, EPOCH: 11, train_loss: 0.020224688750138317\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01701140853443316\n",
      "SEED: 0, FOLD: 2, EPOCH: 12, train_loss: 0.020199059184802616\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 12, valid_loss: 0.017032465524971487\n",
      "SEED: 0, FOLD: 2, EPOCH: 13, train_loss: 0.02009553500059722\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 13, valid_loss: 0.017062745988368988\n",
      "SEED: 0, FOLD: 2, EPOCH: 14, train_loss: 0.020033873968582222\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016868738191468374\n",
      "SEED: 0, FOLD: 2, EPOCH: 15, train_loss: 0.019870741535787998\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01677260726158108\n",
      "SEED: 0, FOLD: 2, EPOCH: 16, train_loss: 0.019714723219690117\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016703375056385993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 0, FOLD: 2, EPOCH: 17, train_loss: 0.019476176253047543\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01658906369869198\n",
      "SEED: 0, FOLD: 2, EPOCH: 18, train_loss: 0.019159017677378397\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016364830040505953\n",
      "SEED: 0, FOLD: 2, EPOCH: 19, train_loss: 0.01889975161791064\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01632181898291622\n",
      "SEED: 0, FOLD: 2, EPOCH: 20, train_loss: 0.018506386499528005\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01620917400079114\n",
      "SEED: 0, FOLD: 2, EPOCH: 21, train_loss: 0.018142445444844772\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01609649389450039\n",
      "SEED: 0, FOLD: 2, EPOCH: 22, train_loss: 0.017747088544664606\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01608567155365433\n",
      "SEED: 0, FOLD: 2, EPOCH: 23, train_loss: 0.017425535631406565\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 23, valid_loss: 0.016064309887588023\n",
      "SEED: 0, FOLD: 2, EPOCH: 24, train_loss: 0.017244716087167246\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016077506914734842\n",
      "SEED: 0, FOLD: 3, EPOCH: 0, train_loss: 0.4940342004748358\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 0, valid_loss: 0.024790498295000622\n",
      "SEED: 0, FOLD: 3, EPOCH: 1, train_loss: 0.02514434820445983\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 1, valid_loss: 0.0198362406875406\n",
      "SEED: 0, FOLD: 3, EPOCH: 2, train_loss: 0.022320073232918545\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 2, valid_loss: 0.0187091447945152\n",
      "SEED: 0, FOLD: 3, EPOCH: 3, train_loss: 0.021276681791937004\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017907445106123174\n",
      "SEED: 0, FOLD: 3, EPOCH: 4, train_loss: 0.020497685271328774\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01739912275224924\n",
      "SEED: 0, FOLD: 3, EPOCH: 5, train_loss: 0.020191743902430153\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01735225370419877\n",
      "SEED: 0, FOLD: 3, EPOCH: 6, train_loss: 0.020154585292481857\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017549346733306135\n",
      "SEED: 0, FOLD: 3, EPOCH: 7, train_loss: 0.02020792912799811\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017371364762740475\n",
      "SEED: 0, FOLD: 3, EPOCH: 8, train_loss: 0.020277573403133\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017339885234832764\n",
      "SEED: 0, FOLD: 3, EPOCH: 9, train_loss: 0.020238794750817444\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01735553297081164\n",
      "SEED: 0, FOLD: 3, EPOCH: 10, train_loss: 0.02027435600757599\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01737051997333765\n",
      "SEED: 0, FOLD: 3, EPOCH: 11, train_loss: 0.02015656711992578\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017378922126122884\n",
      "SEED: 0, FOLD: 3, EPOCH: 12, train_loss: 0.020163303160149117\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01721494288316795\n",
      "SEED: 0, FOLD: 3, EPOCH: 13, train_loss: 0.020123751402117203\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017111132240721156\n",
      "SEED: 0, FOLD: 3, EPOCH: 14, train_loss: 0.019959903322160244\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017187475386474815\n",
      "SEED: 0, FOLD: 3, EPOCH: 15, train_loss: 0.019817621730591938\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 15, valid_loss: 0.017034687554197653\n",
      "SEED: 0, FOLD: 3, EPOCH: 16, train_loss: 0.01960542254095924\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 16, valid_loss: 0.017078011828873838\n",
      "SEED: 0, FOLD: 3, EPOCH: 17, train_loss: 0.01942816769461269\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016653350102049963\n",
      "SEED: 0, FOLD: 3, EPOCH: 18, train_loss: 0.019097256636166054\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016757435537874697\n",
      "SEED: 0, FOLD: 3, EPOCH: 19, train_loss: 0.018815838718327923\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016497000546327658\n",
      "SEED: 0, FOLD: 3, EPOCH: 20, train_loss: 0.018424488901012184\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016459000536373683\n",
      "SEED: 0, FOLD: 3, EPOCH: 21, train_loss: 0.018054746091365814\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016399630132530416\n",
      "SEED: 0, FOLD: 3, EPOCH: 22, train_loss: 0.017590113463339167\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01633991806634835\n",
      "SEED: 0, FOLD: 3, EPOCH: 23, train_loss: 0.017247916536702625\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01631921503160681\n",
      "SEED: 0, FOLD: 3, EPOCH: 24, train_loss: 0.017090837444192257\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016338096825139863\n",
      "SEED: 0, FOLD: 4, EPOCH: 0, train_loss: 0.4946257980891328\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 0, valid_loss: 0.025917053914495877\n",
      "SEED: 0, FOLD: 4, EPOCH: 1, train_loss: 0.02444522468832092\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01956309649561133\n",
      "SEED: 0, FOLD: 4, EPOCH: 2, train_loss: 0.02228252651790778\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018247001298836298\n",
      "SEED: 0, FOLD: 4, EPOCH: 3, train_loss: 0.021191414567115513\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01762734901692186\n",
      "SEED: 0, FOLD: 4, EPOCH: 4, train_loss: 0.02057375976194938\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017548762554568904\n",
      "SEED: 0, FOLD: 4, EPOCH: 5, train_loss: 0.020359585628561352\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017239146972341197\n",
      "SEED: 0, FOLD: 4, EPOCH: 6, train_loss: 0.020266178199022575\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 6, valid_loss: 0.0174345534827028\n",
      "SEED: 0, FOLD: 4, EPOCH: 7, train_loss: 0.02037561509380306\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017264781998736517\n",
      "SEED: 0, FOLD: 4, EPOCH: 8, train_loss: 0.020326741755116676\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01722071048404489\n",
      "SEED: 0, FOLD: 4, EPOCH: 9, train_loss: 0.020385918652881748\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017518372674073492\n",
      "SEED: 0, FOLD: 4, EPOCH: 10, train_loss: 0.020295218429595665\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016995143650897913\n",
      "SEED: 0, FOLD: 4, EPOCH: 11, train_loss: 0.020227793415171513\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017099149471947125\n",
      "SEED: 0, FOLD: 4, EPOCH: 12, train_loss: 0.020274149038005566\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01711062432399818\n",
      "SEED: 0, FOLD: 4, EPOCH: 13, train_loss: 0.020164013408340405\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01711981057056359\n",
      "SEED: 0, FOLD: 4, EPOCH: 14, train_loss: 0.019968427488229412\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016938838948096547\n",
      "SEED: 0, FOLD: 4, EPOCH: 15, train_loss: 0.019867661854495174\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016782780976167748\n",
      "SEED: 0, FOLD: 4, EPOCH: 16, train_loss: 0.019717892483416675\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016768957168928216\n",
      "SEED: 0, FOLD: 4, EPOCH: 17, train_loss: 0.01954899937508331\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016678423647369656\n",
      "SEED: 0, FOLD: 4, EPOCH: 18, train_loss: 0.019250048256978607\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016377706027456692\n",
      "SEED: 0, FOLD: 4, EPOCH: 19, train_loss: 0.018945423062836777\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016252493539026806\n",
      "SEED: 0, FOLD: 4, EPOCH: 20, train_loss: 0.01853538871459339\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016191118077508043\n",
      "SEED: 0, FOLD: 4, EPOCH: 21, train_loss: 0.018131802526667067\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016081231726067406\n",
      "SEED: 0, FOLD: 4, EPOCH: 22, train_loss: 0.017774053147413593\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016051399095782213\n",
      "SEED: 0, FOLD: 4, EPOCH: 23, train_loss: 0.017448006926671318\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016001925750502518\n",
      "SEED: 0, FOLD: 4, EPOCH: 24, train_loss: 0.017263575787723497\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01600225583783218\n",
      "SEED: 1, FOLD: 0, EPOCH: 0, train_loss: 0.49314845383059286\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 0, valid_loss: 0.02542211753981454\n",
      "SEED: 1, FOLD: 0, EPOCH: 1, train_loss: 0.025915105867645016\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020571965458137647\n",
      "SEED: 1, FOLD: 0, EPOCH: 2, train_loss: 0.02258284349480401\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01873505243233272\n",
      "SEED: 1, FOLD: 0, EPOCH: 3, train_loss: 0.02137525421499774\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017581254722816603\n",
      "SEED: 1, FOLD: 0, EPOCH: 4, train_loss: 0.02051805137940075\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017353222253067152\n",
      "SEED: 1, FOLD: 0, EPOCH: 5, train_loss: 0.020362171195987343\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017190643293516977\n",
      "SEED: 1, FOLD: 0, EPOCH: 6, train_loss: 0.020245999516244385\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017322264345628873\n",
      "SEED: 1, FOLD: 0, EPOCH: 7, train_loss: 0.020170066816111405\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017182241353605476\n",
      "SEED: 1, FOLD: 0, EPOCH: 8, train_loss: 0.02028339979765208\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017272015527955122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1, FOLD: 0, EPOCH: 9, train_loss: 0.020312114416257195\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017160854754703386\n",
      "SEED: 1, FOLD: 0, EPOCH: 10, train_loss: 0.02031999644215988\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01748760717787913\n",
      "SEED: 1, FOLD: 0, EPOCH: 11, train_loss: 0.020276958676244038\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017477706287588393\n",
      "SEED: 1, FOLD: 0, EPOCH: 12, train_loss: 0.020215231466336525\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017425501506243432\n",
      "SEED: 1, FOLD: 0, EPOCH: 13, train_loss: 0.020118913802223793\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01705980950168201\n",
      "SEED: 1, FOLD: 0, EPOCH: 14, train_loss: 0.019984045295395714\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01683983275932925\n",
      "SEED: 1, FOLD: 0, EPOCH: 15, train_loss: 0.019924099840547726\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016853347713393824\n",
      "SEED: 1, FOLD: 0, EPOCH: 16, train_loss: 0.019724249434859856\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016754164573337352\n",
      "SEED: 1, FOLD: 0, EPOCH: 17, train_loss: 0.019425104871608208\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016597037922058785\n",
      "SEED: 1, FOLD: 0, EPOCH: 18, train_loss: 0.01920377928763628\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016446972239230362\n",
      "SEED: 1, FOLD: 0, EPOCH: 19, train_loss: 0.018854466361412102\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016371838748455048\n",
      "SEED: 1, FOLD: 0, EPOCH: 20, train_loss: 0.018553157242527908\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016224452214581627\n",
      "SEED: 1, FOLD: 0, EPOCH: 21, train_loss: 0.01813050823799078\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016189754993787834\n",
      "SEED: 1, FOLD: 0, EPOCH: 22, train_loss: 0.0177325283082715\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016131947429052423\n",
      "SEED: 1, FOLD: 0, EPOCH: 23, train_loss: 0.01746228320416117\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016108479563679015\n",
      "SEED: 1, FOLD: 0, EPOCH: 24, train_loss: 0.017290630816495504\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016077398854706968\n",
      "SEED: 1, FOLD: 1, EPOCH: 0, train_loss: 0.49165527282309707\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 0, valid_loss: 0.02471537542130266\n",
      "SEED: 1, FOLD: 1, EPOCH: 1, train_loss: 0.024601173749112564\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 1, valid_loss: 0.01955379375389644\n",
      "SEED: 1, FOLD: 1, EPOCH: 2, train_loss: 0.022613304005800815\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018559985820736202\n",
      "SEED: 1, FOLD: 1, EPOCH: 3, train_loss: 0.021243773468270683\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017577443750841276\n",
      "SEED: 1, FOLD: 1, EPOCH: 4, train_loss: 0.020484172320668247\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017442460278315204\n",
      "SEED: 1, FOLD: 1, EPOCH: 5, train_loss: 0.020273540195995483\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017162859732551234\n",
      "SEED: 1, FOLD: 1, EPOCH: 6, train_loss: 0.020229978432905846\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017378776467272213\n",
      "SEED: 1, FOLD: 1, EPOCH: 7, train_loss: 0.020304477422673634\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017297212300556048\n",
      "SEED: 1, FOLD: 1, EPOCH: 8, train_loss: 0.020403223058235817\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017284131688731056\n",
      "SEED: 1, FOLD: 1, EPOCH: 9, train_loss: 0.020344785225672134\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01730738380657775\n",
      "SEED: 1, FOLD: 1, EPOCH: 10, train_loss: 0.02031575611698023\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017273449205926487\n",
      "SEED: 1, FOLD: 1, EPOCH: 11, train_loss: 0.020286416553932686\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017420250310429503\n",
      "SEED: 1, FOLD: 1, EPOCH: 12, train_loss: 0.020260015165136345\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01707404391574008\n",
      "SEED: 1, FOLD: 1, EPOCH: 13, train_loss: 0.020130845893552338\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01708938120199101\n",
      "SEED: 1, FOLD: 1, EPOCH: 14, train_loss: 0.02006225395893705\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 14, valid_loss: 0.017152604646980762\n",
      "SEED: 1, FOLD: 1, EPOCH: 15, train_loss: 0.019921665930229683\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 15, valid_loss: 0.0168375237179654\n",
      "SEED: 1, FOLD: 1, EPOCH: 16, train_loss: 0.019737450392457886\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016699102467724256\n",
      "SEED: 1, FOLD: 1, EPOCH: 17, train_loss: 0.019566551633719086\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016579735412129332\n",
      "SEED: 1, FOLD: 1, EPOCH: 18, train_loss: 0.019304934727108997\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016487191564270427\n",
      "SEED: 1, FOLD: 1, EPOCH: 19, train_loss: 0.019028501099218494\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01638609668506043\n",
      "SEED: 1, FOLD: 1, EPOCH: 20, train_loss: 0.018728139985730682\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01633812077343464\n",
      "SEED: 1, FOLD: 1, EPOCH: 21, train_loss: 0.018305216868664476\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01622064584600074\n",
      "SEED: 1, FOLD: 1, EPOCH: 22, train_loss: 0.017896066622241684\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 22, valid_loss: 0.01618647077786071\n",
      "SEED: 1, FOLD: 1, EPOCH: 23, train_loss: 0.01763873660693998\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016123537852295807\n",
      "SEED: 1, FOLD: 1, EPOCH: 24, train_loss: 0.01748033151354479\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016105095935719353\n",
      "SEED: 1, FOLD: 2, EPOCH: 0, train_loss: 0.49061289030140726\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 0, valid_loss: 0.025352667538183077\n",
      "SEED: 1, FOLD: 2, EPOCH: 1, train_loss: 0.024582627269884815\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019527132170540945\n",
      "SEED: 1, FOLD: 2, EPOCH: 2, train_loss: 0.02246216959927393\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01962677878992898\n",
      "SEED: 1, FOLD: 2, EPOCH: 3, train_loss: 0.021302367493078327\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01772791889629194\n",
      "SEED: 1, FOLD: 2, EPOCH: 4, train_loss: 0.02058917037008897\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01746085174381733\n",
      "SEED: 1, FOLD: 2, EPOCH: 5, train_loss: 0.020289806595099144\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017374687269330023\n",
      "SEED: 1, FOLD: 2, EPOCH: 6, train_loss: 0.02030695416033268\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01720908297491925\n",
      "SEED: 1, FOLD: 2, EPOCH: 7, train_loss: 0.020307068537542786\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017280497854309424\n",
      "SEED: 1, FOLD: 2, EPOCH: 8, train_loss: 0.020344773010499237\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01734521665743419\n",
      "SEED: 1, FOLD: 2, EPOCH: 9, train_loss: 0.02034612847627073\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01728790205504213\n",
      "SEED: 1, FOLD: 2, EPOCH: 10, train_loss: 0.02033860853238814\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017306614986487796\n",
      "SEED: 1, FOLD: 2, EPOCH: 11, train_loss: 0.02035038503885701\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017277102944042\n",
      "SEED: 1, FOLD: 2, EPOCH: 12, train_loss: 0.02019638160540574\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01707841067441872\n",
      "SEED: 1, FOLD: 2, EPOCH: 13, train_loss: 0.02013696527675442\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016970504208334854\n",
      "SEED: 1, FOLD: 2, EPOCH: 14, train_loss: 0.020010856115191742\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 14, valid_loss: 0.017094427560056958\n",
      "SEED: 1, FOLD: 2, EPOCH: 15, train_loss: 0.019874476233794205\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016889471055141516\n",
      "SEED: 1, FOLD: 2, EPOCH: 16, train_loss: 0.01970365250726109\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016697151958942412\n",
      "SEED: 1, FOLD: 2, EPOCH: 17, train_loss: 0.01954161806329005\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016573888010212354\n",
      "SEED: 1, FOLD: 2, EPOCH: 18, train_loss: 0.019338743329264114\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016477485985628197\n",
      "SEED: 1, FOLD: 2, EPOCH: 19, train_loss: 0.019045761867385845\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01622943891478436\n",
      "SEED: 1, FOLD: 2, EPOCH: 20, train_loss: 0.018639453200866348\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01621891145727464\n",
      "SEED: 1, FOLD: 2, EPOCH: 21, train_loss: 0.018260649182712255\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01608142043863024\n",
      "SEED: 1, FOLD: 2, EPOCH: 22, train_loss: 0.01787721828652033\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01604669855109283\n",
      "SEED: 1, FOLD: 2, EPOCH: 23, train_loss: 0.01760947902727386\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015973049854593618\n",
      "SEED: 1, FOLD: 2, EPOCH: 24, train_loss: 0.017460367028210043\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016009406186640263\n",
      "SEED: 1, FOLD: 3, EPOCH: 0, train_loss: 0.49224499198675586\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 0, valid_loss: 0.026584788518292563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1, FOLD: 3, EPOCH: 1, train_loss: 0.02448790122255467\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02015777150435107\n",
      "SEED: 1, FOLD: 3, EPOCH: 2, train_loss: 0.022633962306207504\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01858004629611969\n",
      "SEED: 1, FOLD: 3, EPOCH: 3, train_loss: 0.021181615838861984\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017790326236614157\n",
      "SEED: 1, FOLD: 3, EPOCH: 4, train_loss: 0.02045616824719785\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017576046607324054\n",
      "SEED: 1, FOLD: 3, EPOCH: 5, train_loss: 0.020205302771342838\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017498965188860894\n",
      "SEED: 1, FOLD: 3, EPOCH: 6, train_loss: 0.020242915299815544\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017574721202254295\n",
      "SEED: 1, FOLD: 3, EPOCH: 7, train_loss: 0.020224107942287472\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017353903369179795\n",
      "SEED: 1, FOLD: 3, EPOCH: 8, train_loss: 0.020233590236824493\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017335346740271363\n",
      "SEED: 1, FOLD: 3, EPOCH: 9, train_loss: 0.020238453090406845\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017356423448239053\n",
      "SEED: 1, FOLD: 3, EPOCH: 10, train_loss: 0.020203603094146736\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017344529075281962\n",
      "SEED: 1, FOLD: 3, EPOCH: 11, train_loss: 0.020194715131884037\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017307767484869275\n",
      "SEED: 1, FOLD: 3, EPOCH: 12, train_loss: 0.02018103905130124\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017327128749872956\n",
      "SEED: 1, FOLD: 3, EPOCH: 13, train_loss: 0.019982045367900013\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017230785318783352\n",
      "SEED: 1, FOLD: 3, EPOCH: 14, train_loss: 0.019914528840909832\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017261137281145367\n",
      "SEED: 1, FOLD: 3, EPOCH: 15, train_loss: 0.01980914444109236\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 15, valid_loss: 0.017057572172156404\n",
      "SEED: 1, FOLD: 3, EPOCH: 16, train_loss: 0.019681410756016125\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016932521175060954\n",
      "SEED: 1, FOLD: 3, EPOCH: 17, train_loss: 0.0194441136782584\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01672990372670548\n",
      "SEED: 1, FOLD: 3, EPOCH: 18, train_loss: 0.019202102272622826\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016628897642450673\n",
      "SEED: 1, FOLD: 3, EPOCH: 19, train_loss: 0.018796046669392483\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01656807908522231\n",
      "SEED: 1, FOLD: 3, EPOCH: 20, train_loss: 0.018462731259996475\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016454399403716836\n",
      "SEED: 1, FOLD: 3, EPOCH: 21, train_loss: 0.017987085560309715\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016412972791918685\n",
      "SEED: 1, FOLD: 3, EPOCH: 22, train_loss: 0.017599863526613815\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01632956266403198\n",
      "SEED: 1, FOLD: 3, EPOCH: 23, train_loss: 0.017275730876818947\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016331148067755357\n",
      "SEED: 1, FOLD: 3, EPOCH: 24, train_loss: 0.017108980276068483\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016315779914813384\n",
      "SEED: 1, FOLD: 4, EPOCH: 0, train_loss: 0.4929825856849767\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 0, valid_loss: 0.025205364344375474\n",
      "SEED: 1, FOLD: 4, EPOCH: 1, train_loss: 0.024398218610904354\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01967095493205956\n",
      "SEED: 1, FOLD: 4, EPOCH: 2, train_loss: 0.022478842824373558\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018565070256590842\n",
      "SEED: 1, FOLD: 4, EPOCH: 3, train_loss: 0.021226038461200136\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017506774781005725\n",
      "SEED: 1, FOLD: 4, EPOCH: 4, train_loss: 0.02041878039692191\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017461101258439676\n",
      "SEED: 1, FOLD: 4, EPOCH: 5, train_loss: 0.020332052750323994\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017178457682686193\n",
      "SEED: 1, FOLD: 4, EPOCH: 6, train_loss: 0.020318052299536656\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01722748763859272\n",
      "SEED: 1, FOLD: 4, EPOCH: 7, train_loss: 0.020283202573225117\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017525792414588588\n",
      "SEED: 1, FOLD: 4, EPOCH: 8, train_loss: 0.02034456166776194\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017217982640223842\n",
      "SEED: 1, FOLD: 4, EPOCH: 9, train_loss: 0.020368919640347576\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01740205165530954\n",
      "SEED: 1, FOLD: 4, EPOCH: 10, train_loss: 0.02029441579150549\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01717530097812414\n",
      "SEED: 1, FOLD: 4, EPOCH: 11, train_loss: 0.02030294688175554\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01718796637973615\n",
      "SEED: 1, FOLD: 4, EPOCH: 12, train_loss: 0.020328951014232807\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017100570776632854\n",
      "SEED: 1, FOLD: 4, EPOCH: 13, train_loss: 0.020174724400799343\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01711707969329187\n",
      "SEED: 1, FOLD: 4, EPOCH: 14, train_loss: 0.020008973061930443\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016886131066296783\n",
      "SEED: 1, FOLD: 4, EPOCH: 15, train_loss: 0.019895415496675\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 15, valid_loss: 0.0167816609410303\n",
      "SEED: 1, FOLD: 4, EPOCH: 16, train_loss: 0.01972830539866202\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016651802669678417\n",
      "SEED: 1, FOLD: 4, EPOCH: 17, train_loss: 0.01952917448690404\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016586861865861075\n",
      "SEED: 1, FOLD: 4, EPOCH: 18, train_loss: 0.01922968878964151\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016441198997199535\n",
      "SEED: 1, FOLD: 4, EPOCH: 19, train_loss: 0.019025681553867416\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016337790047483786\n",
      "SEED: 1, FOLD: 4, EPOCH: 20, train_loss: 0.018617218562766262\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01619123358811651\n",
      "SEED: 1, FOLD: 4, EPOCH: 21, train_loss: 0.018214144251322832\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016146411454038962\n",
      "SEED: 1, FOLD: 4, EPOCH: 22, train_loss: 0.017823563557982012\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016047851368784904\n",
      "SEED: 1, FOLD: 4, EPOCH: 23, train_loss: 0.017488036075256008\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016074084357491563\n",
      "SEED: 1, FOLD: 4, EPOCH: 24, train_loss: 0.01736479927448259\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 24, valid_loss: 0.016078339543725763\n",
      "SEED: 2, FOLD: 0, EPOCH: 0, train_loss: 0.48985359904126846\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 0, valid_loss: 0.023837560947452274\n",
      "SEED: 2, FOLD: 0, EPOCH: 1, train_loss: 0.024270921621633613\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 1, valid_loss: 0.01939744289432253\n",
      "SEED: 2, FOLD: 0, EPOCH: 2, train_loss: 0.022545747863857643\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01879428162106446\n",
      "SEED: 2, FOLD: 0, EPOCH: 3, train_loss: 0.02113762285992287\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017558208480477334\n",
      "SEED: 2, FOLD: 0, EPOCH: 4, train_loss: 0.020401383466694668\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017325579587902342\n",
      "SEED: 2, FOLD: 0, EPOCH: 5, train_loss: 0.02024126349799875\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017759500284280097\n",
      "SEED: 2, FOLD: 0, EPOCH: 6, train_loss: 0.02032645280216483\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017250929613198553\n",
      "SEED: 2, FOLD: 0, EPOCH: 7, train_loss: 0.02026165962435197\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01712678668222257\n",
      "SEED: 2, FOLD: 0, EPOCH: 8, train_loss: 0.02029986462245385\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017420550622045994\n",
      "SEED: 2, FOLD: 0, EPOCH: 9, train_loss: 0.020372040569782257\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017337292140083654\n",
      "SEED: 2, FOLD: 0, EPOCH: 10, train_loss: 0.020277159936402157\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017082620012973036\n",
      "SEED: 2, FOLD: 0, EPOCH: 11, train_loss: 0.020202048460318558\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017418745346367358\n",
      "SEED: 2, FOLD: 0, EPOCH: 12, train_loss: 0.02024719599580419\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01711421265665974\n",
      "SEED: 2, FOLD: 0, EPOCH: 13, train_loss: 0.02022428466412036\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01710272489913872\n",
      "SEED: 2, FOLD: 0, EPOCH: 14, train_loss: 0.02002607402054296\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01699183974415064\n",
      "SEED: 2, FOLD: 0, EPOCH: 15, train_loss: 0.019841480878708156\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01681015986417021\n",
      "SEED: 2, FOLD: 0, EPOCH: 16, train_loss: 0.01966334076301343\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016715347793485436\n",
      "SEED: 2, FOLD: 0, EPOCH: 17, train_loss: 0.019436127425211926\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016614180377551486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 2, FOLD: 0, EPOCH: 18, train_loss: 0.01921979691563309\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016513354224818092\n",
      "SEED: 2, FOLD: 0, EPOCH: 19, train_loss: 0.01896142419697582\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016381853951939515\n",
      "SEED: 2, FOLD: 0, EPOCH: 20, train_loss: 0.01861335482934247\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01630061950002398\n",
      "SEED: 2, FOLD: 0, EPOCH: 21, train_loss: 0.018184201292477657\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016232046937303884\n",
      "SEED: 2, FOLD: 0, EPOCH: 22, train_loss: 0.017809289480573025\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016144783635224615\n",
      "SEED: 2, FOLD: 0, EPOCH: 23, train_loss: 0.017547462074814932\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016142239794135094\n",
      "SEED: 2, FOLD: 0, EPOCH: 24, train_loss: 0.017383888174874195\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016112037881144455\n",
      "SEED: 2, FOLD: 1, EPOCH: 0, train_loss: 0.49166649827004777\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 0, valid_loss: 0.024349446115749223\n",
      "SEED: 2, FOLD: 1, EPOCH: 1, train_loss: 0.024614961129491745\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 1, valid_loss: 0.02053425067237445\n",
      "SEED: 2, FOLD: 1, EPOCH: 2, train_loss: 0.02273092495844416\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018231508801026003\n",
      "SEED: 2, FOLD: 1, EPOCH: 3, train_loss: 0.02109191924387562\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017740954352276666\n",
      "SEED: 2, FOLD: 1, EPOCH: 4, train_loss: 0.020648092382412025\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01743254185255085\n",
      "SEED: 2, FOLD: 1, EPOCH: 5, train_loss: 0.02026231281891249\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017515907250344753\n",
      "SEED: 2, FOLD: 1, EPOCH: 6, train_loss: 0.020213814641254536\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017273156877074924\n",
      "SEED: 2, FOLD: 1, EPOCH: 7, train_loss: 0.020271401298974735\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01756336587880339\n",
      "SEED: 2, FOLD: 1, EPOCH: 8, train_loss: 0.020380632573927658\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01728375173572983\n",
      "SEED: 2, FOLD: 1, EPOCH: 9, train_loss: 0.02030304043243329\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01728163869785411\n",
      "SEED: 2, FOLD: 1, EPOCH: 10, train_loss: 0.020335195059685604\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017152932578963893\n",
      "SEED: 2, FOLD: 1, EPOCH: 11, train_loss: 0.02029174556820721\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01719920055142471\n",
      "SEED: 2, FOLD: 1, EPOCH: 12, train_loss: 0.020280214782426323\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017083006618278367\n",
      "SEED: 2, FOLD: 1, EPOCH: 13, train_loss: 0.02017708906930858\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01692602980349745\n",
      "SEED: 2, FOLD: 1, EPOCH: 14, train_loss: 0.019944095376717007\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016895600647798607\n",
      "SEED: 2, FOLD: 1, EPOCH: 15, train_loss: 0.01988727160041099\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016886311636439392\n",
      "SEED: 2, FOLD: 1, EPOCH: 16, train_loss: 0.01965954245162615\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016594433757875646\n",
      "SEED: 2, FOLD: 1, EPOCH: 17, train_loss: 0.019470208526953407\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016728077323309012\n",
      "SEED: 2, FOLD: 1, EPOCH: 18, train_loss: 0.019210650774555794\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01648745390453509\n",
      "SEED: 2, FOLD: 1, EPOCH: 19, train_loss: 0.018862228624630665\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016418750451079437\n",
      "SEED: 2, FOLD: 1, EPOCH: 20, train_loss: 0.01855805799688982\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016332190643463817\n",
      "SEED: 2, FOLD: 1, EPOCH: 21, train_loss: 0.018139358461443066\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016269082230116638\n",
      "SEED: 2, FOLD: 1, EPOCH: 22, train_loss: 0.01771338450708899\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016166842223278115\n",
      "SEED: 2, FOLD: 1, EPOCH: 23, train_loss: 0.01737267061042181\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01619636014636074\n",
      "SEED: 2, FOLD: 1, EPOCH: 24, train_loss: 0.017251581601474598\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01617409810423851\n",
      "SEED: 2, FOLD: 2, EPOCH: 0, train_loss: 0.4923355260162034\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 0, valid_loss: 0.025448204896279743\n",
      "SEED: 2, FOLD: 2, EPOCH: 1, train_loss: 0.024366770155619884\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019627206240381515\n",
      "SEED: 2, FOLD: 2, EPOCH: 2, train_loss: 0.022421116265805736\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 2, valid_loss: 0.017934999535126346\n",
      "SEED: 2, FOLD: 2, EPOCH: 3, train_loss: 0.02126166374301133\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017697509032274995\n",
      "SEED: 2, FOLD: 2, EPOCH: 4, train_loss: 0.020424925560212654\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017418871207961015\n",
      "SEED: 2, FOLD: 2, EPOCH: 5, train_loss: 0.020314842732488247\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017334928709481445\n",
      "SEED: 2, FOLD: 2, EPOCH: 6, train_loss: 0.02029943088258522\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01716108053390469\n",
      "SEED: 2, FOLD: 2, EPOCH: 7, train_loss: 0.020278825748549854\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017276290564664773\n",
      "SEED: 2, FOLD: 2, EPOCH: 8, train_loss: 0.020331470822186573\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017122046569628374\n",
      "SEED: 2, FOLD: 2, EPOCH: 9, train_loss: 0.020404418269037338\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017258334292897155\n",
      "SEED: 2, FOLD: 2, EPOCH: 10, train_loss: 0.020316468038852665\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01722699401101896\n",
      "SEED: 2, FOLD: 2, EPOCH: 11, train_loss: 0.02027836944098058\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017140237827386176\n",
      "SEED: 2, FOLD: 2, EPOCH: 12, train_loss: 0.020214364944916706\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 12, valid_loss: 0.017078093572386672\n",
      "SEED: 2, FOLD: 2, EPOCH: 13, train_loss: 0.020067485197838665\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01693582058485065\n",
      "SEED: 2, FOLD: 2, EPOCH: 14, train_loss: 0.019951011567120102\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01690916278000389\n",
      "SEED: 2, FOLD: 2, EPOCH: 15, train_loss: 0.019862503582692665\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01670956952231271\n",
      "SEED: 2, FOLD: 2, EPOCH: 16, train_loss: 0.019662803065949593\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 16, valid_loss: 0.0167882806754538\n",
      "SEED: 2, FOLD: 2, EPOCH: 17, train_loss: 0.01952801960641923\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016544839101178304\n",
      "SEED: 2, FOLD: 2, EPOCH: 18, train_loss: 0.019278856088825756\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016396609826811723\n",
      "SEED: 2, FOLD: 2, EPOCH: 19, train_loss: 0.018952673422577587\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01630715789007289\n",
      "SEED: 2, FOLD: 2, EPOCH: 20, train_loss: 0.018572577099869217\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 20, valid_loss: 0.0162374258307474\n",
      "SEED: 2, FOLD: 2, EPOCH: 21, train_loss: 0.018160624348598976\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016090027163071292\n",
      "SEED: 2, FOLD: 2, EPOCH: 22, train_loss: 0.01774670141816571\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016046575004501\n",
      "SEED: 2, FOLD: 2, EPOCH: 23, train_loss: 0.017421239831795294\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01601549924484321\n",
      "SEED: 2, FOLD: 2, EPOCH: 24, train_loss: 0.01724740136684715\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016031953426344055\n",
      "SEED: 2, FOLD: 3, EPOCH: 0, train_loss: 0.4913215562431277\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 0, valid_loss: 0.02595052511564323\n",
      "SEED: 2, FOLD: 3, EPOCH: 1, train_loss: 0.024579828686040382\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 1, valid_loss: 0.01948935357587678\n",
      "SEED: 2, FOLD: 3, EPOCH: 2, train_loss: 0.022667763849207455\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018642538413405418\n",
      "SEED: 2, FOLD: 3, EPOCH: 3, train_loss: 0.021213822174763333\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018274394050240516\n",
      "SEED: 2, FOLD: 3, EPOCH: 4, train_loss: 0.020603195642647537\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017698834144643374\n",
      "SEED: 2, FOLD: 3, EPOCH: 5, train_loss: 0.02026485203616861\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 5, valid_loss: 0.0172945092565247\n",
      "SEED: 2, FOLD: 3, EPOCH: 6, train_loss: 0.020203466702630554\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01741063033363649\n",
      "SEED: 2, FOLD: 3, EPOCH: 7, train_loss: 0.020299395411342815\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017455911796007837\n",
      "SEED: 2, FOLD: 3, EPOCH: 8, train_loss: 0.020311660281773926\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017600964062980243\n",
      "SEED: 2, FOLD: 3, EPOCH: 9, train_loss: 0.02036057050893272\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017333243707461015\n",
      "SEED: 2, FOLD: 3, EPOCH: 10, train_loss: 0.02027945800859859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 2 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017377082098807606\n",
      "SEED: 2, FOLD: 3, EPOCH: 11, train_loss: 0.020247139967978\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01724230721592903\n",
      "SEED: 2, FOLD: 3, EPOCH: 12, train_loss: 0.02017679134302813\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01727732220398528\n",
      "SEED: 2, FOLD: 3, EPOCH: 13, train_loss: 0.020077619229213917\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017284802507076945\n",
      "SEED: 2, FOLD: 3, EPOCH: 14, train_loss: 0.020010813530804455\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01716196888259479\n",
      "SEED: 2, FOLD: 3, EPOCH: 15, train_loss: 0.019771243236365095\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01703906399863107\n",
      "SEED: 2, FOLD: 3, EPOCH: 16, train_loss: 0.019710850422743006\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01686716784856149\n",
      "SEED: 2, FOLD: 3, EPOCH: 17, train_loss: 0.019422728595310364\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01675425570990358\n",
      "SEED: 2, FOLD: 3, EPOCH: 18, train_loss: 0.019186835965492588\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016607811195509775\n",
      "SEED: 2, FOLD: 3, EPOCH: 19, train_loss: 0.01892284768215124\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016538707805531367\n",
      "SEED: 2, FOLD: 3, EPOCH: 20, train_loss: 0.018583284380535286\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01646236412759338\n",
      "SEED: 2, FOLD: 3, EPOCH: 21, train_loss: 0.018185763120435287\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016352328205747262\n",
      "SEED: 2, FOLD: 3, EPOCH: 22, train_loss: 0.01778198714516517\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016280207304017885\n",
      "SEED: 2, FOLD: 3, EPOCH: 23, train_loss: 0.017457153162230617\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016261153322245394\n",
      "SEED: 2, FOLD: 3, EPOCH: 24, train_loss: 0.01731007596126933\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016258863572563443\n",
      "SEED: 2, FOLD: 4, EPOCH: 0, train_loss: 0.4926460448085614\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 0, valid_loss: 0.025300099008849688\n",
      "SEED: 2, FOLD: 4, EPOCH: 1, train_loss: 0.024135797770450943\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 1, valid_loss: 0.019394581232752117\n",
      "SEED: 2, FOLD: 4, EPOCH: 2, train_loss: 0.0223758635043666\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01833471746316978\n",
      "SEED: 2, FOLD: 4, EPOCH: 3, train_loss: 0.021227311234975208\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017471444713217873\n",
      "SEED: 2, FOLD: 4, EPOCH: 4, train_loss: 0.0204470065165905\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017468891346028873\n",
      "SEED: 2, FOLD: 4, EPOCH: 5, train_loss: 0.02032432468958955\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017264792269894056\n",
      "SEED: 2, FOLD: 4, EPOCH: 6, train_loss: 0.02028412007443283\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017469926684030464\n",
      "SEED: 2, FOLD: 4, EPOCH: 7, train_loss: 0.02033879836022422\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017199326279972282\n",
      "SEED: 2, FOLD: 4, EPOCH: 8, train_loss: 0.020423467136055664\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01721250071589436\n",
      "SEED: 2, FOLD: 4, EPOCH: 9, train_loss: 0.020379124951643356\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017558553123048375\n",
      "SEED: 2, FOLD: 4, EPOCH: 10, train_loss: 0.020349864308060944\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017088042119784014\n",
      "SEED: 2, FOLD: 4, EPOCH: 11, train_loss: 0.020280333465316158\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017156924972576756\n",
      "SEED: 2, FOLD: 4, EPOCH: 12, train_loss: 0.020291141220840855\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017274969284023556\n",
      "SEED: 2, FOLD: 4, EPOCH: 13, train_loss: 0.020125412638636604\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 13, valid_loss: 0.017088641066636358\n",
      "SEED: 2, FOLD: 4, EPOCH: 14, train_loss: 0.020033078322160072\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01677890752575227\n",
      "SEED: 2, FOLD: 4, EPOCH: 15, train_loss: 0.01994469231399505\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01677091004593032\n",
      "SEED: 2, FOLD: 4, EPOCH: 16, train_loss: 0.019716727925275547\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01665645225771836\n",
      "SEED: 2, FOLD: 4, EPOCH: 17, train_loss: 0.019540875988162083\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 17, valid_loss: 0.0166420024686626\n",
      "SEED: 2, FOLD: 4, EPOCH: 18, train_loss: 0.019265016513890114\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016434590518474578\n",
      "SEED: 2, FOLD: 4, EPOCH: 19, train_loss: 0.018931244958893978\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01630363557487726\n",
      "SEED: 2, FOLD: 4, EPOCH: 20, train_loss: 0.01863952146411158\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01622625272721052\n",
      "SEED: 2, FOLD: 4, EPOCH: 21, train_loss: 0.018259888420394367\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016158769013626235\n",
      "SEED: 2, FOLD: 4, EPOCH: 22, train_loss: 0.017874445469267128\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016064093740923064\n",
      "SEED: 2, FOLD: 4, EPOCH: 23, train_loss: 0.017524444693834452\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 23, valid_loss: 0.0161006858838456\n",
      "SEED: 2, FOLD: 4, EPOCH: 24, train_loss: 0.01747097721512335\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 24, valid_loss: 0.016098269101764474\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\\n       'acat_inhibitor', 'acetylcholine_receptor_agonist',\\n       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\\n       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\\n       'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist',\\n       ...\\n       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\\n       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\\n       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\\n       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\\n      dtype='object', length=206)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f0efbc39bbb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2933\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2934\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2935\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2964\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2965\u001b[0m                 indexer = self.loc._get_listlike_indexer(\n\u001b[1;32m-> 2966\u001b[1;33m                     \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2967\u001b[0m                 )[1]\n\u001b[0;32m   2968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\\n       'acat_inhibitor', 'acetylcholine_receptor_agonist',\\n       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\\n       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\\n       'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist',\\n       ...\\n       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\\n       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\\n       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\\n       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\\n      dtype='object', length=206)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0, 1, 2]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pred1 = np.load('moa_01844.npy')\n",
    "pred2 = np.load('model_oof_01840.npy')\n",
    "pred3 = np.load('moa_oof_01858.npy')\n",
    "pred4 = np.load('moa_oof_xgb.npy')\n",
    "pred5 = np.load('model_newcv_oof_01835.npy')\n",
    "pred6 = np.load('moa_oof_newcv_01844.npy')\n",
    "pred7= np.load('moa_oof_newcv_01858_opt.npy')\n",
    "\n",
    "pred8 = np.load('model_newcv_oof_01835.npy')\n",
    "pred9 = np.load('moa_oof_newcv_01858_7folds.npy')\n",
    "pred10 = np.load('moa_oof_newcv_01838_7folds.npy')\n",
    "pred11 = np.load('moa_oof_newcv_01858.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00137969, 0.00123399, 0.00066726, ..., 0.00167902, 0.00038655,\n",
       "        0.00175185],\n",
       "       [0.00068334, 0.00062712, 0.00224532, ..., 0.00274619, 0.00163212,\n",
       "        0.00300532],\n",
       "       [0.00182621, 0.00229216, 0.00078583, ..., 0.00068411, 0.00042305,\n",
       "        0.00122084],\n",
       "       ...,\n",
       "       [0.00067229, 0.00092357, 0.00287745, ..., 0.00195627, 0.0142041 ,\n",
       "        0.00260228],\n",
       "       [0.00045427, 0.00036849, 0.00042206, ..., 0.00035887, 0.00059093,\n",
       "        0.00068581],\n",
       "       [0.00051417, 0.00082633, 0.00092055, ..., 0.00063163, 0.00032853,\n",
       "        0.00045329]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred11 * 5 + pred8 *2 + pred1)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00151763, 0.00200997, 0.00352883, ..., 0.00239399, 0.00749808,\n",
       "        0.00215664],\n",
       "       [0.00089854, 0.0012979 , 0.00258505, ..., 0.00152582, 0.00215663,\n",
       "        0.00353468],\n",
       "       [0.00114159, 0.00129429, 0.00250067, ..., 0.00261794, 0.00053776,\n",
       "        0.00274661],\n",
       "       ...,\n",
       "       [0.00159203, 0.00134392, 0.00142612, ..., 0.00178747, 0.00068978,\n",
       "        0.00149942],\n",
       "       [0.00207427, 0.00163424, 0.00174905, ..., 0.00253873, 0.00038995,\n",
       "        0.00387187],\n",
       "       [0.00083419, 0.00120032, 0.00151174, ..., 0.00226848, 0.0004628 ,\n",
       "        0.00159326]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[target_cols] = (pred2 +pred1+pred3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.01574985566852989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in target_cols:\n",
    "    test[i]=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_ = np.load('moa_01844.npy')\n",
    "pred2_ = np.load('model_01840.npy')\n",
    "pred3_ = np.load('moa_01858.npy')\n",
    "pred4_ = np.load('moa_xgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target_cols] = (pred1_*0.10 + pred2_ * 0.80+ pred3_ * 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission_05_11_2020_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('moa_oof_newcv_01844', oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('moa_newcv_01844', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>-1.364787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.001982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.020551</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.307875</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>-2.288417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.104720</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>-0.375501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.237856</td>\n",
       "      <td>-1.228203</td>\n",
       "      <td>0.218376</td>\n",
       "      <td>-0.365976</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>-0.150978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.001372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>0.735603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>-0.304313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.017936</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.027558</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>-1.622462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 1285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  1.134849  0.907687 -0.416385 -0.966814   \n",
       "1      id_000779bfc      72      D1  0.119282  0.681738  0.272399  0.080113   \n",
       "2      id_000a6266a      48      D1  0.779973  0.946463  1.425350 -0.132928   \n",
       "3      id_0015fd391      48      D1 -0.734910 -0.274641 -0.438509  0.759097   \n",
       "4      id_001626bd3      72      D2 -0.452718 -0.477513  0.972316  0.970731   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1  0.237856 -1.228203  0.218376 -0.365976   \n",
       "21944  id_fffb1ceed      24      D2  0.209361 -0.022389 -0.235888 -0.796989   \n",
       "21945  id_fffb70c0c      24      D2 -1.911021  0.587228 -0.588417  1.296405   \n",
       "21946  id_fffcb9e7c      24      D1  0.816407  0.417618  0.431631  0.300617   \n",
       "21947  id_ffffdd77b      72      D1 -1.243096  1.567730 -0.269573  1.083636   \n",
       "\n",
       "              4         5         6  ...  \\\n",
       "0     -0.254723 -1.017473 -1.364787  ...   \n",
       "1      1.205169  0.686517  0.313396  ...   \n",
       "2     -0.006122  1.492493  0.235577  ...   \n",
       "3      2.346330 -0.858153 -2.288417  ...   \n",
       "4      1.463427 -0.869555 -0.375501  ...   \n",
       "...         ...       ...       ...  ...   \n",
       "21943 -0.330177  0.569243 -0.150978  ...   \n",
       "21944 -0.674009  0.919312  0.735603  ...   \n",
       "21945 -1.002640  0.850589 -0.304313  ...   \n",
       "21946  1.070346 -0.024189  0.048942  ...   \n",
       "21947 -0.511235 -2.099634 -1.622462  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                                   0.000838      0.000540         0.002809   \n",
       "1                                   0.001504      0.003216         0.004645   \n",
       "2                                   0.000631      0.003011         0.003850   \n",
       "3                                   0.001118      0.002908         0.002429   \n",
       "4                                   0.001834      0.002123         0.004314   \n",
       "...                                      ...           ...              ...   \n",
       "21943                               0.000873      0.000658         0.003546   \n",
       "21944                               0.001077      0.000669         0.003029   \n",
       "21945                               0.000714      0.003098         0.004251   \n",
       "21946                               0.000378      0.000240         0.000879   \n",
       "21947                               0.000555      0.003495         0.001472   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0               0.001458                   0.001181   \n",
       "1               0.005326                   0.004050   \n",
       "2               0.001351                   0.020551   \n",
       "3               0.104720                   0.003758   \n",
       "4               0.001826                   0.003485   \n",
       "...                  ...                        ...   \n",
       "21943           0.000345                   0.001008   \n",
       "21944           0.001465                   0.001537   \n",
       "21945           0.000294                   0.019630   \n",
       "21946           0.001592                   0.001604   \n",
       "21947           0.011478                   0.002752   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                   0.000739         0.000547   0.002032   \n",
       "1                                   0.000679         0.001483   0.002844   \n",
       "2                                   0.001575         0.307875   0.000941   \n",
       "3                                   0.001489         0.002399   0.001373   \n",
       "4                                   0.001336         0.001609   0.002830   \n",
       "...                                      ...              ...        ...   \n",
       "21943                               0.001680         0.006100   0.001703   \n",
       "21944                               0.001051         0.001604   0.001873   \n",
       "21945                               0.000835         0.017936   0.001747   \n",
       "21946                               0.000386         0.000796   0.000390   \n",
       "21947                               0.001039         0.002097   0.001109   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                        0.000300       0.001982  \n",
       "1                        0.001748       0.002967  \n",
       "2                        0.000467       0.001430  \n",
       "3                        0.000207       0.000712  \n",
       "4                        0.000616       0.003128  \n",
       "...                           ...            ...  \n",
       "21943                    0.001223       0.001372  \n",
       "21944                    0.000750       0.001789  \n",
       "21945                    0.027558       0.002846  \n",
       "21946                    0.000196       0.000564  \n",
       "21947                    0.000519       0.000627  \n",
       "\n",
       "[21948 rows x 1285 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.load('moa_oof_01844.npy')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
