{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything(seed=42)\n",
    "\n",
    "\n",
    "def read_data(train_file, test_file, target_file, path='D:\\\\Dataset\\\\MOA\\\\',):\n",
    "    \n",
    "    df_train=pd.read_csv(os.path.join(path, train_file))\n",
    "    df_test=pd.read_csv(os.path.join(path, test_file))\n",
    "    df_target=pd.read_csv(os.path.join(path, target_file))\n",
    "    \n",
    "    print(df_train.shape, df_test.shape, df_target.shape, df_test.shape)\n",
    "    \n",
    "    return df_train, df_test, df_target, df_test\n",
    "\n",
    "\n",
    "def process_data(train, test, target):\n",
    "    df1 = train[train.cp_type!='ctl_vehicle'].reset_index(drop=True)\n",
    "    df2 = test[test.cp_type!='ctl_vehicle'].reset_index(drop=True)\n",
    "    \n",
    "    #Handle categorical variables\n",
    "    con_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "    con_df = pd.get_dummies(con_df, columns=['cp_type','cp_time','cp_dose']) \n",
    "    \n",
    "    #Train test splitter\n",
    "    train_df = con_df.iloc[:df1.shape[0],:]\n",
    "    test_df   = con_df.iloc[df1.shape[0]:,:]\n",
    "    \n",
    "    #Train data combiner\n",
    "    final_train = pd.merge(train_df, target, on='sig_id', how='left')\n",
    "\n",
    "    \n",
    "    print(final_train.shape)\n",
    "    \n",
    "    return final_train, test_df\n",
    "\n",
    "\n",
    "def create_folds(train, target, path='D:\\\\Dataset\\\\MOA\\\\'):\n",
    "    df=train.copy()\n",
    "    df[\"kfold\"] = -1\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    y = target.values\n",
    "    skf = MultilabelStratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "    for fold,(idxT,idxV) in enumerate(skf.split(X=df, y=target)):\n",
    "        df.loc[idxV, \"kfold\"] = fold\n",
    "    print(df.kfold.value_counts())\n",
    "    df.to_csv(os.path.join(path, \"train_folds.csv\"), index=False)\n",
    "    \n",
    "\n",
    "def Multi_log_loss(y_true, y_pred):\n",
    "\n",
    "    score = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        \n",
    "        log_score = metrics.log_loss(y_true[:,i].astype(float) , \n",
    "                                     y_pred[:,i].astype(float),\n",
    "                                     labels=sorted(np.unique(y_true))\n",
    "                                    \n",
    "                                    )\n",
    "        score.append(log_score)  \n",
    "        \n",
    "    return np.mean(np.array(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 876) (3982, 876) (23814, 207) (3982, 876)\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features, train_targets_scored, test_final = read_data('train_features.csv', 'test_features.csv', 'train_targets_scored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "transformer.fit(train_features.loc[:, GENES + CELLS])\n",
    "train_features[GENES + CELLS] = transformer.transform(train_features.loc[:, GENES + CELLS])\n",
    "\n",
    "dump(transformer, 'rank_1858_5fold_sub.bin', compress=True)\n",
    "\n",
    "\n",
    "test_features[GENES + CELLS] = transformer.transform(test_features.loc[:, GENES + CELLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from sklearn.decomposition import PCA\n",
    "    from joblib import dump, load\n",
    "    # GENES\n",
    "    n_comp = 100\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "    #data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "    \n",
    "    pca_genes = PCA(n_components=n_comp, random_state=42)\n",
    "    data2 = pca_genes.fit_transform(data[GENES])\n",
    "\n",
    "    dump(pca_genes, '1858_5fold_genes_sub.bin', compress=True)\n",
    "    \n",
    "    train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "    train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "    test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "    # drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "    train_features = pd.concat((train_features, train2), axis=1)\n",
    "    test_features = pd.concat((test_features, test2), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #CELLS\n",
    "    n_comp = 15\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "    #data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "    \n",
    "    pca_cells = PCA(n_components=n_comp, random_state=42)\n",
    "    data2 = pca_cells.fit_transform(data[CELLS])\n",
    "    \n",
    "    dump(pca_cells, '1858_5fold_cells_sub.bin', compress=True)\n",
    "    \n",
    "    train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "    train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "    test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "    # drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "    train_features = pd.concat((train_features, train2), axis=1)\n",
    "    test_features = pd.concat((test_features, test2), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    var_thresh = VarianceThreshold(threshold=0.5)\n",
    "    data = train_features.append(test_features)\n",
    "    data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "    dump(var_thresh, 'Variance_transform_1858_sub.bin', compress=True)\n",
    "    \n",
    "    train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "    test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "    train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "    train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "    test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "    test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "drug = pd.read_csv('D://Dataset//MOA//train_drug.csv')\n",
    "train = train.merge(drug, on='sig_id')\n",
    "\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    #data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    #data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "# --------------------- Normalize ---------------------\n",
    "#     for col in GENES:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#     for col in CELLS:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#--------------------- Removing Skewness ---------------------\n",
    "#     for col in GENES + CELLS:\n",
    "#         if(abs(data[col].skew()) > 0.75):\n",
    "            \n",
    "#             if(data[col].skew() < 0): # neg-skewness\n",
    "#                 data[col] = data[col].max() - data[col] + 1\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "            \n",
    "#             else:\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_folds(num_starts, num_splits, trn):\n",
    "\n",
    "    folds = []\n",
    "    scored = trn.copy()\n",
    "    #targets_ = scored.loc[:, train_targets_scored.columns].columns[1:].tolist()\n",
    "    #train_cols = train_features.columns.tolist() + ['fold','drug_id']\n",
    "    #train_cols = [col for col in train_cols if col!='cp_type']\n",
    "    # LOCATE DRUGS\n",
    "    vc = scored.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc <= 18].index.sort_values()\n",
    "    vc2 = vc.loc[vc > 18].index.sort_values()\n",
    "    \n",
    "    for seed in range(num_starts):\n",
    "    \n",
    "        # STRATIFY DRUGS 18X OR LESS\n",
    "        dct1 = {}; dct2 = {}\n",
    "        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state = seed)\n",
    "        tmp = scored.groupby('drug_id')[target_cols].mean().loc[vc1]\n",
    "        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "            dd = {k:fold for k in tmp.index[idxV].values}\n",
    "            dct1.update(dd)\n",
    "    \n",
    "        # STRATIFY DRUGS MORE THAN 18X\n",
    "        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state = seed)\n",
    "        tmp = scored.loc[scored.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "            dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "            dct2.update(dd)\n",
    "    \n",
    "        # ASSIGN FOLDS\n",
    "        scored['fold'] = scored.drug_id.map(dct1)\n",
    "        scored.loc[scored.fold.isna(),'fold'] =\\\n",
    "            scored.loc[scored.fold.isna(),'sig_id'].map(dct2)\n",
    "        scored.fold = scored.fold.astype('int8')\n",
    "        folds.append(scored.fold.values)\n",
    "        #train_cols = train_feats.columns.tolist() + ['fold','drug_id']\n",
    "        #train_feats_main = train_feats_.merge(scored, on='sig_id', how='left')\n",
    "        #train_feats_main['fold'] = train_feats_main['fold'].astype(int)\n",
    "        \n",
    "    return scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds= create_folds(1, 10, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1197)\n",
      "(21948, 1198)\n",
      "(3624, 990)\n",
      "(21948, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "def train_fn(model, optimizer,scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.5, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.register_buffer('noise', torch.tensor(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.expand(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size, dropout):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_features, hidden_size)\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.dense3 = nn.Linear(hidden_size, num_targets)\n",
    "        #bias_ = torch.Tensor(bias)\n",
    "        #print(self.dense3.bias.data)\n",
    "        #nn.init.xavier_normal_(self.dense3.weight)\n",
    "        #self.dense3.bias = torch.nn.Parameter(_bias)\n",
    "        self.gausian = GaussianNoise()\n",
    "        #self.relu=nn.PReLU()\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        #x = self.gausian(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.gausian(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['fold','sig_id','drug_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1858_5fold_feature_cols_sub.bin']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(target_cols, '1858_5fold_target_cols_sub.bin')\n",
    "dump(feature_cols, '1858_5fold_feature_cols_sub.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 2.629318926022435e-05\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 10\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "\n",
    "hidden_size=1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    trn_idx = train[train['fold'] != fold].index\n",
    "    val_idx = train[train['fold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['fold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['fold'] == fold].reset_index(drop=True)\n",
    "    #print(train_df[feature_cols].head())\n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    #a = -np.log(y_train.mean(axis=0))\n",
    "    #print(torch.Tensor(a))\n",
    "    \n",
    "    model = Model(\n",
    "        num_features = num_features,\n",
    "        num_targets = num_targets,\n",
    "        hidden_size = 1400,\n",
    "        dropout = 0.10721077648722396\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"D:\\\\MOA_Pretrained_Models\\\\1858_10folds _moa_sub\\\\{fold}_{seed}.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features = num_features,\n",
    "        num_targets = num_targets,\n",
    "        hidden_size = 1400,\n",
    "        dropout = 0.10721077648722396\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"D:\\\\MOA_Pretrained_Models\\\\1858_10folds _moa_sub\\\\{fold}_{seed}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), len(target_cols)))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return   oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.6755095791432165\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.36395814488915834\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.06094682125314589\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02016482567962478\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023060176341283704\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01964694940868546\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.02251327498064887\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.022578860578291556\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.022465917203695545\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.019615361467003822\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.02134100139862107\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018166171058135873\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.020569118316615783\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017978368874858406\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020363950765421315\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01795531710719361\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020342902118159877\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018154084572897237\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020383070565519794\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.018132821273277786\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.02042192569182765\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01831897282425095\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.020491197801405382\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.018128677326090196\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.02057071102242316\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018133342375650126\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.020566886735539282\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.018210229518658975\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.020702660876897074\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.018228857175392264\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.020732433649320755\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.01804160129498033\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.020664781896818068\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.018435076317366433\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.020749217067514696\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.018354702412205583\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.020827574883737873\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.018180675256778214\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.02083390178459306\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.018140347455354297\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.020843672055390575\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018360332859789625\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.020824742990155375\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.018287936115966123\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.020854056890933743\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.018268557265400887\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.0208039817189978\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.018161813016323483\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.02076494396934586\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.018227693789145526\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.0208131586111361\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.01815112220013843\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.020745192936831906\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.01844329638954471\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.020776161899970422\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.018295469967757955\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.020645936939024157\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01818706445834216\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.020714807918956205\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.01839167800019769\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.020613279914663683\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.018229677944498902\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.020560108317482857\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.018173646181821823\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.02048325721294649\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.018239814788103104\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.020341628044843674\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.017805743633824235\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.020267648982905572\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.01782505740137661\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.02015094640514543\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.017860728261225364\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.020047375980404115\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.01761844480300651\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.0199600005822797\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.01781389917082646\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.01987015821280018\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.017481353681753662\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.019690380317549553\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.017642668010119128\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.019578230164704783\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.01743495464324951\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.019472070134455156\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.01734204447883017\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.01926211342215538\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.01736195642939385\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.019184600177311127\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.017398587154114947\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.018992624335712003\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.017403207938460744\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.018871844451754324\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.017443967435289833\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.01872772621291299\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.0173508222488796\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.018529941093537117\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.01719607867519645\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.018333629969387286\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.0173598897698171\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.01821689505971247\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.017356579904170596\n",
      "FOLD: 0, EPOCH: 50, train_loss: 0.018026537153749696\n",
      "FOLD: 0, EPOCH: 50, valid_loss: 0.017274981200256768\n",
      "FOLD: 0, EPOCH: 51, train_loss: 0.017864704059977685\n",
      "FOLD: 0, EPOCH: 51, valid_loss: 0.017237751470769152\n",
      "FOLD: 0, EPOCH: 52, train_loss: 0.017710647347473327\n",
      "FOLD: 0, EPOCH: 52, valid_loss: 0.017283396028420505\n",
      "FOLD: 0, EPOCH: 53, train_loss: 0.017583138988383356\n",
      "FOLD: 0, EPOCH: 53, valid_loss: 0.017304018139839172\n",
      "FOLD: 0, EPOCH: 54, train_loss: 0.017457765503035436\n",
      "FOLD: 0, EPOCH: 54, valid_loss: 0.017224136027781403\n",
      "FOLD: 0, EPOCH: 55, train_loss: 0.017306550634243797\n",
      "FOLD: 0, EPOCH: 55, valid_loss: 0.017242754261721584\n",
      "FOLD: 0, EPOCH: 56, train_loss: 0.017198518885960502\n",
      "FOLD: 0, EPOCH: 56, valid_loss: 0.017234854674076334\n",
      "FOLD: 0, EPOCH: 57, train_loss: 0.017134594592836595\n",
      "FOLD: 0, EPOCH: 57, valid_loss: 0.017242355765227008\n",
      "FOLD: 0, EPOCH: 58, train_loss: 0.017099347812754493\n",
      "FOLD: 0, EPOCH: 58, valid_loss: 0.017216887325048447\n",
      "FOLD: 0, EPOCH: 59, train_loss: 0.017073636111472883\n",
      "FOLD: 0, EPOCH: 59, valid_loss: 0.017220092608648187\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.675967788696289\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.35029807852374184\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.061098210970240256\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02045303365836541\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02302483184443366\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.019289295059732266\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.02285780904273833\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.024950439317358866\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.023244154597482372\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.02017066374214159\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.020977210577937864\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.018168247977478638\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020522981173088473\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01823765489583214\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.020268464629207887\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.018202090584155586\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.02023060088676791\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.018260267252723377\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020291384213393736\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01817662672450145\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.020320987136613938\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.018623455944988463\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.02041824076685213\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018407020045237407\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.02044780987405008\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01871744626098209\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.020524388864155738\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.019018555680910747\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.020599125145423797\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.018489030448512897\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.02058015513804651\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018270589721699555\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.020690514387622955\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.018427759564171236\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.020731755658503503\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01868734596711066\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.020842139422893525\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.018862197848243847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 19, train_loss: 0.02081239353264532\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.018581001553684473\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.020816698682404332\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01851999040486084\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.02077836972330847\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01834105596774154\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.020793574087081417\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.018584174052294757\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.02075691372156143\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018663116834229894\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.02074945077540413\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01859367209383183\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.02078195781477036\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.018536794671995774\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.020693598038727237\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.018677412014868524\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.020706383355202213\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.018505439007033903\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.020637092607155922\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.018791343706349533\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.020605378369650533\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.01854532098190652\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.02052254392014396\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.018134448315120406\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.02048122344478484\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018221510988142755\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.020454146316455257\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018375371841506824\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.020299713890398703\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.01819400556592478\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.020132932451463515\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.018258640335665807\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.02007843999853057\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.01801948533910844\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.02003100031325894\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.01792322440693776\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.019912590723364584\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.017895657413949568\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.019809193320332034\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.01788159009690086\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.01966475564385614\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.01775685278698802\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.019526431853732755\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.017858329849938553\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.019379167739422092\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.0178363730923997\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.01931832956690942\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.017606715361277264\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.019072134528429277\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.01780252241426044\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.018982082749566725\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.0176051066050099\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.018912509684601137\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.01769805782371097\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.01870099969448582\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.0174838793464005\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.01855166493764808\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.01757408187000288\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.018361685401008975\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.017589313702450857\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.018207914712688615\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.017645823251869943\n",
      "FOLD: 1, EPOCH: 50, train_loss: 0.018005830476120595\n",
      "FOLD: 1, EPOCH: 50, valid_loss: 0.01754087649492754\n",
      "FOLD: 1, EPOCH: 51, train_loss: 0.017824939500179982\n",
      "FOLD: 1, EPOCH: 51, valid_loss: 0.017558451121052105\n",
      "FOLD: 1, EPOCH: 52, train_loss: 0.017691206042805024\n",
      "FOLD: 1, EPOCH: 52, valid_loss: 0.01755515020340681\n",
      "FOLD: 1, EPOCH: 53, train_loss: 0.017545876658010866\n",
      "FOLD: 1, EPOCH: 53, valid_loss: 0.01765883108600974\n",
      "FOLD: 1, EPOCH: 54, train_loss: 0.017408189970639445\n",
      "FOLD: 1, EPOCH: 54, valid_loss: 0.01755826697788305\n",
      "FOLD: 1, EPOCH: 55, train_loss: 0.01728025618940592\n",
      "FOLD: 1, EPOCH: 55, valid_loss: 0.017550783542295296\n",
      "FOLD: 1, EPOCH: 56, train_loss: 0.017183163287418503\n",
      "FOLD: 1, EPOCH: 56, valid_loss: 0.017579105372230213\n",
      "FOLD: 1, EPOCH: 57, train_loss: 0.01711382557067179\n",
      "FOLD: 1, EPOCH: 57, valid_loss: 0.017576785809877846\n",
      "FOLD: 1, EPOCH: 58, train_loss: 0.017056942298527687\n",
      "FOLD: 1, EPOCH: 58, valid_loss: 0.01756353945367866\n",
      "FOLD: 1, EPOCH: 59, train_loss: 0.017031031732838\n",
      "FOLD: 1, EPOCH: 59, valid_loss: 0.017546725769837696\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6764162988431992\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.34593789445029366\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.06145405229781904\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020821856127844915\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023054008918904488\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019992402858204313\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.02426064469881596\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.024821656342181895\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.02603211294739477\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018869533358762663\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.021923635695730487\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.018536498459676903\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.021240626756222018\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018727963583336935\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020798641178877125\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018015180559207995\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020604873472644437\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.018064951420658164\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.02054309956729412\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01865903277777963\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.0205386511380634\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.018369724974036217\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.02060094089998353\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018811437611778576\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.020551733276055705\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018161789048463106\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.02066398956362278\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01821932600190242\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.020607785736360858\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018637815697325602\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.0207021685737756\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.018270234163436625\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.020795978846088532\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.018686132609016366\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.020782971514328834\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01816584262996912\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.02070560225796315\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01841789825508992\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.02085253591499021\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.0183701744923989\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.02086822819565573\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01840679854568508\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.020800543444291237\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01854424023379882\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.020788811904288107\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018290222415493593\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.020855163206015864\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.018466408260994487\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.020906461270586138\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018166991882026196\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.020784243953324132\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.01812704098928306\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.0207212250799902\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01814052452229791\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.020731717203893968\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01840981271945768\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.020697833032857986\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.01797158359032538\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.020604770690683397\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.01804693193278379\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.020642691309894285\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.017908674095653825\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.02052064711047757\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.017861609450644918\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.020496562327588758\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017696871577451628\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.020373840966532306\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017876107297423813\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.020282947872915576\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.017908167507913377\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.02013652730853327\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.017816717374242015\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.020072112136310147\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.01755933975800872\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.01998794740967212\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.01767961670541101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 38, train_loss: 0.019881325239135373\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.017589439327518146\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.019743510083325446\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.017416614211267896\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.01958864872013369\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.017400235920730565\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.01944984848941526\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.017473640023834176\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.019428580795084277\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.01747745011622707\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.019277814379142177\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.01727072284039524\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.019142266236726314\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.01734085732864009\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.01890081726014614\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017358416174021032\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.018791468982254304\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.017228804270012513\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.01863703273477093\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.017311291665666632\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.018447545543313026\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.017329588066786528\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.018271215860882112\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.017193941606415644\n",
      "FOLD: 2, EPOCH: 50, train_loss: 0.01811752550664448\n",
      "FOLD: 2, EPOCH: 50, valid_loss: 0.01727308353616132\n",
      "FOLD: 2, EPOCH: 51, train_loss: 0.017903681147483086\n",
      "FOLD: 2, EPOCH: 51, valid_loss: 0.017155967342356842\n",
      "FOLD: 2, EPOCH: 52, train_loss: 0.017764409252953146\n",
      "FOLD: 2, EPOCH: 52, valid_loss: 0.017154953701214656\n",
      "FOLD: 2, EPOCH: 53, train_loss: 0.01761258057048244\n",
      "FOLD: 2, EPOCH: 53, valid_loss: 0.017208035776598588\n",
      "FOLD: 2, EPOCH: 54, train_loss: 0.01745382135193194\n",
      "FOLD: 2, EPOCH: 54, valid_loss: 0.017202083642284077\n",
      "FOLD: 2, EPOCH: 55, train_loss: 0.017302068995852623\n",
      "FOLD: 2, EPOCH: 55, valid_loss: 0.017217236726234358\n",
      "FOLD: 2, EPOCH: 56, train_loss: 0.01723428665990791\n",
      "FOLD: 2, EPOCH: 56, valid_loss: 0.017212418528894585\n",
      "FOLD: 2, EPOCH: 57, train_loss: 0.01715370144454702\n",
      "FOLD: 2, EPOCH: 57, valid_loss: 0.01723040459263656\n",
      "FOLD: 2, EPOCH: 58, train_loss: 0.01710319462562761\n",
      "FOLD: 2, EPOCH: 58, valid_loss: 0.01724994048062298\n",
      "FOLD: 2, EPOCH: 59, train_loss: 0.017146541076081413\n",
      "FOLD: 2, EPOCH: 59, valid_loss: 0.017232541874465015\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6756860290804217\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.3817013700803121\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.061479593705265755\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020251937107079558\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02340969618770384\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01988880869208111\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.02328008504644517\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.040921194996270865\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.02229343301826908\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.018319079135027196\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.021899144675943158\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01787362578842375\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.02080241161729059\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.018140069881661072\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020496384138541837\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01762840710580349\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.02034087245382609\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017609900587962732\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020386321253834234\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01776957729210456\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.02046628867185885\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017631451444079477\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.02051113109675146\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.018052286002784967\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.020543438640813674\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.018089100511537656\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.020612523127948083\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01807341890202628\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.020644080374510057\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017928703584604792\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.020735802164962215\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.018127096454716392\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.02071420428974013\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01787452135855953\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.02083638914890828\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.0182151191143526\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.02079739216114244\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01793278107005689\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.020809017193894233\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.018236609537982278\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.02088574274413047\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017886102872176304\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.020935738182836963\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.018220428532610338\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.020881123131802005\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01813372090044949\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020899857304269267\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01799830085494452\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020816090054089024\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.018241185177531507\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.020852380570384764\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.017733050665507715\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.020789509494939157\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.018201361720760662\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.020736092232888744\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.018229533038619492\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.020846002633052488\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01794486404913995\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.020663391882854123\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.017561963241961267\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.02051305886237852\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.017733337823301554\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.020514723850834755\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.017585776798013184\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.020466887049617306\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.017644162703719404\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.02034358200767348\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.01778992648339934\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.02021576198599031\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.017658003761122625\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.020246879011392594\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.017308418949445088\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.02009019337354168\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.017399119161483314\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.01992727825718541\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017348304390907288\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.019894876258988534\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.017206485745393567\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.01973458509291372\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.017135681636217568\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.019645719855062423\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017220927816298272\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.019495546745677148\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.017034113200174436\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.019360152019127722\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.017150069173011515\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.01917875032992132\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.016919572941131063\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.01905443913513614\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.017030655561635893\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.01894356103674058\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.016884028704630002\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.01880740861017858\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.016760035521454282\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.01858792704560103\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.016797777420530718\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.018445316828306645\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.016809555753651593\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.018264878565265288\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.01688842697896891\n",
      "FOLD: 3, EPOCH: 50, train_loss: 0.018125479169670614\n",
      "FOLD: 3, EPOCH: 50, valid_loss: 0.01680866302922368\n",
      "FOLD: 3, EPOCH: 51, train_loss: 0.017940453752394645\n",
      "FOLD: 3, EPOCH: 51, valid_loss: 0.016834010370075703\n",
      "FOLD: 3, EPOCH: 52, train_loss: 0.017719222316818852\n",
      "FOLD: 3, EPOCH: 52, valid_loss: 0.016732668090197775\n",
      "FOLD: 3, EPOCH: 53, train_loss: 0.017583366639671787\n",
      "FOLD: 3, EPOCH: 53, valid_loss: 0.016759104405840237\n",
      "FOLD: 3, EPOCH: 54, train_loss: 0.0174510044256045\n",
      "FOLD: 3, EPOCH: 54, valid_loss: 0.016781208622786734\n",
      "FOLD: 3, EPOCH: 55, train_loss: 0.01734601223180371\n",
      "FOLD: 3, EPOCH: 55, valid_loss: 0.016824284051027562\n",
      "FOLD: 3, EPOCH: 56, train_loss: 0.017256724894527467\n",
      "FOLD: 3, EPOCH: 56, valid_loss: 0.016787064986096487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 57, train_loss: 0.017188975281052052\n",
      "FOLD: 3, EPOCH: 57, valid_loss: 0.01678875730269485\n",
      "FOLD: 3, EPOCH: 58, train_loss: 0.017122101092771177\n",
      "FOLD: 3, EPOCH: 58, valid_loss: 0.01680145924910903\n",
      "FOLD: 3, EPOCH: 59, train_loss: 0.017103214543913642\n",
      "FOLD: 3, EPOCH: 59, valid_loss: 0.01679219202035003\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6769494147069992\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.38718157675531173\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.06167349284214358\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020256776155696973\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023346074622484947\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01851510453141398\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.023229821963656333\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.018103088873128097\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.021204670302329524\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01732971239835024\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.020915964954803065\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.3760144743654463\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.023794447955104613\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01866224066664775\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.021553328729444935\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.018347705921365157\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.021232734896963642\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017951938323676586\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.021198650954231138\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018498220584458776\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.021154695364736742\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017967146148698196\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.021123009451454684\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01783969599960579\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.021259654277274685\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017938497321059305\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.021170096640144624\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.018188456280363932\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.02118770684446058\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01809165994119313\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.021165582405463342\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017881116312411096\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.021116173303415697\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01823057762036721\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.0211328465251192\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.017826908112814028\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.021164462318824184\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.018614696235292487\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.021176907672516763\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.017999300681468513\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.021025282336819558\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01799650847290953\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.021131958271707257\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.018016518507566717\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.021107489147013235\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.018000676503611937\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.02118699065139217\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01815516584449344\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.02100446047561784\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.017980330623686314\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.021061917310280183\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.017983762236932915\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.02096439339220524\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.017835401826434664\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.020954634393415144\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.01824537230034669\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.02088213337044562\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.01773144242664178\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.02080063625208793\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01810684660449624\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.020730244488485396\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.017659751905335322\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.02065044622267446\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.017610245746456914\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.020595334362118474\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017449098225269053\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.02046373236563898\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.017171665094792843\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.020351799301082087\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.017315360872695845\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.020289898663759232\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.017294286232855585\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.020150168594573775\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.017237079795449972\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.02003503021213316\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.016980738948202796\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.019960269872700016\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017059255184398756\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.01989394125919188\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.017291485331952572\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.019738792567964524\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.016924382653087378\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.01953459663256522\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.016887631474269763\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.019502564291319538\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.016991690939499274\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.01934274094960382\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.01687505587728487\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.019136222229609565\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.016872986788964935\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.018984086883644904\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.016766854147944186\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.018837329240575913\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.016750678316586547\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.018667902448965656\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.016873587905946705\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.01851648839130517\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.01667629151294629\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.01825926171675805\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.016682369944949944\n",
      "FOLD: 4, EPOCH: 50, train_loss: 0.0180632543059126\n",
      "FOLD: 4, EPOCH: 50, valid_loss: 0.016760846134275198\n",
      "FOLD: 4, EPOCH: 51, train_loss: 0.017879721071691283\n",
      "FOLD: 4, EPOCH: 51, valid_loss: 0.016740323199580114\n",
      "FOLD: 4, EPOCH: 52, train_loss: 0.017660233132060495\n",
      "FOLD: 4, EPOCH: 52, valid_loss: 0.016779532035191853\n",
      "FOLD: 4, EPOCH: 53, train_loss: 0.017478820056684555\n",
      "FOLD: 4, EPOCH: 53, valid_loss: 0.016800395989169676\n",
      "FOLD: 4, EPOCH: 54, train_loss: 0.017252159497189907\n",
      "FOLD: 4, EPOCH: 54, valid_loss: 0.016757300227052636\n",
      "FOLD: 4, EPOCH: 55, train_loss: 0.01712763876083397\n",
      "FOLD: 4, EPOCH: 55, valid_loss: 0.016746282060113218\n",
      "FOLD: 4, EPOCH: 56, train_loss: 0.016961207493178306\n",
      "FOLD: 4, EPOCH: 56, valid_loss: 0.01677120906404323\n",
      "FOLD: 4, EPOCH: 57, train_loss: 0.016895238886917793\n",
      "FOLD: 4, EPOCH: 57, valid_loss: 0.016715421807020903\n",
      "FOLD: 4, EPOCH: 58, train_loss: 0.016769342244632782\n",
      "FOLD: 4, EPOCH: 58, valid_loss: 0.016718865527460974\n",
      "FOLD: 4, EPOCH: 59, train_loss: 0.01681568078216045\n",
      "FOLD: 4, EPOCH: 59, valid_loss: 0.016743417208393414\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.6762121092888617\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.34858213033941055\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.06149000759807325\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.020112056699064042\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.023391857719229112\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.024066544758776825\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.025652477097126744\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.019042103965249326\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.02233242567989134\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.0897054909211066\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.022039210363741842\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.02025587535980675\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.0211229229406003\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.018560202171405155\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.020565669611096384\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.018499343656003475\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.020491849679139352\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.01847248576167557\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.020438562778215253\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.01869425984720389\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.020431625001853512\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.01894714165892866\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.020411319033272805\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.018653624794549413\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.020436744415952314\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.018844668960405722\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.02050479479855107\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.01864127514676915\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.02065067175895937\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.01856178552326229\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.02057529389858246\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.01888824471582969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 5, EPOCH: 16, train_loss: 0.02068146486436167\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.01949269448717435\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.020765244420016964\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.0187286204761929\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.020798111959330498\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.01919536478817463\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.02080445304032295\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.01879189329014884\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.0207643372397269\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.01867556261519591\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.02077473644768038\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.019319089853929147\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.020743354319805098\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.018653179570618603\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.020849509849663703\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.01864920411672857\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.020729336953691897\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.018500335204104584\n",
      "FOLD: 5, EPOCH: 25, train_loss: 0.020803929853343194\n",
      "FOLD: 5, EPOCH: 25, valid_loss: 0.018983144623537857\n",
      "FOLD: 5, EPOCH: 26, train_loss: 0.020706518354915802\n",
      "FOLD: 5, EPOCH: 26, valid_loss: 0.018626053921050496\n",
      "FOLD: 5, EPOCH: 27, train_loss: 0.020776668455331555\n",
      "FOLD: 5, EPOCH: 27, valid_loss: 0.018637994511259928\n",
      "FOLD: 5, EPOCH: 28, train_loss: 0.02070656262578503\n",
      "FOLD: 5, EPOCH: 28, valid_loss: 0.019007235248055723\n",
      "FOLD: 5, EPOCH: 29, train_loss: 0.020626526482162937\n",
      "FOLD: 5, EPOCH: 29, valid_loss: 0.01864381331122584\n",
      "FOLD: 5, EPOCH: 30, train_loss: 0.02053640369446047\n",
      "FOLD: 5, EPOCH: 30, valid_loss: 0.018488072583244905\n",
      "FOLD: 5, EPOCH: 31, train_loss: 0.020504990376291738\n",
      "FOLD: 5, EPOCH: 31, valid_loss: 0.01858710166480806\n",
      "FOLD: 5, EPOCH: 32, train_loss: 0.020367978381053094\n",
      "FOLD: 5, EPOCH: 32, valid_loss: 0.01821635839425855\n",
      "FOLD: 5, EPOCH: 33, train_loss: 0.020299796207297233\n",
      "FOLD: 5, EPOCH: 33, valid_loss: 0.018580252925554912\n",
      "FOLD: 5, EPOCH: 34, train_loss: 0.02027430646121502\n",
      "FOLD: 5, EPOCH: 34, valid_loss: 0.018012597173866298\n",
      "FOLD: 5, EPOCH: 35, train_loss: 0.0200857151660227\n",
      "FOLD: 5, EPOCH: 35, valid_loss: 0.018009913567867544\n",
      "FOLD: 5, EPOCH: 36, train_loss: 0.019993779051207725\n",
      "FOLD: 5, EPOCH: 36, valid_loss: 0.018247100835045178\n",
      "FOLD: 5, EPOCH: 37, train_loss: 0.01987767429842103\n",
      "FOLD: 5, EPOCH: 37, valid_loss: 0.018109018707440958\n",
      "FOLD: 5, EPOCH: 38, train_loss: 0.019811200650949632\n",
      "FOLD: 5, EPOCH: 38, valid_loss: 0.017972669874628384\n",
      "FOLD: 5, EPOCH: 39, train_loss: 0.019696274087313684\n",
      "FOLD: 5, EPOCH: 39, valid_loss: 0.017995568509731028\n",
      "FOLD: 5, EPOCH: 40, train_loss: 0.01956646176836183\n",
      "FOLD: 5, EPOCH: 40, valid_loss: 0.017998502020620637\n",
      "FOLD: 5, EPOCH: 41, train_loss: 0.019409841323091138\n",
      "FOLD: 5, EPOCH: 41, valid_loss: 0.01799032236966822\n",
      "FOLD: 5, EPOCH: 42, train_loss: 0.01928929292386578\n",
      "FOLD: 5, EPOCH: 42, valid_loss: 0.018017969094216824\n",
      "FOLD: 5, EPOCH: 43, train_loss: 0.019283965842858436\n",
      "FOLD: 5, EPOCH: 43, valid_loss: 0.017812881670478318\n",
      "FOLD: 5, EPOCH: 44, train_loss: 0.019101567013609794\n",
      "FOLD: 5, EPOCH: 44, valid_loss: 0.01791894632495112\n",
      "FOLD: 5, EPOCH: 45, train_loss: 0.018831651219196856\n",
      "FOLD: 5, EPOCH: 45, valid_loss: 0.017875578047500715\n",
      "FOLD: 5, EPOCH: 46, train_loss: 0.01870452756843259\n",
      "FOLD: 5, EPOCH: 46, valid_loss: 0.01788139431219962\n",
      "FOLD: 5, EPOCH: 47, train_loss: 0.01848265706531463\n",
      "FOLD: 5, EPOCH: 47, valid_loss: 0.01786294895120793\n",
      "FOLD: 5, EPOCH: 48, train_loss: 0.01832456134500042\n",
      "FOLD: 5, EPOCH: 48, valid_loss: 0.017837019482006628\n",
      "FOLD: 5, EPOCH: 49, train_loss: 0.01814908748192172\n",
      "FOLD: 5, EPOCH: 49, valid_loss: 0.017779214307665825\n",
      "FOLD: 5, EPOCH: 50, train_loss: 0.01792012078747634\n",
      "FOLD: 5, EPOCH: 50, valid_loss: 0.01784639469244414\n",
      "FOLD: 5, EPOCH: 51, train_loss: 0.01781960998571688\n",
      "FOLD: 5, EPOCH: 51, valid_loss: 0.01777685024879045\n",
      "FOLD: 5, EPOCH: 52, train_loss: 0.017659265535973735\n",
      "FOLD: 5, EPOCH: 52, valid_loss: 0.017773620836022828\n",
      "FOLD: 5, EPOCH: 53, train_loss: 0.017434119799685094\n",
      "FOLD: 5, EPOCH: 53, valid_loss: 0.017737987865176465\n",
      "FOLD: 5, EPOCH: 54, train_loss: 0.017308218242420303\n",
      "FOLD: 5, EPOCH: 54, valid_loss: 0.01775060614777936\n",
      "FOLD: 5, EPOCH: 55, train_loss: 0.017176922008154853\n",
      "FOLD: 5, EPOCH: 55, valid_loss: 0.017768086969024606\n",
      "FOLD: 5, EPOCH: 56, train_loss: 0.017068520314510793\n",
      "FOLD: 5, EPOCH: 56, valid_loss: 0.017783896014508273\n",
      "FOLD: 5, EPOCH: 57, train_loss: 0.01697152986401512\n",
      "FOLD: 5, EPOCH: 57, valid_loss: 0.01781370671879914\n",
      "FOLD: 5, EPOCH: 58, train_loss: 0.016940020589578535\n",
      "FOLD: 5, EPOCH: 58, valid_loss: 0.017757297234816685\n",
      "FOLD: 5, EPOCH: 59, train_loss: 0.01693052471645417\n",
      "FOLD: 5, EPOCH: 59, valid_loss: 0.01778106815699074\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.6761575931502927\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.3575357338961433\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.06202988520024284\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.02099571727654513\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.022927816584706308\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.019511595477952677\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.02231389967904937\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.019296109895495808\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.02137792287093978\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.019120399785392424\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.023595768850176564\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.019469403826138553\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.021434847385652604\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.019818019998424193\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.02089516283763993\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.018930898650604135\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.020740678161382677\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.01878795400261879\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.020773063948558223\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.018756373401950386\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.020667405991304306\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.019415145739912987\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.02075682686221215\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.01913027826915769\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.02068598429041524\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.019083347500247115\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.020685557672573674\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.01915305173572372\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.020667274043925345\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.018841657732777736\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.02067550628656341\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.01868849335347905\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.020695444797315905\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.018933256868930423\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.020717807306397346\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.018800940693301314\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.02070875491105741\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.019018052693675545\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.02073609378309019\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.018877132193130607\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.020751573818345224\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.018771563820979175\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.02077254758727166\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.019104686510913512\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.020725064075762224\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.018703235970700487\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.020782170733136516\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.019067032700952363\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.020768645225513367\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.01876114571795744\n",
      "FOLD: 6, EPOCH: 25, train_loss: 0.02066034773184407\n",
      "FOLD: 6, EPOCH: 25, valid_loss: 0.018761434208820846\n",
      "FOLD: 6, EPOCH: 26, train_loss: 0.020652294795840017\n",
      "FOLD: 6, EPOCH: 26, valid_loss: 0.018602853640913963\n",
      "FOLD: 6, EPOCH: 27, train_loss: 0.020636991832044815\n",
      "FOLD: 6, EPOCH: 27, valid_loss: 0.018551746383309364\n",
      "FOLD: 6, EPOCH: 28, train_loss: 0.0205609476253871\n",
      "FOLD: 6, EPOCH: 28, valid_loss: 0.018578885999672553\n",
      "FOLD: 6, EPOCH: 29, train_loss: 0.020511599606083286\n",
      "FOLD: 6, EPOCH: 29, valid_loss: 0.018912569784066257\n",
      "FOLD: 6, EPOCH: 30, train_loss: 0.02048323818993184\n",
      "FOLD: 6, EPOCH: 30, valid_loss: 0.018684392685399336\n",
      "FOLD: 6, EPOCH: 31, train_loss: 0.020379012378473435\n",
      "FOLD: 6, EPOCH: 31, valid_loss: 0.01853254919542986\n",
      "FOLD: 6, EPOCH: 32, train_loss: 0.02028862189862036\n",
      "FOLD: 6, EPOCH: 32, valid_loss: 0.018532116842620513\n",
      "FOLD: 6, EPOCH: 33, train_loss: 0.020226325190836385\n",
      "FOLD: 6, EPOCH: 33, valid_loss: 0.01834615582928938\n",
      "FOLD: 6, EPOCH: 34, train_loss: 0.020149736334719965\n",
      "FOLD: 6, EPOCH: 34, valid_loss: 0.018552391515935168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 6, EPOCH: 35, train_loss: 0.02000965772857589\n",
      "FOLD: 6, EPOCH: 35, valid_loss: 0.018512804828145924\n",
      "FOLD: 6, EPOCH: 36, train_loss: 0.01998361022241654\n",
      "FOLD: 6, EPOCH: 36, valid_loss: 0.01816848380600705\n",
      "FOLD: 6, EPOCH: 37, train_loss: 0.019809434959484683\n",
      "FOLD: 6, EPOCH: 37, valid_loss: 0.018214275293490467\n",
      "FOLD: 6, EPOCH: 38, train_loss: 0.019729896154134504\n",
      "FOLD: 6, EPOCH: 38, valid_loss: 0.01818092819303274\n",
      "FOLD: 6, EPOCH: 39, train_loss: 0.01957275264205471\n",
      "FOLD: 6, EPOCH: 39, valid_loss: 0.01809727307409048\n",
      "FOLD: 6, EPOCH: 40, train_loss: 0.019533906156016936\n",
      "FOLD: 6, EPOCH: 40, valid_loss: 0.018210962853010965\n",
      "FOLD: 6, EPOCH: 41, train_loss: 0.019393875173503352\n",
      "FOLD: 6, EPOCH: 41, valid_loss: 0.01801682367701741\n",
      "FOLD: 6, EPOCH: 42, train_loss: 0.01928744274041345\n",
      "FOLD: 6, EPOCH: 42, valid_loss: 0.01797954968231566\n",
      "FOLD: 6, EPOCH: 43, train_loss: 0.019117478389413127\n",
      "FOLD: 6, EPOCH: 43, valid_loss: 0.017886425532838878\n",
      "FOLD: 6, EPOCH: 44, train_loss: 0.019026955505532604\n",
      "FOLD: 6, EPOCH: 44, valid_loss: 0.01785261244239176\n",
      "FOLD: 6, EPOCH: 45, train_loss: 0.0188138151120755\n",
      "FOLD: 6, EPOCH: 45, valid_loss: 0.017764887882067877\n",
      "FOLD: 6, EPOCH: 46, train_loss: 0.018651784704096855\n",
      "FOLD: 6, EPOCH: 46, valid_loss: 0.01790055610677775\n",
      "FOLD: 6, EPOCH: 47, train_loss: 0.018475977042990345\n",
      "FOLD: 6, EPOCH: 47, valid_loss: 0.017787382006645203\n",
      "FOLD: 6, EPOCH: 48, train_loss: 0.01833029096165011\n",
      "FOLD: 6, EPOCH: 48, valid_loss: 0.017834803746903643\n",
      "FOLD: 6, EPOCH: 49, train_loss: 0.018183157178423098\n",
      "FOLD: 6, EPOCH: 49, valid_loss: 0.017887436730020186\n",
      "FOLD: 6, EPOCH: 50, train_loss: 0.017975992637295875\n",
      "FOLD: 6, EPOCH: 50, valid_loss: 0.01776962453389869\n",
      "FOLD: 6, EPOCH: 51, train_loss: 0.017827229057588885\n",
      "FOLD: 6, EPOCH: 51, valid_loss: 0.017772757831741783\n",
      "FOLD: 6, EPOCH: 52, train_loss: 0.017676968512035186\n",
      "FOLD: 6, EPOCH: 52, valid_loss: 0.01786812865997062\n",
      "FOLD: 6, EPOCH: 53, train_loss: 0.017480195025282523\n",
      "FOLD: 6, EPOCH: 53, valid_loss: 0.017893241115790957\n",
      "FOLD: 6, EPOCH: 54, train_loss: 0.017339515445693846\n",
      "FOLD: 6, EPOCH: 54, valid_loss: 0.017878745682537556\n",
      "FOLD: 6, EPOCH: 55, train_loss: 0.01723537268417497\n",
      "FOLD: 6, EPOCH: 55, valid_loss: 0.017824386739555526\n",
      "FOLD: 6, EPOCH: 56, train_loss: 0.017107612747819193\n",
      "FOLD: 6, EPOCH: 56, valid_loss: 0.017846097567063922\n",
      "FOLD: 6, EPOCH: 57, train_loss: 0.017034054042831544\n",
      "FOLD: 6, EPOCH: 57, valid_loss: 0.017842599409906304\n",
      "FOLD: 6, EPOCH: 58, train_loss: 0.016980609075436668\n",
      "FOLD: 6, EPOCH: 58, valid_loss: 0.01784883554586593\n",
      "FOLD: 6, EPOCH: 59, train_loss: 0.0169622469453081\n",
      "FOLD: 6, EPOCH: 59, valid_loss: 0.01786072431680034\n",
      "FOLD: 7, EPOCH: 0, train_loss: 0.6761957478138708\n",
      "FOLD: 7, EPOCH: 0, valid_loss: 0.3603881019003251\n",
      "FOLD: 7, EPOCH: 1, train_loss: 0.06099707348452461\n",
      "FOLD: 7, EPOCH: 1, valid_loss: 0.019433571354431266\n",
      "FOLD: 7, EPOCH: 2, train_loss: 0.023128831518753883\n",
      "FOLD: 7, EPOCH: 2, valid_loss: 0.01932845144149135\n",
      "FOLD: 7, EPOCH: 3, train_loss: 0.02266350058057616\n",
      "FOLD: 7, EPOCH: 3, valid_loss: 0.01836721960674314\n",
      "FOLD: 7, EPOCH: 4, train_loss: 0.0222569479577003\n",
      "FOLD: 7, EPOCH: 4, valid_loss: 0.01813290750279146\n",
      "FOLD: 7, EPOCH: 5, train_loss: 0.021177959045575512\n",
      "FOLD: 7, EPOCH: 5, valid_loss: 0.017831930123707828\n",
      "FOLD: 7, EPOCH: 6, train_loss: 0.020623803150749975\n",
      "FOLD: 7, EPOCH: 6, valid_loss: 0.017706580898341012\n",
      "FOLD: 7, EPOCH: 7, train_loss: 0.020324014932397872\n",
      "FOLD: 7, EPOCH: 7, valid_loss: 0.017730148728279507\n",
      "FOLD: 7, EPOCH: 8, train_loss: 0.02030830043217828\n",
      "FOLD: 7, EPOCH: 8, valid_loss: 0.017954267342300975\n",
      "FOLD: 7, EPOCH: 9, train_loss: 0.020360825318963296\n",
      "FOLD: 7, EPOCH: 9, valid_loss: 0.017963047741967088\n",
      "FOLD: 7, EPOCH: 10, train_loss: 0.020421276001199598\n",
      "FOLD: 7, EPOCH: 10, valid_loss: 0.018055323949631524\n",
      "FOLD: 7, EPOCH: 11, train_loss: 0.02040997792876536\n",
      "FOLD: 7, EPOCH: 11, valid_loss: 0.017959678436026853\n",
      "FOLD: 7, EPOCH: 12, train_loss: 0.020520071541109394\n",
      "FOLD: 7, EPOCH: 12, valid_loss: 0.01817265372065937\n",
      "FOLD: 7, EPOCH: 13, train_loss: 0.020610729689078948\n",
      "FOLD: 7, EPOCH: 13, valid_loss: 0.018129594952744597\n",
      "FOLD: 7, EPOCH: 14, train_loss: 0.02056265924005739\n",
      "FOLD: 7, EPOCH: 14, valid_loss: 0.01836362459203776\n",
      "FOLD: 7, EPOCH: 15, train_loss: 0.020757643421811443\n",
      "FOLD: 7, EPOCH: 15, valid_loss: 0.018148183055660305\n",
      "FOLD: 7, EPOCH: 16, train_loss: 0.020806845229479575\n",
      "FOLD: 7, EPOCH: 16, valid_loss: 0.01840273794882438\n",
      "FOLD: 7, EPOCH: 17, train_loss: 0.02078984209126042\n",
      "FOLD: 7, EPOCH: 17, valid_loss: 0.018117273555082435\n",
      "FOLD: 7, EPOCH: 18, train_loss: 0.02083500352117323\n",
      "FOLD: 7, EPOCH: 18, valid_loss: 0.01800142798353644\n",
      "FOLD: 7, EPOCH: 19, train_loss: 0.020795179398790484\n",
      "FOLD: 7, EPOCH: 19, valid_loss: 0.018308766295804697\n",
      "FOLD: 7, EPOCH: 20, train_loss: 0.020863153605211165\n",
      "FOLD: 7, EPOCH: 20, valid_loss: 0.01801978424191475\n",
      "FOLD: 7, EPOCH: 21, train_loss: 0.020906497393884966\n",
      "FOLD: 7, EPOCH: 21, valid_loss: 0.018360601738095284\n",
      "FOLD: 7, EPOCH: 22, train_loss: 0.0208661449892867\n",
      "FOLD: 7, EPOCH: 22, valid_loss: 0.017827661269727874\n",
      "FOLD: 7, EPOCH: 23, train_loss: 0.020915631865782124\n",
      "FOLD: 7, EPOCH: 23, valid_loss: 0.017952402286669788\n",
      "FOLD: 7, EPOCH: 24, train_loss: 0.020840522959347695\n",
      "FOLD: 7, EPOCH: 24, valid_loss: 0.017956823220147806\n",
      "FOLD: 7, EPOCH: 25, train_loss: 0.02080180729108472\n",
      "FOLD: 7, EPOCH: 25, valid_loss: 0.01788424207445453\n",
      "FOLD: 7, EPOCH: 26, train_loss: 0.02082340389249786\n",
      "FOLD: 7, EPOCH: 26, valid_loss: 0.018206414930960712\n",
      "FOLD: 7, EPOCH: 27, train_loss: 0.020728718513442625\n",
      "FOLD: 7, EPOCH: 27, valid_loss: 0.018123816479654872\n",
      "FOLD: 7, EPOCH: 28, train_loss: 0.020727937271998776\n",
      "FOLD: 7, EPOCH: 28, valid_loss: 0.018110950422637603\n",
      "FOLD: 7, EPOCH: 29, train_loss: 0.020639073608383057\n",
      "FOLD: 7, EPOCH: 29, valid_loss: 0.018040823695414206\n",
      "FOLD: 7, EPOCH: 30, train_loss: 0.02053619559493757\n",
      "FOLD: 7, EPOCH: 30, valid_loss: 0.018034362069824162\n",
      "FOLD: 7, EPOCH: 31, train_loss: 0.02054363495159534\n",
      "FOLD: 7, EPOCH: 31, valid_loss: 0.017855555147809142\n",
      "FOLD: 7, EPOCH: 32, train_loss: 0.02041688115606385\n",
      "FOLD: 7, EPOCH: 32, valid_loss: 0.017692926832858252\n",
      "FOLD: 7, EPOCH: 33, train_loss: 0.020369717082188977\n",
      "FOLD: 7, EPOCH: 33, valid_loss: 0.017718565814635334\n",
      "FOLD: 7, EPOCH: 34, train_loss: 0.02025728329054771\n",
      "FOLD: 7, EPOCH: 34, valid_loss: 0.017551631392801508\n",
      "FOLD: 7, EPOCH: 35, train_loss: 0.02013117592901953\n",
      "FOLD: 7, EPOCH: 35, valid_loss: 0.017600229776957455\n",
      "FOLD: 7, EPOCH: 36, train_loss: 0.020101442308195175\n",
      "FOLD: 7, EPOCH: 36, valid_loss: 0.017633967101573944\n",
      "FOLD: 7, EPOCH: 37, train_loss: 0.01995228968801037\n",
      "FOLD: 7, EPOCH: 37, valid_loss: 0.017626392709858277\n",
      "FOLD: 7, EPOCH: 38, train_loss: 0.019826622415454156\n",
      "FOLD: 7, EPOCH: 38, valid_loss: 0.017536800026017076\n",
      "FOLD: 7, EPOCH: 39, train_loss: 0.01967584720302013\n",
      "FOLD: 7, EPOCH: 39, valid_loss: 0.017544373979463297\n",
      "FOLD: 7, EPOCH: 40, train_loss: 0.019586037459873383\n",
      "FOLD: 7, EPOCH: 40, valid_loss: 0.01739807700847878\n",
      "FOLD: 7, EPOCH: 41, train_loss: 0.019450118801286144\n",
      "FOLD: 7, EPOCH: 41, valid_loss: 0.017512879279606482\n",
      "FOLD: 7, EPOCH: 42, train_loss: 0.01935969885558851\n",
      "FOLD: 7, EPOCH: 42, valid_loss: 0.01737631139728953\n",
      "FOLD: 7, EPOCH: 43, train_loss: 0.019224623170110488\n",
      "FOLD: 7, EPOCH: 43, valid_loss: 0.017392441301661378\n",
      "FOLD: 7, EPOCH: 44, train_loss: 0.019054395597307913\n",
      "FOLD: 7, EPOCH: 44, valid_loss: 0.017357317073380247\n",
      "FOLD: 7, EPOCH: 45, train_loss: 0.018925120212858724\n",
      "FOLD: 7, EPOCH: 45, valid_loss: 0.017365421004155102\n",
      "FOLD: 7, EPOCH: 46, train_loss: 0.01875633275917461\n",
      "FOLD: 7, EPOCH: 46, valid_loss: 0.017295699511819026\n",
      "FOLD: 7, EPOCH: 47, train_loss: 0.018587679716367874\n",
      "FOLD: 7, EPOCH: 47, valid_loss: 0.017294348491465345\n",
      "FOLD: 7, EPOCH: 48, train_loss: 0.018418553621778563\n",
      "FOLD: 7, EPOCH: 48, valid_loss: 0.017253211261156726\n",
      "FOLD: 7, EPOCH: 49, train_loss: 0.018240545401650092\n",
      "FOLD: 7, EPOCH: 49, valid_loss: 0.017205040080144125\n",
      "FOLD: 7, EPOCH: 50, train_loss: 0.01809460729841263\n",
      "FOLD: 7, EPOCH: 50, valid_loss: 0.017287035363123697\n",
      "FOLD: 7, EPOCH: 51, train_loss: 0.017929992356127307\n",
      "FOLD: 7, EPOCH: 51, valid_loss: 0.01718514774213819\n",
      "FOLD: 7, EPOCH: 52, train_loss: 0.01776719247742045\n",
      "FOLD: 7, EPOCH: 52, valid_loss: 0.01716093664221904\n",
      "FOLD: 7, EPOCH: 53, train_loss: 0.017612631775198444\n",
      "FOLD: 7, EPOCH: 53, valid_loss: 0.017200105001821238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 7, EPOCH: 54, train_loss: 0.01744225443971734\n",
      "FOLD: 7, EPOCH: 54, valid_loss: 0.017200371579212302\n",
      "FOLD: 7, EPOCH: 55, train_loss: 0.017355104920364194\n",
      "FOLD: 7, EPOCH: 55, valid_loss: 0.017177900463780937\n",
      "FOLD: 7, EPOCH: 56, train_loss: 0.01721830773017099\n",
      "FOLD: 7, EPOCH: 56, valid_loss: 0.01714701868374558\n",
      "FOLD: 7, EPOCH: 57, train_loss: 0.017171460780645572\n",
      "FOLD: 7, EPOCH: 57, valid_loss: 0.01715356544317568\n",
      "FOLD: 7, EPOCH: 58, train_loss: 0.017142678142314956\n",
      "FOLD: 7, EPOCH: 58, valid_loss: 0.017143630367868087\n",
      "FOLD: 7, EPOCH: 59, train_loss: 0.01709758147236801\n",
      "FOLD: 7, EPOCH: 59, valid_loss: 0.017156172653331477\n",
      "FOLD: 8, EPOCH: 0, train_loss: 0.6760427924894518\n",
      "FOLD: 8, EPOCH: 0, valid_loss: 0.36568457384904224\n",
      "FOLD: 8, EPOCH: 1, train_loss: 0.06113833614414738\n",
      "FOLD: 8, EPOCH: 1, valid_loss: 0.019826427309049502\n",
      "FOLD: 8, EPOCH: 2, train_loss: 0.023467244400132085\n",
      "FOLD: 8, EPOCH: 2, valid_loss: 0.019211641771511898\n",
      "FOLD: 8, EPOCH: 3, train_loss: 0.02367178732829709\n",
      "FOLD: 8, EPOCH: 3, valid_loss: 0.021596678843100865\n",
      "FOLD: 8, EPOCH: 4, train_loss: 0.023917122750032334\n",
      "FOLD: 8, EPOCH: 4, valid_loss: 0.017969508448408708\n",
      "FOLD: 8, EPOCH: 5, train_loss: 0.021007019173233738\n",
      "FOLD: 8, EPOCH: 5, valid_loss: 0.017739206190324493\n",
      "FOLD: 8, EPOCH: 6, train_loss: 0.02085590522375799\n",
      "FOLD: 8, EPOCH: 6, valid_loss: 0.017834837393214304\n",
      "FOLD: 8, EPOCH: 7, train_loss: 0.020719425236025164\n",
      "FOLD: 8, EPOCH: 7, valid_loss: 0.017827076216538746\n",
      "FOLD: 8, EPOCH: 8, train_loss: 0.02045001941582849\n",
      "FOLD: 8, EPOCH: 8, valid_loss: 0.017999342280543514\n",
      "FOLD: 8, EPOCH: 9, train_loss: 0.020499119306764294\n",
      "FOLD: 8, EPOCH: 9, valid_loss: 0.018043951234883733\n",
      "FOLD: 8, EPOCH: 10, train_loss: 0.020521454248697526\n",
      "FOLD: 8, EPOCH: 10, valid_loss: 0.017912281728867028\n",
      "FOLD: 8, EPOCH: 11, train_loss: 0.02051641655064398\n",
      "FOLD: 8, EPOCH: 11, valid_loss: 0.01781005784869194\n",
      "FOLD: 8, EPOCH: 12, train_loss: 0.02061604427233819\n",
      "FOLD: 8, EPOCH: 12, valid_loss: 0.01780020445585251\n",
      "FOLD: 8, EPOCH: 13, train_loss: 0.020637892871614424\n",
      "FOLD: 8, EPOCH: 13, valid_loss: 0.01802838324672646\n",
      "FOLD: 8, EPOCH: 14, train_loss: 0.020655244144220507\n",
      "FOLD: 8, EPOCH: 14, valid_loss: 0.01836204958251781\n",
      "FOLD: 8, EPOCH: 15, train_loss: 0.02074224522277232\n",
      "FOLD: 8, EPOCH: 15, valid_loss: 0.017971049373348553\n",
      "FOLD: 8, EPOCH: 16, train_loss: 0.02072705690178179\n",
      "FOLD: 8, EPOCH: 16, valid_loss: 0.017827962214748066\n",
      "FOLD: 8, EPOCH: 17, train_loss: 0.020804691927567606\n",
      "FOLD: 8, EPOCH: 17, valid_loss: 0.018263402860611677\n",
      "FOLD: 8, EPOCH: 18, train_loss: 0.02082337306872491\n",
      "FOLD: 8, EPOCH: 18, valid_loss: 0.018210122568739787\n",
      "FOLD: 8, EPOCH: 19, train_loss: 0.020970427653481883\n",
      "FOLD: 8, EPOCH: 19, valid_loss: 0.017903545250495274\n",
      "FOLD: 8, EPOCH: 20, train_loss: 0.020901674428774466\n",
      "FOLD: 8, EPOCH: 20, valid_loss: 0.017940415483382013\n",
      "FOLD: 8, EPOCH: 21, train_loss: 0.02094042100492985\n",
      "FOLD: 8, EPOCH: 21, valid_loss: 0.01808248760385646\n",
      "FOLD: 8, EPOCH: 22, train_loss: 0.02090145837395422\n",
      "FOLD: 8, EPOCH: 22, valid_loss: 0.018419619960089523\n",
      "FOLD: 8, EPOCH: 23, train_loss: 0.020903842884206002\n",
      "FOLD: 8, EPOCH: 23, valid_loss: 0.01786569904329048\n",
      "FOLD: 8, EPOCH: 24, train_loss: 0.020971455076529134\n",
      "FOLD: 8, EPOCH: 24, valid_loss: 0.018176926196449332\n",
      "FOLD: 8, EPOCH: 25, train_loss: 0.020856149855159944\n",
      "FOLD: 8, EPOCH: 25, valid_loss: 0.017924581343928974\n",
      "FOLD: 8, EPOCH: 26, train_loss: 0.020805423466428635\n",
      "FOLD: 8, EPOCH: 26, valid_loss: 0.018187396021352872\n",
      "FOLD: 8, EPOCH: 27, train_loss: 0.020818404576951458\n",
      "FOLD: 8, EPOCH: 27, valid_loss: 0.01802759865919749\n",
      "FOLD: 8, EPOCH: 28, train_loss: 0.02071244881278084\n",
      "FOLD: 8, EPOCH: 28, valid_loss: 0.017828046965102356\n",
      "FOLD: 8, EPOCH: 29, train_loss: 0.0207082848995924\n",
      "FOLD: 8, EPOCH: 29, valid_loss: 0.018042498216446903\n",
      "FOLD: 8, EPOCH: 30, train_loss: 0.020609190687537193\n",
      "FOLD: 8, EPOCH: 30, valid_loss: 0.01758904956902067\n",
      "FOLD: 8, EPOCH: 31, train_loss: 0.020576165286043\n",
      "FOLD: 8, EPOCH: 31, valid_loss: 0.01795131516539388\n",
      "FOLD: 8, EPOCH: 32, train_loss: 0.020480186360016944\n",
      "FOLD: 8, EPOCH: 32, valid_loss: 0.017827390589647822\n",
      "FOLD: 8, EPOCH: 33, train_loss: 0.020363618878106917\n",
      "FOLD: 8, EPOCH: 33, valid_loss: 0.01756563037633896\n",
      "FOLD: 8, EPOCH: 34, train_loss: 0.020263306315868132\n",
      "FOLD: 8, EPOCH: 34, valid_loss: 0.0178261689013905\n",
      "FOLD: 8, EPOCH: 35, train_loss: 0.02017415610532607\n",
      "FOLD: 8, EPOCH: 35, valid_loss: 0.0173114326575564\n",
      "FOLD: 8, EPOCH: 36, train_loss: 0.020104860069770965\n",
      "FOLD: 8, EPOCH: 36, valid_loss: 0.017616811415387526\n",
      "FOLD: 8, EPOCH: 37, train_loss: 0.020000759428066592\n",
      "FOLD: 8, EPOCH: 37, valid_loss: 0.017796129402187135\n",
      "FOLD: 8, EPOCH: 38, train_loss: 0.019907828672758993\n",
      "FOLD: 8, EPOCH: 38, valid_loss: 0.017257900598148506\n",
      "FOLD: 8, EPOCH: 39, train_loss: 0.019768569666531777\n",
      "FOLD: 8, EPOCH: 39, valid_loss: 0.017241603798336454\n",
      "FOLD: 8, EPOCH: 40, train_loss: 0.019649409394591085\n",
      "FOLD: 8, EPOCH: 40, valid_loss: 0.017240803067882855\n",
      "FOLD: 8, EPOCH: 41, train_loss: 0.01951633196684622\n",
      "FOLD: 8, EPOCH: 41, valid_loss: 0.017237119531879824\n",
      "FOLD: 8, EPOCH: 42, train_loss: 0.019390057279698312\n",
      "FOLD: 8, EPOCH: 42, valid_loss: 0.01729126636766725\n",
      "FOLD: 8, EPOCH: 43, train_loss: 0.01926610197030729\n",
      "FOLD: 8, EPOCH: 43, valid_loss: 0.017131503257486556\n",
      "FOLD: 8, EPOCH: 44, train_loss: 0.019054531978984032\n",
      "FOLD: 8, EPOCH: 44, valid_loss: 0.01713341438314981\n",
      "FOLD: 8, EPOCH: 45, train_loss: 0.018916837234170206\n",
      "FOLD: 8, EPOCH: 45, valid_loss: 0.017011268943962123\n",
      "FOLD: 8, EPOCH: 46, train_loss: 0.01875968930581885\n",
      "FOLD: 8, EPOCH: 46, valid_loss: 0.017034947354760435\n",
      "FOLD: 8, EPOCH: 47, train_loss: 0.01859832933593181\n",
      "FOLD: 8, EPOCH: 47, valid_loss: 0.017142165452241898\n",
      "FOLD: 8, EPOCH: 48, train_loss: 0.0184090256690979\n",
      "FOLD: 8, EPOCH: 48, valid_loss: 0.01716761104762554\n",
      "FOLD: 8, EPOCH: 49, train_loss: 0.018279669596062552\n",
      "FOLD: 8, EPOCH: 49, valid_loss: 0.017086332249972556\n",
      "FOLD: 8, EPOCH: 50, train_loss: 0.018068293614252922\n",
      "FOLD: 8, EPOCH: 50, valid_loss: 0.017029873716334503\n",
      "FOLD: 8, EPOCH: 51, train_loss: 0.017906268289492978\n",
      "FOLD: 8, EPOCH: 51, valid_loss: 0.017105229198932648\n",
      "FOLD: 8, EPOCH: 52, train_loss: 0.01773587908715971\n",
      "FOLD: 8, EPOCH: 52, valid_loss: 0.017025577783998515\n",
      "FOLD: 8, EPOCH: 53, train_loss: 0.01755358811107374\n",
      "FOLD: 8, EPOCH: 53, valid_loss: 0.01706496165651414\n",
      "FOLD: 8, EPOCH: 54, train_loss: 0.017416174114952165\n",
      "FOLD: 8, EPOCH: 54, valid_loss: 0.01703947104720606\n",
      "FOLD: 8, EPOCH: 55, train_loss: 0.017326051585616602\n",
      "FOLD: 8, EPOCH: 55, valid_loss: 0.01700907598973976\n",
      "FOLD: 8, EPOCH: 56, train_loss: 0.017222801589917753\n",
      "FOLD: 8, EPOCH: 56, valid_loss: 0.017074947038458452\n",
      "FOLD: 8, EPOCH: 57, train_loss: 0.01714404632727946\n",
      "FOLD: 8, EPOCH: 57, valid_loss: 0.017072426827831402\n",
      "FOLD: 8, EPOCH: 58, train_loss: 0.01711005552281295\n",
      "FOLD: 8, EPOCH: 58, valid_loss: 0.01706110680889752\n",
      "FOLD: 8, EPOCH: 59, train_loss: 0.01709763398093562\n",
      "FOLD: 8, EPOCH: 59, valid_loss: 0.0171194804004497\n",
      "FOLD: 9, EPOCH: 0, train_loss: 0.6764797674071404\n",
      "FOLD: 9, EPOCH: 0, valid_loss: 0.36671428713533616\n",
      "FOLD: 9, EPOCH: 1, train_loss: 0.06334169752174808\n",
      "FOLD: 9, EPOCH: 1, valid_loss: 0.020501916607220966\n",
      "FOLD: 9, EPOCH: 2, train_loss: 0.036317426266689455\n",
      "FOLD: 9, EPOCH: 2, valid_loss: 0.020846387681861717\n",
      "FOLD: 9, EPOCH: 3, train_loss: 0.025870737000819176\n",
      "FOLD: 9, EPOCH: 3, valid_loss: 0.03217501172588931\n",
      "FOLD: 9, EPOCH: 4, train_loss: 0.02562978283291863\n",
      "FOLD: 9, EPOCH: 4, valid_loss: 0.02330596341441075\n",
      "FOLD: 9, EPOCH: 5, train_loss: 0.02429078673162768\n",
      "FOLD: 9, EPOCH: 5, valid_loss: 0.01944038023551305\n",
      "FOLD: 9, EPOCH: 6, train_loss: 0.022548873974911628\n",
      "FOLD: 9, EPOCH: 6, valid_loss: 0.01948650874611404\n",
      "FOLD: 9, EPOCH: 7, train_loss: 0.021683416659793547\n",
      "FOLD: 9, EPOCH: 7, valid_loss: 0.01897876099165943\n",
      "FOLD: 9, EPOCH: 8, train_loss: 0.020989079857545515\n",
      "FOLD: 9, EPOCH: 8, valid_loss: 0.018733320343825553\n",
      "FOLD: 9, EPOCH: 9, train_loss: 0.02054605992931512\n",
      "FOLD: 9, EPOCH: 9, valid_loss: 0.021639025045765772\n",
      "FOLD: 9, EPOCH: 10, train_loss: 0.02061773401594931\n",
      "FOLD: 9, EPOCH: 10, valid_loss: 0.01931865130447679\n",
      "FOLD: 9, EPOCH: 11, train_loss: 0.020457644135721268\n",
      "FOLD: 9, EPOCH: 11, valid_loss: 0.01921258421821727\n",
      "FOLD: 9, EPOCH: 12, train_loss: 0.02058125210385169\n",
      "FOLD: 9, EPOCH: 12, valid_loss: 0.020528180938627984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 9, EPOCH: 13, train_loss: 0.020477486173472097\n",
      "FOLD: 9, EPOCH: 13, valid_loss: 0.020565543737676408\n",
      "FOLD: 9, EPOCH: 14, train_loss: 0.020411931302758955\n",
      "FOLD: 9, EPOCH: 14, valid_loss: 0.01792790409591463\n",
      "FOLD: 9, EPOCH: 15, train_loss: 0.020245085788830636\n",
      "FOLD: 9, EPOCH: 15, valid_loss: 0.018425521958205435\n",
      "FOLD: 9, EPOCH: 16, train_loss: 0.020252880934746035\n",
      "FOLD: 9, EPOCH: 16, valid_loss: 0.01929884683340788\n",
      "FOLD: 9, EPOCH: 17, train_loss: 0.020348457667616105\n",
      "FOLD: 9, EPOCH: 17, valid_loss: 0.02020755989683999\n",
      "FOLD: 9, EPOCH: 18, train_loss: 0.02024604196269666\n",
      "FOLD: 9, EPOCH: 18, valid_loss: 0.01773280484808816\n",
      "FOLD: 9, EPOCH: 19, train_loss: 0.020238809191411543\n",
      "FOLD: 9, EPOCH: 19, valid_loss: 0.019407137711015012\n",
      "FOLD: 9, EPOCH: 20, train_loss: 0.02034010961050949\n",
      "FOLD: 9, EPOCH: 20, valid_loss: 0.01820255329625474\n",
      "FOLD: 9, EPOCH: 21, train_loss: 0.02017698171398332\n",
      "FOLD: 9, EPOCH: 21, valid_loss: 0.019319901449812785\n",
      "FOLD: 9, EPOCH: 22, train_loss: 0.020256834993920017\n",
      "FOLD: 9, EPOCH: 22, valid_loss: 0.019584826814631622\n",
      "FOLD: 9, EPOCH: 23, train_loss: 0.020580017386424926\n",
      "FOLD: 9, EPOCH: 23, valid_loss: 0.01908927183184359\n",
      "FOLD: 9, EPOCH: 24, train_loss: 0.02046130241285409\n",
      "FOLD: 9, EPOCH: 24, valid_loss: 0.01745226901645462\n",
      "FOLD: 9, EPOCH: 25, train_loss: 0.02068078271563976\n",
      "FOLD: 9, EPOCH: 25, valid_loss: 0.01864038190493981\n",
      "FOLD: 9, EPOCH: 26, train_loss: 0.020505522125430647\n",
      "FOLD: 9, EPOCH: 26, valid_loss: 0.017955513567560248\n",
      "FOLD: 9, EPOCH: 27, train_loss: 0.020426914564544155\n",
      "FOLD: 9, EPOCH: 27, valid_loss: 0.017562694744103484\n",
      "FOLD: 9, EPOCH: 28, train_loss: 0.020414181600414937\n",
      "FOLD: 9, EPOCH: 28, valid_loss: 0.017690769914123747\n",
      "FOLD: 9, EPOCH: 29, train_loss: 0.020236409755964434\n",
      "FOLD: 9, EPOCH: 29, valid_loss: 0.01797965955403116\n",
      "FOLD: 9, EPOCH: 30, train_loss: 0.02051532209640549\n",
      "FOLD: 9, EPOCH: 30, valid_loss: 0.017522203632526927\n",
      "FOLD: 9, EPOCH: 31, train_loss: 0.020502341887162576\n",
      "FOLD: 9, EPOCH: 31, valid_loss: 0.017671835815740958\n",
      "FOLD: 9, EPOCH: 32, train_loss: 0.02017266437891991\n",
      "FOLD: 9, EPOCH: 32, valid_loss: 0.017399442796077993\n",
      "FOLD: 9, EPOCH: 33, train_loss: 0.02045880987519218\n",
      "FOLD: 9, EPOCH: 33, valid_loss: 0.01738699246197939\n",
      "FOLD: 9, EPOCH: 34, train_loss: 0.02034534202708352\n",
      "FOLD: 9, EPOCH: 34, valid_loss: 0.017258575186133385\n",
      "FOLD: 9, EPOCH: 35, train_loss: 0.0199733808937092\n",
      "FOLD: 9, EPOCH: 35, valid_loss: 0.017106963373306725\n",
      "FOLD: 9, EPOCH: 36, train_loss: 0.019936515306753496\n",
      "FOLD: 9, EPOCH: 36, valid_loss: 0.01711191474977467\n",
      "FOLD: 9, EPOCH: 37, train_loss: 0.019809993710969725\n",
      "FOLD: 9, EPOCH: 37, valid_loss: 0.01698826900165942\n",
      "FOLD: 9, EPOCH: 38, train_loss: 0.01961400287165757\n",
      "FOLD: 9, EPOCH: 38, valid_loss: 0.016914630257007148\n",
      "FOLD: 9, EPOCH: 39, train_loss: 0.019398322557249378\n",
      "FOLD: 9, EPOCH: 39, valid_loss: 0.01688936275119583\n",
      "FOLD: 9, EPOCH: 40, train_loss: 0.01957896694300636\n",
      "FOLD: 9, EPOCH: 40, valid_loss: 0.01682268062399493\n",
      "FOLD: 9, EPOCH: 41, train_loss: 0.0193220357741079\n",
      "FOLD: 9, EPOCH: 41, valid_loss: 0.016819399108903274\n",
      "FOLD: 9, EPOCH: 42, train_loss: 0.019064620768110597\n",
      "FOLD: 9, EPOCH: 42, valid_loss: 0.016688885839862957\n",
      "FOLD: 9, EPOCH: 43, train_loss: 0.019037854791648927\n",
      "FOLD: 9, EPOCH: 43, valid_loss: 0.016806005965918303\n",
      "FOLD: 9, EPOCH: 44, train_loss: 0.0190347112474903\n",
      "FOLD: 9, EPOCH: 44, valid_loss: 0.016803230262464948\n",
      "FOLD: 9, EPOCH: 45, train_loss: 0.018728836727959493\n",
      "FOLD: 9, EPOCH: 45, valid_loss: 0.016828743275254965\n",
      "FOLD: 9, EPOCH: 46, train_loss: 0.01852773838346043\n",
      "FOLD: 9, EPOCH: 46, valid_loss: 0.016891171793556876\n",
      "FOLD: 9, EPOCH: 47, train_loss: 0.01838538846181285\n",
      "FOLD: 9, EPOCH: 47, valid_loss: 0.016798337869760063\n",
      "FOLD: 9, EPOCH: 48, train_loss: 0.01809108795357808\n",
      "FOLD: 9, EPOCH: 48, valid_loss: 0.016779852824078664\n",
      "FOLD: 9, EPOCH: 49, train_loss: 0.01784380521745451\n",
      "FOLD: 9, EPOCH: 49, valid_loss: 0.016879980452358723\n",
      "FOLD: 9, EPOCH: 50, train_loss: 0.017730149542612414\n",
      "FOLD: 9, EPOCH: 50, valid_loss: 0.01677541486505005\n",
      "FOLD: 9, EPOCH: 51, train_loss: 0.017478810989808653\n",
      "FOLD: 9, EPOCH: 51, valid_loss: 0.016814841474923823\n",
      "FOLD: 9, EPOCH: 52, train_loss: 0.017157758261647917\n",
      "FOLD: 9, EPOCH: 52, valid_loss: 0.01679216521895594\n",
      "FOLD: 9, EPOCH: 53, train_loss: 0.016960089545576804\n",
      "FOLD: 9, EPOCH: 53, valid_loss: 0.01684964168816805\n",
      "FOLD: 9, EPOCH: 54, train_loss: 0.01666282558993947\n",
      "FOLD: 9, EPOCH: 54, valid_loss: 0.016896446959839925\n",
      "FOLD: 9, EPOCH: 55, train_loss: 0.01647943340602421\n",
      "FOLD: 9, EPOCH: 55, valid_loss: 0.016871139355417755\n",
      "FOLD: 9, EPOCH: 56, train_loss: 0.016440536376209028\n",
      "FOLD: 9, EPOCH: 56, valid_loss: 0.01689151105367475\n",
      "FOLD: 9, EPOCH: 57, train_loss: 0.016177258207913367\n",
      "FOLD: 9, EPOCH: 57, valid_loss: 0.016873597995274596\n",
      "FOLD: 9, EPOCH: 58, train_loss: 0.016088361569469974\n",
      "FOLD: 9, EPOCH: 58, valid_loss: 0.016919525909341045\n",
      "FOLD: 9, EPOCH: 59, train_loss: 0.016117358742462052\n",
      "FOLD: 9, EPOCH: 59, valid_loss: 0.01690719173186355\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6768227248422561\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.3659808775957893\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.06083611654898813\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.019975598572808152\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023214946723272723\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.019599575001527283\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.022244097616884017\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.019412487416582948\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.023987115306719656\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.018446547034032205\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.023476831230425065\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018760221188559252\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.021693101308999523\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01837988307370859\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.02105576883881323\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.018447045455960667\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020855748785599586\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018524750190622667\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020764159747669774\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.018083507742951897\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020791463097256997\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.018127070739865303\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.020713612713640736\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.018084132605615783\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.02069096733485499\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018647720160729745\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.020800227780015237\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.018133480649660614\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.020803028333090966\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.018492242430939394\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.020852044176670814\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.018356367397834274\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.020802495123878603\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.018263925305184198\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.02086716813425864\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.018458080532796243\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.020876944401571826\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.018664181342019755\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.020834859893206627\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.018385174191173387\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.020875603921951785\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018462513847386137\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.020936435100532346\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.018162291716126835\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.020914486266912953\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.018264695454169724\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.020848153807943866\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.018370095969123\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.02086545007844125\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01849481320994742\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.02085273989265965\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.018150301211897063\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.020782051848307732\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.018284789012635454\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.020773881121027855\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01796907657647834\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.02068454350434965\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01800809702014222\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.020600702156943658\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018098354120464885\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.020539644841224915\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.01818616929299691\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.020486424226434\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.017750144552658585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 32, train_loss: 0.020325810245929225\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.018186437842600486\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.020280277692983226\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.018036504550015226\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.020237060347872395\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.017969886005363044\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.020140688577967306\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.0177100774119882\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.020037696210126722\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.017727547818247008\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.01992299585573135\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.017492188414668337\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.019755470944989112\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.017679952304152882\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.019762968728619237\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.017635824597057176\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.019576284697940274\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.017644323627738392\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.019455541838561335\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.01754700523965499\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.01937268705617997\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.017482130295213533\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.019236157498052044\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.017462451284860864\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.019067847248046627\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.017373314236893374\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.018912335172776254\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.017359828959931347\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.018763818591833115\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.01722101554931963\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.018590703047811984\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.01723732130930704\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.018464217551292912\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.017324533806565928\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.01827797361559445\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.017221684731981334\n",
      "FOLD: 0, EPOCH: 50, train_loss: 0.018111179835133013\n",
      "FOLD: 0, EPOCH: 50, valid_loss: 0.017340474049834645\n",
      "FOLD: 0, EPOCH: 51, train_loss: 0.017962024601236467\n",
      "FOLD: 0, EPOCH: 51, valid_loss: 0.0172480301493231\n",
      "FOLD: 0, EPOCH: 52, train_loss: 0.017812510669952437\n",
      "FOLD: 0, EPOCH: 52, valid_loss: 0.017199011574334958\n",
      "FOLD: 0, EPOCH: 53, train_loss: 0.017632512399746527\n",
      "FOLD: 0, EPOCH: 53, valid_loss: 0.017201554523233104\n",
      "FOLD: 0, EPOCH: 54, train_loss: 0.01756198679607722\n",
      "FOLD: 0, EPOCH: 54, valid_loss: 0.017209099879597917\n",
      "FOLD: 0, EPOCH: 55, train_loss: 0.017430529316827176\n",
      "FOLD: 0, EPOCH: 55, valid_loss: 0.017244545578518334\n",
      "FOLD: 0, EPOCH: 56, train_loss: 0.017358196400586636\n",
      "FOLD: 0, EPOCH: 56, valid_loss: 0.01723276182790013\n",
      "FOLD: 0, EPOCH: 57, train_loss: 0.017267942656913112\n",
      "FOLD: 0, EPOCH: 57, valid_loss: 0.017228814663694185\n",
      "FOLD: 0, EPOCH: 58, train_loss: 0.017257158530335274\n",
      "FOLD: 0, EPOCH: 58, valid_loss: 0.017244825906613293\n",
      "FOLD: 0, EPOCH: 59, train_loss: 0.01718106314299568\n",
      "FOLD: 0, EPOCH: 59, valid_loss: 0.017255199306151447\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6761545333170121\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.37399206227726406\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.06100523647281431\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020147353048539825\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.022818480275811688\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.021274352290978033\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.02338800453130276\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.02020264696329832\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.0218103998010197\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.018731943900800414\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02057482252918905\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01811371309061845\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020210251500529627\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.018291854972226754\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.02011933917960813\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01834015232614345\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.02020855263596581\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.018662875932123926\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020242608602969878\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.018337925844308402\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.020290104251715443\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.018698813445452187\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020339814405287465\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018401247397479083\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.020356115951172767\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017939651436689828\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.02042145745888833\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.018648662914832432\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.020568494342507855\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01871676267021232\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.020568497286688896\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01837365510356095\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.02069874941822021\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.018801203980627988\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.020749503734611697\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.018290190491825342\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.020658713807502102\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.018351025879383087\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.020775644180755462\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.018646973547422223\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.0207751844919497\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01837552949372265\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.020820670538852292\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01868756751840313\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.020756380728656244\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01860740915354755\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.02081520540579673\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01859497382409043\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.020784935138879284\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.018746302514854405\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.02081151188861939\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.018489066925313737\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.02072846605893104\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.01845340420388513\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.020698647213078316\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.01900158149914609\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.020722548062762906\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.018538055010139942\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.02064862055403571\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.018259534974479012\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.02055116551778009\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.01864237669441435\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.020501607968922583\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018129715126835637\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.020403606336443655\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018371841456327174\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.020349842021542212\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.01808006538906031\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.02023013246155554\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.018183129373937845\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.020090395788992604\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.017991039746751387\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.020074224123551\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.0180072826333344\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.019961566093467897\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.017989947615812223\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.01974077940948548\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.018159385356638167\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.019725905899559297\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.018190430115080543\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.01953467969452181\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.017801995078722637\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.019425892253075876\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.018077810243186023\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.01926361484633338\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.017757106727610033\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.019167338588064717\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.017561022709641192\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.01899576288077139\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.01790757104754448\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.01879241756734348\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.01773053402495053\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.018668626044546405\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.01776492890591423\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.01848500590290754\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.017641714308410883\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.018316361560456216\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.017640670916686457\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.018135262647223087\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.01768754044961598\n",
      "FOLD: 1, EPOCH: 50, train_loss: 0.01794115650437532\n",
      "FOLD: 1, EPOCH: 50, valid_loss: 0.017668854652179614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 51, train_loss: 0.01780648247128533\n",
      "FOLD: 1, EPOCH: 51, valid_loss: 0.01776303257793188\n",
      "FOLD: 1, EPOCH: 52, train_loss: 0.017573318456209474\n",
      "FOLD: 1, EPOCH: 52, valid_loss: 0.017662231913871236\n",
      "FOLD: 1, EPOCH: 53, train_loss: 0.017397353840210746\n",
      "FOLD: 1, EPOCH: 53, valid_loss: 0.017731190141704347\n",
      "FOLD: 1, EPOCH: 54, train_loss: 0.0172614884953345\n",
      "FOLD: 1, EPOCH: 54, valid_loss: 0.017676117416057322\n",
      "FOLD: 1, EPOCH: 55, train_loss: 0.017109001397846206\n",
      "FOLD: 1, EPOCH: 55, valid_loss: 0.017652591845641535\n",
      "FOLD: 1, EPOCH: 56, train_loss: 0.017006801940020053\n",
      "FOLD: 1, EPOCH: 56, valid_loss: 0.01768855776430832\n",
      "FOLD: 1, EPOCH: 57, train_loss: 0.01695019462776761\n",
      "FOLD: 1, EPOCH: 57, valid_loss: 0.017672410596989922\n",
      "FOLD: 1, EPOCH: 58, train_loss: 0.016903816133497222\n",
      "FOLD: 1, EPOCH: 58, valid_loss: 0.017650162801146507\n",
      "FOLD: 1, EPOCH: 59, train_loss: 0.016918602615835204\n",
      "FOLD: 1, EPOCH: 59, valid_loss: 0.017669075944771368\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6769589110728234\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.35227929552396137\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.06150820293734151\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.021192100416455004\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023307739750992866\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01948967058625486\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.02297830669389617\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.020437549696200423\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.022394835119766573\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.022358021284970973\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02080895189316042\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01826346939843562\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.022538458712158666\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018617925337619252\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020905300181719565\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.024359301146533754\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020784220351807534\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.018289339469952717\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.0208002025561948\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01859915753205617\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.020690611064914734\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.018489732924434874\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.02073212863216477\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.0185873843729496\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.020785539537187547\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018561739681495562\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.020803892348081835\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.018392676539305184\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.02077465777195269\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018387926483733788\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.020889250032844083\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.018207011744379997\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.020767150819301604\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.0189767690996329\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.02078167256568709\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.018522390992277198\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.020835300546980674\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.018457794251541298\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.020981524343932828\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01846000003731913\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.020802246502810907\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.018198805085072916\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.020929925047582197\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01858979484273328\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.020888119731699267\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018341902333001297\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.02086787760978745\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01807109820139077\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.02086537129455997\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018474534826560154\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.020819264013440378\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.018099217468665704\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.02084403787889788\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01859696778572268\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.02080645666968438\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.018528405163023207\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.020728825333137666\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.018024048664503627\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.020687359451286254\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.018262394703924656\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.020613126180345012\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.017810725813938513\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.02055675470300259\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.018088277895003557\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.020525766272217996\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017874105936951108\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.02036991080930156\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017948306889997587\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.020294548114461283\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.017849871112654608\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.020229535285503635\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.017575198060108557\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.020140902505766962\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.0177212228688101\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.01995467357337475\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.017659556068893936\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.019869499401219428\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.017504242145352893\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.019756923243403435\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.01767499393059148\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.01970240027313271\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.0174771115804712\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.01956921564715524\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.01741606592097216\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.019420073529885663\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.017581442474491067\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.019310547171100492\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.017316652927547693\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.019128474448957752\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017190596502688196\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.018985550910715136\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017326586828049686\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.018797201795443412\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.01714300804047121\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.018695602866430436\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.017121205158117745\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.018501652518828068\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.017231126005450886\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.018347938478954377\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.01716906561826666\n",
      "FOLD: 2, EPOCH: 50, train_loss: 0.01818573858228422\n",
      "FOLD: 2, EPOCH: 50, valid_loss: 0.017114867818438344\n",
      "FOLD: 2, EPOCH: 51, train_loss: 0.01799853395430311\n",
      "FOLD: 2, EPOCH: 51, valid_loss: 0.0171356531791389\n",
      "FOLD: 2, EPOCH: 52, train_loss: 0.017842773281999173\n",
      "FOLD: 2, EPOCH: 52, valid_loss: 0.01718224228049318\n",
      "FOLD: 2, EPOCH: 53, train_loss: 0.017728013551283266\n",
      "FOLD: 2, EPOCH: 53, valid_loss: 0.01708734521849288\n",
      "FOLD: 2, EPOCH: 54, train_loss: 0.01758665333712293\n",
      "FOLD: 2, EPOCH: 54, valid_loss: 0.017139552109357383\n",
      "FOLD: 2, EPOCH: 55, train_loss: 0.017458066951122977\n",
      "FOLD: 2, EPOCH: 55, valid_loss: 0.017153384991818003\n",
      "FOLD: 2, EPOCH: 56, train_loss: 0.017357956906480173\n",
      "FOLD: 2, EPOCH: 56, valid_loss: 0.017153722647991445\n",
      "FOLD: 2, EPOCH: 57, train_loss: 0.017306165289013617\n",
      "FOLD: 2, EPOCH: 57, valid_loss: 0.017149997512913413\n",
      "FOLD: 2, EPOCH: 58, train_loss: 0.01722230922671095\n",
      "FOLD: 2, EPOCH: 58, valid_loss: 0.01717398589890864\n",
      "FOLD: 2, EPOCH: 59, train_loss: 0.01722193155437708\n",
      "FOLD: 2, EPOCH: 59, valid_loss: 0.017163558035261102\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.676829142532041\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.36709069543414646\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.062026716540417366\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.019744721862177055\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.022946866637756747\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01978016903416978\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.02299850929167963\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018958860439144902\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.022615818318820768\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.018552972624699276\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.02100635126473442\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017631564082370862\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.02073078004102553\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.018225380271259282\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02044938931301717\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01783363702189591\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.02035989269854561\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01770339709603124\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020371071501604974\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017496856136454478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 10, train_loss: 0.020449220953929807\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017681765059630077\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.020501646723958752\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017888512255416975\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.020484529916317232\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.018216920499172475\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.020569403409477202\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017771304378079042\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.02070236055841369\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017957554819683235\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.020694118485816062\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017849547581540212\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.020704322764950413\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.018084637665500242\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.02083854171777925\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017870504667775497\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.02081857862011079\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01798987083343996\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.020857846508583716\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01786395400348637\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020775779324673838\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01788373053487804\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.020967733343282054\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01812645270385676\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.02087819772141595\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017953612479484744\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020890679174373226\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01823759063457449\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020929666764793856\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017850050650950935\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.020831277233458335\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.017911088652908802\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.02080978637020434\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.01764246795533432\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.020809767599548064\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.017929800423896976\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.020711982238196557\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.017814434340430632\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.020662951313199535\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.017768841805971332\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.020667065463719828\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.017649849721541006\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.020595048920762155\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.017397930483437248\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.020500086656501215\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.017613080588893756\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.020446897682643708\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.01759602776211169\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.02036750191642392\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.017277866912384827\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.02018279162866454\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.017152987472299073\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.02011638520465743\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.017442675307393074\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.01999722612240622\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017274596728384495\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.019883747759365265\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.017147459348456726\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.01972192882770492\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.01716944021690223\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.01962703494054656\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017058177540699642\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.019523742626751623\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.016982295343445405\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.019350577626497514\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.016949569754716422\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.01921126593745524\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.016997265060328774\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.019087039871561913\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.01688760606985953\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.018900100045627165\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.016855715825739834\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.018798091743261584\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.016685399899466172\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.01862041919582313\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.01687715223266019\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.018418585166575446\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.016720884583062597\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.018240313328081563\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.016768837192406256\n",
      "FOLD: 3, EPOCH: 50, train_loss: 0.01805522280234483\n",
      "FOLD: 3, EPOCH: 50, valid_loss: 0.01681234123599198\n",
      "FOLD: 3, EPOCH: 51, train_loss: 0.017844219205360258\n",
      "FOLD: 3, EPOCH: 51, valid_loss: 0.01679210163032015\n",
      "FOLD: 3, EPOCH: 52, train_loss: 0.017759176421790354\n",
      "FOLD: 3, EPOCH: 52, valid_loss: 0.016701668293939695\n",
      "FOLD: 3, EPOCH: 53, train_loss: 0.017598355273085255\n",
      "FOLD: 3, EPOCH: 53, valid_loss: 0.016763787406186264\n",
      "FOLD: 3, EPOCH: 54, train_loss: 0.017466810465820375\n",
      "FOLD: 3, EPOCH: 54, valid_loss: 0.01674786660199364\n",
      "FOLD: 3, EPOCH: 55, train_loss: 0.01727338536011596\n",
      "FOLD: 3, EPOCH: 55, valid_loss: 0.01671232831560903\n",
      "FOLD: 3, EPOCH: 56, train_loss: 0.017210768788091597\n",
      "FOLD: 3, EPOCH: 56, valid_loss: 0.016720318131976657\n",
      "FOLD: 3, EPOCH: 57, train_loss: 0.01711887492527885\n",
      "FOLD: 3, EPOCH: 57, valid_loss: 0.016722720737258594\n",
      "FOLD: 3, EPOCH: 58, train_loss: 0.01707862950861454\n",
      "FOLD: 3, EPOCH: 58, valid_loss: 0.016700978701313336\n",
      "FOLD: 3, EPOCH: 59, train_loss: 0.017032083472417248\n",
      "FOLD: 3, EPOCH: 59, valid_loss: 0.01672950852662325\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6766162678118675\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.36467820240391624\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.062151419779946725\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020487407946752176\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023534487344084247\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.019777430635359552\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.02272298827527031\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.019417613848216005\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.02303358525518448\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.15310212742123339\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.023135460408464554\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.018208668567240238\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.021503451418492102\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01821025719659196\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.021037084729440752\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017777478581087455\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.020975913720265513\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.018016502519862518\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.020890358595117446\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018024319265451696\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.02083802974272159\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017812764944715634\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.020746641125409835\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01768968326763974\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.020783053542817793\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.018136327982776694\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.020755295143012078\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01762106181639764\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.020769146397229165\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017669080911825102\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.0207812424388624\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.01806817338284519\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.02079429690155291\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017796989168143935\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.020823112719001308\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01775383825103442\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.020838549757196057\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.017958255329479773\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.02083082577634242\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.017745099651316803\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.020755234733223916\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.017577260680910613\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.02079346770000073\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017940766385032073\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.020811696530830474\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.017994032344884343\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.020787687431420048\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.017636289716594748\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.02082920430168029\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01805744268414047\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.02078867277070399\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.017473117758830387\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.020763395113810416\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.01786454849772983\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.02071206186327242\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.017564354464411736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4, EPOCH: 28, train_loss: 0.020654985705210318\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.017624843658672437\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.02066398776106296\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01750586037006643\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.020512876215000305\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.017182681657787826\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.020499157641203174\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.017554283193829987\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.020407452181943002\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017422451844645873\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.020303255427748926\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.01721229999222689\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.020217078359377\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.01739685672024886\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.020131967937754045\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.01703767788906892\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.01999280023719034\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.01717875965146555\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.019889983330522814\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.017093516420572996\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.019825776774556405\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.01711638866820269\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.019716325354191565\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.016909411177039146\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.019527552409037467\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.01693589835324221\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.019457774368986006\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.01691635258288847\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.019296211893520047\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.016856246317426365\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.019187278865325834\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.016746152606275346\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.01900906227529049\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.016798610126392707\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.018869772517392712\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.016775208577099774\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.018656906125045593\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.01668079590631856\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.018511393894591638\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.016673285048455\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.018316394156746327\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.016632352024316788\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.01814519559904452\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.016581209221233923\n",
      "FOLD: 4, EPOCH: 50, train_loss: 0.017942893787497475\n",
      "FOLD: 4, EPOCH: 50, valid_loss: 0.016704858435938757\n",
      "FOLD: 4, EPOCH: 51, train_loss: 0.01780028552297623\n",
      "FOLD: 4, EPOCH: 51, valid_loss: 0.016564694543679554\n",
      "FOLD: 4, EPOCH: 52, train_loss: 0.01749575377231644\n",
      "FOLD: 4, EPOCH: 52, valid_loss: 0.01666610103307499\n",
      "FOLD: 4, EPOCH: 53, train_loss: 0.017389370819493648\n",
      "FOLD: 4, EPOCH: 53, valid_loss: 0.016619096147931285\n",
      "FOLD: 4, EPOCH: 54, train_loss: 0.017198512468847536\n",
      "FOLD: 4, EPOCH: 54, valid_loss: 0.016641721439858276\n",
      "FOLD: 4, EPOCH: 55, train_loss: 0.017050642664394072\n",
      "FOLD: 4, EPOCH: 55, valid_loss: 0.01665102845678727\n",
      "FOLD: 4, EPOCH: 56, train_loss: 0.016920674898691715\n",
      "FOLD: 4, EPOCH: 56, valid_loss: 0.016678852546546195\n",
      "FOLD: 4, EPOCH: 57, train_loss: 0.016800404165781314\n",
      "FOLD: 4, EPOCH: 57, valid_loss: 0.01668926856170098\n",
      "FOLD: 4, EPOCH: 58, train_loss: 0.016782657970343867\n",
      "FOLD: 4, EPOCH: 58, valid_loss: 0.01668899164845546\n",
      "FOLD: 4, EPOCH: 59, train_loss: 0.016761251725256443\n",
      "FOLD: 4, EPOCH: 59, valid_loss: 0.016679971892800596\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.6769019098051132\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.3713414735264248\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.06153182359712739\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.019804822384483285\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.022925986241429084\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.022456818570693333\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.025568602606654167\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.0236773236344258\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.022565391533557445\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.018608411049677268\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.020971540974513175\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.018429353626237974\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.021062787634230428\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.018517161202099588\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.02039777557215383\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.01884178537875414\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.02031724051602425\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.018769141390091844\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.0203204476184422\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.018509308497111004\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.020420656833917864\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.019493470796280436\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.020530829398382095\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.01870739780780342\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.02047165817310733\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.018752495758235455\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.020517028183225663\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.019137381058600213\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.02061889174003755\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.018910726635820337\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.02062280824588191\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.019108874826795526\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.020647396063131672\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.018674760436018307\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.02073488283541895\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.01905097708933883\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.020842864604726914\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.019478504235545795\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.020828764404981367\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.01922150370147493\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.020879728899848078\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.018817289939357176\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.020841756354897253\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.019257345754239295\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.020988316365307378\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.019163484685122967\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.02089530472313204\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.01895787049498823\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.020836478916387405\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.018832785180873342\n",
      "FOLD: 5, EPOCH: 25, train_loss: 0.02073476446732398\n",
      "FOLD: 5, EPOCH: 25, valid_loss: 0.01903219251996941\n",
      "FOLD: 5, EPOCH: 26, train_loss: 0.020797800873556444\n",
      "FOLD: 5, EPOCH: 26, valid_loss: 0.01970067164964146\n",
      "FOLD: 5, EPOCH: 27, train_loss: 0.020712972023794726\n",
      "FOLD: 5, EPOCH: 27, valid_loss: 0.018942294642329216\n",
      "FOLD: 5, EPOCH: 28, train_loss: 0.020726458788398773\n",
      "FOLD: 5, EPOCH: 28, valid_loss: 0.0185287832799885\n",
      "FOLD: 5, EPOCH: 29, train_loss: 0.02064507264764078\n",
      "FOLD: 5, EPOCH: 29, valid_loss: 0.018542033413218126\n",
      "FOLD: 5, EPOCH: 30, train_loss: 0.020632786087451442\n",
      "FOLD: 5, EPOCH: 30, valid_loss: 0.01875753752473328\n",
      "FOLD: 5, EPOCH: 31, train_loss: 0.020519922685719307\n",
      "FOLD: 5, EPOCH: 31, valid_loss: 0.018582820167971983\n",
      "FOLD: 5, EPOCH: 32, train_loss: 0.020413723888416443\n",
      "FOLD: 5, EPOCH: 32, valid_loss: 0.01848199911829498\n",
      "FOLD: 5, EPOCH: 33, train_loss: 0.020411024446929656\n",
      "FOLD: 5, EPOCH: 33, valid_loss: 0.018236167418460052\n",
      "FOLD: 5, EPOCH: 34, train_loss: 0.020308520248340022\n",
      "FOLD: 5, EPOCH: 34, valid_loss: 0.01826577607749237\n",
      "FOLD: 5, EPOCH: 35, train_loss: 0.020259539470557242\n",
      "FOLD: 5, EPOCH: 35, valid_loss: 0.018387348701556522\n",
      "FOLD: 5, EPOCH: 36, train_loss: 0.020130432180819974\n",
      "FOLD: 5, EPOCH: 36, valid_loss: 0.018400620462165937\n",
      "FOLD: 5, EPOCH: 37, train_loss: 0.019961394946421348\n",
      "FOLD: 5, EPOCH: 37, valid_loss: 0.018146988107926317\n",
      "FOLD: 5, EPOCH: 38, train_loss: 0.01981915318437161\n",
      "FOLD: 5, EPOCH: 38, valid_loss: 0.018113966927760176\n",
      "FOLD: 5, EPOCH: 39, train_loss: 0.019780024573687584\n",
      "FOLD: 5, EPOCH: 39, valid_loss: 0.01803936545426647\n",
      "FOLD: 5, EPOCH: 40, train_loss: 0.019568316193838274\n",
      "FOLD: 5, EPOCH: 40, valid_loss: 0.017976636067032814\n",
      "FOLD: 5, EPOCH: 41, train_loss: 0.01946842637994597\n",
      "FOLD: 5, EPOCH: 41, valid_loss: 0.01816983407156335\n",
      "FOLD: 5, EPOCH: 42, train_loss: 0.019353168133285737\n",
      "FOLD: 5, EPOCH: 42, valid_loss: 0.01800403231754899\n",
      "FOLD: 5, EPOCH: 43, train_loss: 0.019163182918583193\n",
      "FOLD: 5, EPOCH: 43, valid_loss: 0.018063008319586515\n",
      "FOLD: 5, EPOCH: 44, train_loss: 0.019076074930208346\n",
      "FOLD: 5, EPOCH: 44, valid_loss: 0.017952253421147663\n",
      "FOLD: 5, EPOCH: 45, train_loss: 0.01891892106542664\n",
      "FOLD: 5, EPOCH: 45, valid_loss: 0.017980370049675305\n",
      "FOLD: 5, EPOCH: 46, train_loss: 0.018743149341354445\n",
      "FOLD: 5, EPOCH: 46, valid_loss: 0.017760468129482534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 5, EPOCH: 47, train_loss: 0.018544358453683314\n",
      "FOLD: 5, EPOCH: 47, valid_loss: 0.017916019695500534\n",
      "FOLD: 5, EPOCH: 48, train_loss: 0.018380120636955384\n",
      "FOLD: 5, EPOCH: 48, valid_loss: 0.01778933173045516\n",
      "FOLD: 5, EPOCH: 49, train_loss: 0.018173437379300595\n",
      "FOLD: 5, EPOCH: 49, valid_loss: 0.017879307735711336\n",
      "FOLD: 5, EPOCH: 50, train_loss: 0.01797969062482157\n",
      "FOLD: 5, EPOCH: 50, valid_loss: 0.0178900347608659\n",
      "FOLD: 5, EPOCH: 51, train_loss: 0.017853942453380553\n",
      "FOLD: 5, EPOCH: 51, valid_loss: 0.017859716951433156\n",
      "FOLD: 5, EPOCH: 52, train_loss: 0.017624924890697002\n",
      "FOLD: 5, EPOCH: 52, valid_loss: 0.017908038726697367\n",
      "FOLD: 5, EPOCH: 53, train_loss: 0.01747122262754748\n",
      "FOLD: 5, EPOCH: 53, valid_loss: 0.017838050559577014\n",
      "FOLD: 5, EPOCH: 54, train_loss: 0.01733763217325172\n",
      "FOLD: 5, EPOCH: 54, valid_loss: 0.01784621339498295\n",
      "FOLD: 5, EPOCH: 55, train_loss: 0.01721328247578875\n",
      "FOLD: 5, EPOCH: 55, valid_loss: 0.01785027463403013\n",
      "FOLD: 5, EPOCH: 56, train_loss: 0.017105205573381917\n",
      "FOLD: 5, EPOCH: 56, valid_loss: 0.01782471039849851\n",
      "FOLD: 5, EPOCH: 57, train_loss: 0.01704054708562551\n",
      "FOLD: 5, EPOCH: 57, valid_loss: 0.017813363164249394\n",
      "FOLD: 5, EPOCH: 58, train_loss: 0.016918401510244416\n",
      "FOLD: 5, EPOCH: 58, valid_loss: 0.017858707656462986\n",
      "FOLD: 5, EPOCH: 59, train_loss: 0.01698437996449009\n",
      "FOLD: 5, EPOCH: 59, valid_loss: 0.017858111454794805\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.6762735607162599\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.35838042988496666\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.06165543736950044\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.02105065983007936\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.02310866909402032\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.019707640194717574\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.02260560473847774\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.019325665581752274\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.022101917502380188\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.020543804173083866\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.023049797814699912\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.01869475479949923\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.020950429105470257\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.01867568547673085\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.020537808910012244\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.01883443379226853\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.020388899070601308\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.01870328713865841\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.02035164813841543\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.01894926411264083\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.02042627572532623\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.01891302766607088\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.020442369237782494\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.018614039482439265\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.020498077991989352\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.018534674802247214\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.02049669304922704\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.019141800372916108\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.020551779253348227\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.018772007349659416\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.020638910512770375\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.018843359697391007\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.020647113842348897\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.018834616331493154\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.02075071178617016\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.018988724030992565\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.0207012053939604\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.01887353728799259\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.02074242926413013\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.018884422805379417\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.02077093474086254\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.018726388649905428\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.020785210834395502\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.0186956169850686\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.02080926845871633\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.01907325623666539\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.020794528554524145\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.018842870259986204\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.020743373697323184\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.018999672768747106\n",
      "FOLD: 6, EPOCH: 25, train_loss: 0.02070799514410957\n",
      "FOLD: 6, EPOCH: 25, valid_loss: 0.019139787510913962\n",
      "FOLD: 6, EPOCH: 26, train_loss: 0.020723214060548813\n",
      "FOLD: 6, EPOCH: 26, valid_loss: 0.019008959479191723\n",
      "FOLD: 6, EPOCH: 27, train_loss: 0.02063105653130239\n",
      "FOLD: 6, EPOCH: 27, valid_loss: 0.01873330947230844\n",
      "FOLD: 6, EPOCH: 28, train_loss: 0.020656411481961127\n",
      "FOLD: 6, EPOCH: 28, valid_loss: 0.01902926296872251\n",
      "FOLD: 6, EPOCH: 29, train_loss: 0.02061337768550842\n",
      "FOLD: 6, EPOCH: 29, valid_loss: 0.01885224035119309\n",
      "FOLD: 6, EPOCH: 30, train_loss: 0.02050869482899866\n",
      "FOLD: 6, EPOCH: 30, valid_loss: 0.018660436987000352\n",
      "FOLD: 6, EPOCH: 31, train_loss: 0.020395672789985133\n",
      "FOLD: 6, EPOCH: 31, valid_loss: 0.018580189084305483\n",
      "FOLD: 6, EPOCH: 32, train_loss: 0.02037485190216572\n",
      "FOLD: 6, EPOCH: 32, valid_loss: 0.01835382340804619\n",
      "FOLD: 6, EPOCH: 33, train_loss: 0.02021476919612577\n",
      "FOLD: 6, EPOCH: 33, valid_loss: 0.01861217650858795\n",
      "FOLD: 6, EPOCH: 34, train_loss: 0.020217226710050336\n",
      "FOLD: 6, EPOCH: 34, valid_loss: 0.018548594787716866\n",
      "FOLD: 6, EPOCH: 35, train_loss: 0.020051958592187974\n",
      "FOLD: 6, EPOCH: 35, valid_loss: 0.018441941041280243\n",
      "FOLD: 6, EPOCH: 36, train_loss: 0.01999223876383997\n",
      "FOLD: 6, EPOCH: 36, valid_loss: 0.018212436205324006\n",
      "FOLD: 6, EPOCH: 37, train_loss: 0.01988403369342127\n",
      "FOLD: 6, EPOCH: 37, valid_loss: 0.018060833325280863\n",
      "FOLD: 6, EPOCH: 38, train_loss: 0.019808559684503464\n",
      "FOLD: 6, EPOCH: 38, valid_loss: 0.018257555168341186\n",
      "FOLD: 6, EPOCH: 39, train_loss: 0.019662374282075512\n",
      "FOLD: 6, EPOCH: 39, valid_loss: 0.018227299839696464\n",
      "FOLD: 6, EPOCH: 40, train_loss: 0.019508191366349497\n",
      "FOLD: 6, EPOCH: 40, valid_loss: 0.017960340989863172\n",
      "FOLD: 6, EPOCH: 41, train_loss: 0.019389167307846008\n",
      "FOLD: 6, EPOCH: 41, valid_loss: 0.018074491499539685\n",
      "FOLD: 6, EPOCH: 42, train_loss: 0.019262987056807165\n",
      "FOLD: 6, EPOCH: 42, valid_loss: 0.018019450116245186\n",
      "FOLD: 6, EPOCH: 43, train_loss: 0.019132270615908407\n",
      "FOLD: 6, EPOCH: 43, valid_loss: 0.017839969081037185\n",
      "FOLD: 6, EPOCH: 44, train_loss: 0.01899576599319135\n",
      "FOLD: 6, EPOCH: 44, valid_loss: 0.017880674068103817\n",
      "FOLD: 6, EPOCH: 45, train_loss: 0.018852636182019787\n",
      "FOLD: 6, EPOCH: 45, valid_loss: 0.01800438531619661\n",
      "FOLD: 6, EPOCH: 46, train_loss: 0.01866824851641732\n",
      "FOLD: 6, EPOCH: 46, valid_loss: 0.017816690837635714\n",
      "FOLD: 6, EPOCH: 47, train_loss: 0.018506167420456486\n",
      "FOLD: 6, EPOCH: 47, valid_loss: 0.017904629218665993\n",
      "FOLD: 6, EPOCH: 48, train_loss: 0.018375081971528068\n",
      "FOLD: 6, EPOCH: 48, valid_loss: 0.01782007986570106\n",
      "FOLD: 6, EPOCH: 49, train_loss: 0.018141920978744185\n",
      "FOLD: 6, EPOCH: 49, valid_loss: 0.017838095040882334\n",
      "FOLD: 6, EPOCH: 50, train_loss: 0.01798644417956952\n",
      "FOLD: 6, EPOCH: 50, valid_loss: 0.01783865865539102\n",
      "FOLD: 6, EPOCH: 51, train_loss: 0.017859560281278625\n",
      "FOLD: 6, EPOCH: 51, valid_loss: 0.01786940742064925\n",
      "FOLD: 6, EPOCH: 52, train_loss: 0.017663073894237317\n",
      "FOLD: 6, EPOCH: 52, valid_loss: 0.01782273512114497\n",
      "FOLD: 6, EPOCH: 53, train_loss: 0.017526758257900513\n",
      "FOLD: 6, EPOCH: 53, valid_loss: 0.01786829629803405\n",
      "FOLD: 6, EPOCH: 54, train_loss: 0.017395849676141814\n",
      "FOLD: 6, EPOCH: 54, valid_loss: 0.01786167859373724\n",
      "FOLD: 6, EPOCH: 55, train_loss: 0.0172523315515249\n",
      "FOLD: 6, EPOCH: 55, valid_loss: 0.017841746099293232\n",
      "FOLD: 6, EPOCH: 56, train_loss: 0.017158269539715783\n",
      "FOLD: 6, EPOCH: 56, valid_loss: 0.017835354761165732\n",
      "FOLD: 6, EPOCH: 57, train_loss: 0.017045193784419568\n",
      "FOLD: 6, EPOCH: 57, valid_loss: 0.01785668095245081\n",
      "FOLD: 6, EPOCH: 58, train_loss: 0.017030374615663483\n",
      "FOLD: 6, EPOCH: 58, valid_loss: 0.017832778175087535\n",
      "FOLD: 6, EPOCH: 59, train_loss: 0.017005431285548593\n",
      "FOLD: 6, EPOCH: 59, valid_loss: 0.017883731874034685\n",
      "FOLD: 7, EPOCH: 0, train_loss: 0.6763058347086752\n",
      "FOLD: 7, EPOCH: 0, valid_loss: 0.36615708295036764\n",
      "FOLD: 7, EPOCH: 1, train_loss: 0.06086256403115488\n",
      "FOLD: 7, EPOCH: 1, valid_loss: 0.019735961933346355\n",
      "FOLD: 7, EPOCH: 2, train_loss: 0.023214175455993222\n",
      "FOLD: 7, EPOCH: 2, valid_loss: 0.01933422695626231\n",
      "FOLD: 7, EPOCH: 3, train_loss: 0.031249968250913005\n",
      "FOLD: 7, EPOCH: 3, valid_loss: 0.022869684788234094\n",
      "FOLD: 7, EPOCH: 4, train_loss: 0.025242526648986723\n",
      "FOLD: 7, EPOCH: 4, valid_loss: 0.019282456596984583\n",
      "FOLD: 7, EPOCH: 5, train_loss: 0.023048554745412644\n",
      "FOLD: 7, EPOCH: 5, valid_loss: 0.018664830090368494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 7, EPOCH: 6, train_loss: 0.021757030763453054\n",
      "FOLD: 7, EPOCH: 6, valid_loss: 0.018255224232287967\n",
      "FOLD: 7, EPOCH: 7, train_loss: 0.021039734300105802\n",
      "FOLD: 7, EPOCH: 7, valid_loss: 0.01801673892666312\n",
      "FOLD: 7, EPOCH: 8, train_loss: 0.02073973482174258\n",
      "FOLD: 7, EPOCH: 8, valid_loss: 0.018081734176067746\n",
      "FOLD: 7, EPOCH: 9, train_loss: 0.02055784517959241\n",
      "FOLD: 7, EPOCH: 9, valid_loss: 0.017909204149070906\n",
      "FOLD: 7, EPOCH: 10, train_loss: 0.020511998152059892\n",
      "FOLD: 7, EPOCH: 10, valid_loss: 0.017905493431231555\n",
      "FOLD: 7, EPOCH: 11, train_loss: 0.0203487126577285\n",
      "FOLD: 7, EPOCH: 11, valid_loss: 0.018139959696461174\n",
      "FOLD: 7, EPOCH: 12, train_loss: 0.020431889305191655\n",
      "FOLD: 7, EPOCH: 12, valid_loss: 0.017938222736120224\n",
      "FOLD: 7, EPOCH: 13, train_loss: 0.02046985735575999\n",
      "FOLD: 7, EPOCH: 13, valid_loss: 0.01832738606368794\n",
      "FOLD: 7, EPOCH: 14, train_loss: 0.020447755508845852\n",
      "FOLD: 7, EPOCH: 14, valid_loss: 0.018174505189937705\n",
      "FOLD: 7, EPOCH: 15, train_loss: 0.020559757118744235\n",
      "FOLD: 7, EPOCH: 15, valid_loss: 0.01776894149096573\n",
      "FOLD: 7, EPOCH: 16, train_loss: 0.020569902213831103\n",
      "FOLD: 7, EPOCH: 16, valid_loss: 0.01783202270812848\n",
      "FOLD: 7, EPOCH: 17, train_loss: 0.020654861797248163\n",
      "FOLD: 7, EPOCH: 17, valid_loss: 0.018243842374752548\n",
      "FOLD: 7, EPOCH: 18, train_loss: 0.020723519029636536\n",
      "FOLD: 7, EPOCH: 18, valid_loss: 0.01796891836120802\n",
      "FOLD: 7, EPOCH: 19, train_loss: 0.02071733300483996\n",
      "FOLD: 7, EPOCH: 19, valid_loss: 0.017887400353656095\n",
      "FOLD: 7, EPOCH: 20, train_loss: 0.02072783649688767\n",
      "FOLD: 7, EPOCH: 20, valid_loss: 0.017749552450635853\n",
      "FOLD: 7, EPOCH: 21, train_loss: 0.020800607435164913\n",
      "FOLD: 7, EPOCH: 21, valid_loss: 0.018387423061272678\n",
      "FOLD: 7, EPOCH: 22, train_loss: 0.020694897251744424\n",
      "FOLD: 7, EPOCH: 22, valid_loss: 0.018120766124304605\n",
      "FOLD: 7, EPOCH: 23, train_loss: 0.020836120134880468\n",
      "FOLD: 7, EPOCH: 23, valid_loss: 0.017931056921096408\n",
      "FOLD: 7, EPOCH: 24, train_loss: 0.020732427039934744\n",
      "FOLD: 7, EPOCH: 24, valid_loss: 0.01819087378680706\n",
      "FOLD: 7, EPOCH: 25, train_loss: 0.020749175969150758\n",
      "FOLD: 7, EPOCH: 25, valid_loss: 0.018073514870860997\n",
      "FOLD: 7, EPOCH: 26, train_loss: 0.02072137406756801\n",
      "FOLD: 7, EPOCH: 26, valid_loss: 0.018106094835435644\n",
      "FOLD: 7, EPOCH: 27, train_loss: 0.02073712591682711\n",
      "FOLD: 7, EPOCH: 27, valid_loss: 0.018216678982271868\n",
      "FOLD: 7, EPOCH: 28, train_loss: 0.020644785487844097\n",
      "FOLD: 7, EPOCH: 28, valid_loss: 0.01802949749809854\n",
      "FOLD: 7, EPOCH: 29, train_loss: 0.020630888304402753\n",
      "FOLD: 7, EPOCH: 29, valid_loss: 0.01811968447530971\n",
      "FOLD: 7, EPOCH: 30, train_loss: 0.0205318603183954\n",
      "FOLD: 7, EPOCH: 30, valid_loss: 0.01790005056297078\n",
      "FOLD: 7, EPOCH: 31, train_loss: 0.02048981487751007\n",
      "FOLD: 7, EPOCH: 31, valid_loss: 0.018061672063434824\n",
      "FOLD: 7, EPOCH: 32, train_loss: 0.020437875822667154\n",
      "FOLD: 7, EPOCH: 32, valid_loss: 0.017816775752341047\n",
      "FOLD: 7, EPOCH: 33, train_loss: 0.020324275258087342\n",
      "FOLD: 7, EPOCH: 33, valid_loss: 0.01759170401183998\n",
      "FOLD: 7, EPOCH: 34, train_loss: 0.020232689885362504\n",
      "FOLD: 7, EPOCH: 34, valid_loss: 0.017700482269420344\n",
      "FOLD: 7, EPOCH: 35, train_loss: 0.020101728494609557\n",
      "FOLD: 7, EPOCH: 35, valid_loss: 0.01758052025209455\n",
      "FOLD: 7, EPOCH: 36, train_loss: 0.020068146757060482\n",
      "FOLD: 7, EPOCH: 36, valid_loss: 0.01781591323806959\n",
      "FOLD: 7, EPOCH: 37, train_loss: 0.01997262233447644\n",
      "FOLD: 7, EPOCH: 37, valid_loss: 0.017662097316454437\n",
      "FOLD: 7, EPOCH: 38, train_loss: 0.019840957320505573\n",
      "FOLD: 7, EPOCH: 38, valid_loss: 0.017478244269595426\n",
      "FOLD: 7, EPOCH: 39, train_loss: 0.019708016238385632\n",
      "FOLD: 7, EPOCH: 39, valid_loss: 0.017531130024615454\n",
      "FOLD: 7, EPOCH: 40, train_loss: 0.019654861176686904\n",
      "FOLD: 7, EPOCH: 40, valid_loss: 0.017503951402271494\n",
      "FOLD: 7, EPOCH: 41, train_loss: 0.019441780099465\n",
      "FOLD: 7, EPOCH: 41, valid_loss: 0.017220988431397605\n",
      "FOLD: 7, EPOCH: 42, train_loss: 0.0192840255556568\n",
      "FOLD: 7, EPOCH: 42, valid_loss: 0.017308325780665174\n",
      "FOLD: 7, EPOCH: 43, train_loss: 0.01918789419315515\n",
      "FOLD: 7, EPOCH: 43, valid_loss: 0.017224345958846456\n",
      "FOLD: 7, EPOCH: 44, train_loss: 0.019011413041622408\n",
      "FOLD: 7, EPOCH: 44, valid_loss: 0.01722018009818652\n",
      "FOLD: 7, EPOCH: 45, train_loss: 0.018787042315929165\n",
      "FOLD: 7, EPOCH: 45, valid_loss: 0.017182584523278123\n",
      "FOLD: 7, EPOCH: 46, train_loss: 0.018655990544826754\n",
      "FOLD: 7, EPOCH: 46, valid_loss: 0.01717300121398533\n",
      "FOLD: 7, EPOCH: 47, train_loss: 0.01847118234201785\n",
      "FOLD: 7, EPOCH: 47, valid_loss: 0.017256691010997575\n",
      "FOLD: 7, EPOCH: 48, train_loss: 0.018293925008225825\n",
      "FOLD: 7, EPOCH: 48, valid_loss: 0.01717600818066036\n",
      "FOLD: 7, EPOCH: 49, train_loss: 0.018079472861943707\n",
      "FOLD: 7, EPOCH: 49, valid_loss: 0.017114783965927714\n",
      "FOLD: 7, EPOCH: 50, train_loss: 0.01785434071094759\n",
      "FOLD: 7, EPOCH: 50, valid_loss: 0.017084685044691843\n",
      "FOLD: 7, EPOCH: 51, train_loss: 0.01767645219280835\n",
      "FOLD: 7, EPOCH: 51, valid_loss: 0.017094362965401483\n",
      "FOLD: 7, EPOCH: 52, train_loss: 0.01752492016962459\n",
      "FOLD: 7, EPOCH: 52, valid_loss: 0.017097049283192438\n",
      "FOLD: 7, EPOCH: 53, train_loss: 0.017337117428260464\n",
      "FOLD: 7, EPOCH: 53, valid_loss: 0.017088996356024462\n",
      "FOLD: 7, EPOCH: 54, train_loss: 0.017140450238460496\n",
      "FOLD: 7, EPOCH: 54, valid_loss: 0.01710237266824526\n",
      "FOLD: 7, EPOCH: 55, train_loss: 0.017004156653438844\n",
      "FOLD: 7, EPOCH: 55, valid_loss: 0.017076611025806737\n",
      "FOLD: 7, EPOCH: 56, train_loss: 0.016923483911781542\n",
      "FOLD: 7, EPOCH: 56, valid_loss: 0.017070886788561064\n",
      "FOLD: 7, EPOCH: 57, train_loss: 0.016827659609337006\n",
      "FOLD: 7, EPOCH: 57, valid_loss: 0.0170489139854908\n",
      "FOLD: 7, EPOCH: 58, train_loss: 0.01680458339471971\n",
      "FOLD: 7, EPOCH: 58, valid_loss: 0.01708311538266785\n",
      "FOLD: 7, EPOCH: 59, train_loss: 0.01673655648745837\n",
      "FOLD: 7, EPOCH: 59, valid_loss: 0.01706998806227656\n",
      "FOLD: 8, EPOCH: 0, train_loss: 0.6772492264547656\n",
      "FOLD: 8, EPOCH: 0, valid_loss: 0.37311725152863395\n",
      "FOLD: 8, EPOCH: 1, train_loss: 0.061577447107242\n",
      "FOLD: 8, EPOCH: 1, valid_loss: 0.019727422700574\n",
      "FOLD: 8, EPOCH: 2, train_loss: 0.023221612024691796\n",
      "FOLD: 8, EPOCH: 2, valid_loss: 0.01894632142244114\n",
      "FOLD: 8, EPOCH: 3, train_loss: 0.022715685792988348\n",
      "FOLD: 8, EPOCH: 3, valid_loss: 0.017775039757705398\n",
      "FOLD: 8, EPOCH: 4, train_loss: 0.025516180177369424\n",
      "FOLD: 8, EPOCH: 4, valid_loss: 0.0180652865415646\n",
      "FOLD: 8, EPOCH: 5, train_loss: 0.021468337276770222\n",
      "FOLD: 8, EPOCH: 5, valid_loss: 0.018258263615684375\n",
      "FOLD: 8, EPOCH: 6, train_loss: 0.02090248491975569\n",
      "FOLD: 8, EPOCH: 6, valid_loss: 0.01769665421711074\n",
      "FOLD: 8, EPOCH: 7, train_loss: 0.020567352589099638\n",
      "FOLD: 8, EPOCH: 7, valid_loss: 0.0181362217085229\n",
      "FOLD: 8, EPOCH: 8, train_loss: 0.020519017884808203\n",
      "FOLD: 8, EPOCH: 8, valid_loss: 0.017934588974134788\n",
      "FOLD: 8, EPOCH: 9, train_loss: 0.020534679966588174\n",
      "FOLD: 8, EPOCH: 9, valid_loss: 0.0179019362355272\n",
      "FOLD: 8, EPOCH: 10, train_loss: 0.02046752525193076\n",
      "FOLD: 8, EPOCH: 10, valid_loss: 0.01786255965837174\n",
      "FOLD: 8, EPOCH: 11, train_loss: 0.020511783995935992\n",
      "FOLD: 8, EPOCH: 11, valid_loss: 0.01802945349158512\n",
      "FOLD: 8, EPOCH: 12, train_loss: 0.020580627793265926\n",
      "FOLD: 8, EPOCH: 12, valid_loss: 0.01802448286778397\n",
      "FOLD: 8, EPOCH: 13, train_loss: 0.02058512233197689\n",
      "FOLD: 8, EPOCH: 13, valid_loss: 0.01802235986623499\n",
      "FOLD: 8, EPOCH: 14, train_loss: 0.02069347044152598\n",
      "FOLD: 8, EPOCH: 14, valid_loss: 0.01783427440871795\n",
      "FOLD: 8, EPOCH: 15, train_loss: 0.020700746714588134\n",
      "FOLD: 8, EPOCH: 15, valid_loss: 0.018691422572980326\n",
      "FOLD: 8, EPOCH: 16, train_loss: 0.020708324628010873\n",
      "FOLD: 8, EPOCH: 16, valid_loss: 0.01820661908843451\n",
      "FOLD: 8, EPOCH: 17, train_loss: 0.02077923968674675\n",
      "FOLD: 8, EPOCH: 17, valid_loss: 0.01837867720880442\n",
      "FOLD: 8, EPOCH: 18, train_loss: 0.020858734653842064\n",
      "FOLD: 8, EPOCH: 18, valid_loss: 0.018108464311808348\n",
      "FOLD: 8, EPOCH: 19, train_loss: 0.0207438129691347\n",
      "FOLD: 8, EPOCH: 19, valid_loss: 0.01796111526588599\n",
      "FOLD: 8, EPOCH: 20, train_loss: 0.020790017372177495\n",
      "FOLD: 8, EPOCH: 20, valid_loss: 0.01807918508226673\n",
      "FOLD: 8, EPOCH: 21, train_loss: 0.020882678957235428\n",
      "FOLD: 8, EPOCH: 21, valid_loss: 0.017838875607897837\n",
      "FOLD: 8, EPOCH: 22, train_loss: 0.020863829024376408\n",
      "FOLD: 8, EPOCH: 22, valid_loss: 0.018182266193131607\n",
      "FOLD: 8, EPOCH: 23, train_loss: 0.020807164510892283\n",
      "FOLD: 8, EPOCH: 23, valid_loss: 0.017935494374897745\n",
      "FOLD: 8, EPOCH: 24, train_loss: 0.020819687302554808\n",
      "FOLD: 8, EPOCH: 24, valid_loss: 0.017689676024019718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 8, EPOCH: 25, train_loss: 0.02076127070092386\n",
      "FOLD: 8, EPOCH: 25, valid_loss: 0.017934698870198593\n",
      "FOLD: 8, EPOCH: 26, train_loss: 0.020790212048638252\n",
      "FOLD: 8, EPOCH: 26, valid_loss: 0.01805307897221711\n",
      "FOLD: 8, EPOCH: 27, train_loss: 0.020748118767815252\n",
      "FOLD: 8, EPOCH: 27, valid_loss: 0.01797288718322913\n",
      "FOLD: 8, EPOCH: 28, train_loss: 0.020693492625028856\n",
      "FOLD: 8, EPOCH: 28, valid_loss: 0.017752340011712577\n",
      "FOLD: 8, EPOCH: 29, train_loss: 0.020625619205736346\n",
      "FOLD: 8, EPOCH: 29, valid_loss: 0.017654992329577606\n",
      "FOLD: 8, EPOCH: 30, train_loss: 0.02056430969988146\n",
      "FOLD: 8, EPOCH: 30, valid_loss: 0.01767169213336375\n",
      "FOLD: 8, EPOCH: 31, train_loss: 0.020437562754077297\n",
      "FOLD: 8, EPOCH: 31, valid_loss: 0.017836420745071437\n",
      "FOLD: 8, EPOCH: 32, train_loss: 0.020422424448113288\n",
      "FOLD: 8, EPOCH: 32, valid_loss: 0.01763067968810598\n",
      "FOLD: 8, EPOCH: 33, train_loss: 0.020301776463466308\n",
      "FOLD: 8, EPOCH: 33, valid_loss: 0.01739451687576042\n",
      "FOLD: 8, EPOCH: 34, train_loss: 0.02023071699565457\n",
      "FOLD: 8, EPOCH: 34, valid_loss: 0.017342776525765657\n",
      "FOLD: 8, EPOCH: 35, train_loss: 0.020116443343220217\n",
      "FOLD: 8, EPOCH: 35, valid_loss: 0.017477660284688074\n",
      "FOLD: 8, EPOCH: 36, train_loss: 0.020082130679680454\n",
      "FOLD: 8, EPOCH: 36, valid_loss: 0.017640419925252598\n",
      "FOLD: 8, EPOCH: 37, train_loss: 0.01993102466146792\n",
      "FOLD: 8, EPOCH: 37, valid_loss: 0.017723775054845545\n",
      "FOLD: 8, EPOCH: 38, train_loss: 0.01983068138360977\n",
      "FOLD: 8, EPOCH: 38, valid_loss: 0.017165955156087875\n",
      "FOLD: 8, EPOCH: 39, train_loss: 0.01966802408137629\n",
      "FOLD: 8, EPOCH: 39, valid_loss: 0.017266217670920823\n",
      "FOLD: 8, EPOCH: 40, train_loss: 0.019583762605344095\n",
      "FOLD: 8, EPOCH: 40, valid_loss: 0.01722559363891681\n",
      "FOLD: 8, EPOCH: 41, train_loss: 0.01948439946338054\n",
      "FOLD: 8, EPOCH: 41, valid_loss: 0.017233951793362696\n",
      "FOLD: 8, EPOCH: 42, train_loss: 0.019330331034237338\n",
      "FOLD: 8, EPOCH: 42, valid_loss: 0.017046237881812785\n",
      "FOLD: 8, EPOCH: 43, train_loss: 0.019175824210528405\n",
      "FOLD: 8, EPOCH: 43, valid_loss: 0.01711652733178602\n",
      "FOLD: 8, EPOCH: 44, train_loss: 0.019086684310628522\n",
      "FOLD: 8, EPOCH: 44, valid_loss: 0.017132921868728265\n",
      "FOLD: 8, EPOCH: 45, train_loss: 0.01890828453845555\n",
      "FOLD: 8, EPOCH: 45, valid_loss: 0.017035756053196058\n",
      "FOLD: 8, EPOCH: 46, train_loss: 0.01876297127455473\n",
      "FOLD: 8, EPOCH: 46, valid_loss: 0.01714627253305581\n",
      "FOLD: 8, EPOCH: 47, train_loss: 0.018600538493164124\n",
      "FOLD: 8, EPOCH: 47, valid_loss: 0.017151568447136216\n",
      "FOLD: 8, EPOCH: 48, train_loss: 0.01843099996087051\n",
      "FOLD: 8, EPOCH: 48, valid_loss: 0.01710810512304306\n",
      "FOLD: 8, EPOCH: 49, train_loss: 0.018228876915189526\n",
      "FOLD: 8, EPOCH: 49, valid_loss: 0.016993147269305255\n",
      "FOLD: 8, EPOCH: 50, train_loss: 0.018040391904932836\n",
      "FOLD: 8, EPOCH: 50, valid_loss: 0.0171349861452149\n",
      "FOLD: 8, EPOCH: 51, train_loss: 0.017885433125399773\n",
      "FOLD: 8, EPOCH: 51, valid_loss: 0.017083750313354865\n",
      "FOLD: 8, EPOCH: 52, train_loss: 0.01766170512043661\n",
      "FOLD: 8, EPOCH: 52, valid_loss: 0.017047669272869825\n",
      "FOLD: 8, EPOCH: 53, train_loss: 0.017515543163303407\n",
      "FOLD: 8, EPOCH: 53, valid_loss: 0.017019980535325076\n",
      "FOLD: 8, EPOCH: 54, train_loss: 0.017413357591196416\n",
      "FOLD: 8, EPOCH: 54, valid_loss: 0.017034036417802174\n",
      "FOLD: 8, EPOCH: 55, train_loss: 0.017241546679889003\n",
      "FOLD: 8, EPOCH: 55, valid_loss: 0.017008772844241724\n",
      "FOLD: 8, EPOCH: 56, train_loss: 0.01713246676109491\n",
      "FOLD: 8, EPOCH: 56, valid_loss: 0.017054558058993682\n",
      "FOLD: 8, EPOCH: 57, train_loss: 0.017081731377590087\n",
      "FOLD: 8, EPOCH: 57, valid_loss: 0.01705415655548374\n",
      "FOLD: 8, EPOCH: 58, train_loss: 0.017005001765585715\n",
      "FOLD: 8, EPOCH: 58, valid_loss: 0.017091885209083557\n",
      "FOLD: 8, EPOCH: 59, train_loss: 0.01701765662479785\n",
      "FOLD: 8, EPOCH: 59, valid_loss: 0.017043347160021465\n",
      "FOLD: 9, EPOCH: 0, train_loss: 0.677055036829364\n",
      "FOLD: 9, EPOCH: 0, valid_loss: 0.36185571882459855\n",
      "FOLD: 9, EPOCH: 1, train_loss: 0.06160436383178157\n",
      "FOLD: 9, EPOCH: 1, valid_loss: 0.02024341540204154\n",
      "FOLD: 9, EPOCH: 2, train_loss: 0.023536262793406364\n",
      "FOLD: 9, EPOCH: 2, valid_loss: 0.019393825593094032\n",
      "FOLD: 9, EPOCH: 3, train_loss: 0.04479697517329647\n",
      "FOLD: 9, EPOCH: 3, valid_loss: 0.08852688430084123\n",
      "FOLD: 9, EPOCH: 4, train_loss: 0.028873126773584272\n",
      "FOLD: 9, EPOCH: 4, valid_loss: 0.025105302015112504\n",
      "FOLD: 9, EPOCH: 5, train_loss: 0.025900688238682284\n",
      "FOLD: 9, EPOCH: 5, valid_loss: 0.021382834037972823\n",
      "FOLD: 9, EPOCH: 6, train_loss: 0.023236702202308564\n",
      "FOLD: 9, EPOCH: 6, valid_loss: 0.02075088407016463\n",
      "FOLD: 9, EPOCH: 7, train_loss: 0.02242500581327946\n",
      "FOLD: 9, EPOCH: 7, valid_loss: 0.019026743041144475\n",
      "FOLD: 9, EPOCH: 8, train_loss: 0.021928303172030757\n",
      "FOLD: 9, EPOCH: 8, valid_loss: 0.02090956260346704\n",
      "FOLD: 9, EPOCH: 9, train_loss: 0.021618358947096333\n",
      "FOLD: 9, EPOCH: 9, valid_loss: 0.02009971056961351\n",
      "FOLD: 9, EPOCH: 10, train_loss: 0.021388653245183728\n",
      "FOLD: 9, EPOCH: 10, valid_loss: 0.019460063841607835\n",
      "FOLD: 9, EPOCH: 11, train_loss: 0.021265207699710322\n",
      "FOLD: 9, EPOCH: 11, valid_loss: 0.019387889343003433\n",
      "FOLD: 9, EPOCH: 12, train_loss: 0.02118589791559404\n",
      "FOLD: 9, EPOCH: 12, valid_loss: 0.02018497335828013\n",
      "FOLD: 9, EPOCH: 13, train_loss: 0.02128809637600376\n",
      "FOLD: 9, EPOCH: 13, valid_loss: 0.019873099194632635\n",
      "FOLD: 9, EPOCH: 14, train_loss: 0.021190268342052735\n",
      "FOLD: 9, EPOCH: 14, valid_loss: 0.018938806735806994\n",
      "FOLD: 9, EPOCH: 15, train_loss: 0.021146625232311988\n",
      "FOLD: 9, EPOCH: 15, valid_loss: 0.02165608387440443\n",
      "FOLD: 9, EPOCH: 16, train_loss: 0.021006007288252155\n",
      "FOLD: 9, EPOCH: 16, valid_loss: 0.017674967750079103\n",
      "FOLD: 9, EPOCH: 17, train_loss: 0.021031922138025683\n",
      "FOLD: 9, EPOCH: 17, valid_loss: 0.018394177676075034\n",
      "FOLD: 9, EPOCH: 18, train_loss: 0.021003914720589115\n",
      "FOLD: 9, EPOCH: 18, valid_loss: 0.018585667428043153\n",
      "FOLD: 9, EPOCH: 19, train_loss: 0.02098845428516788\n",
      "FOLD: 9, EPOCH: 19, valid_loss: 0.02020664533807172\n",
      "FOLD: 9, EPOCH: 20, train_loss: 0.021186089840146805\n",
      "FOLD: 9, EPOCH: 20, valid_loss: 0.018099670091436967\n",
      "FOLD: 9, EPOCH: 21, train_loss: 0.021138970625977364\n",
      "FOLD: 9, EPOCH: 21, valid_loss: 0.018550222636097007\n",
      "FOLD: 9, EPOCH: 22, train_loss: 0.02106088490015076\n",
      "FOLD: 9, EPOCH: 22, valid_loss: 0.01778936396456427\n",
      "FOLD: 9, EPOCH: 23, train_loss: 0.021012240498056334\n",
      "FOLD: 9, EPOCH: 23, valid_loss: 0.017920416883296438\n",
      "FOLD: 9, EPOCH: 24, train_loss: 0.021139113556954168\n",
      "FOLD: 9, EPOCH: 24, valid_loss: 0.01834836881607771\n",
      "FOLD: 9, EPOCH: 25, train_loss: 0.0211778232166844\n",
      "FOLD: 9, EPOCH: 25, valid_loss: 0.017557427597542603\n",
      "FOLD: 9, EPOCH: 26, train_loss: 0.02095975774911142\n",
      "FOLD: 9, EPOCH: 26, valid_loss: 0.018257165741589334\n",
      "FOLD: 9, EPOCH: 27, train_loss: 0.02091348101535151\n",
      "FOLD: 9, EPOCH: 27, valid_loss: 0.01748922032614549\n",
      "FOLD: 9, EPOCH: 28, train_loss: 0.020795280678618338\n",
      "FOLD: 9, EPOCH: 28, valid_loss: 0.017625246817866962\n",
      "FOLD: 9, EPOCH: 29, train_loss: 0.020754625720362508\n",
      "FOLD: 9, EPOCH: 29, valid_loss: 0.01730472594499588\n",
      "FOLD: 9, EPOCH: 30, train_loss: 0.020764866194898084\n",
      "FOLD: 9, EPOCH: 30, valid_loss: 0.017406956292688847\n",
      "FOLD: 9, EPOCH: 31, train_loss: 0.02054366375650129\n",
      "FOLD: 9, EPOCH: 31, valid_loss: 0.01724563714944654\n",
      "FOLD: 9, EPOCH: 32, train_loss: 0.020609378129724534\n",
      "FOLD: 9, EPOCH: 32, valid_loss: 0.017383142995337646\n",
      "FOLD: 9, EPOCH: 33, train_loss: 0.020608294995561723\n",
      "FOLD: 9, EPOCH: 33, valid_loss: 0.01749465221332179\n",
      "FOLD: 9, EPOCH: 34, train_loss: 0.020572549044605225\n",
      "FOLD: 9, EPOCH: 34, valid_loss: 0.017264605241103306\n",
      "FOLD: 9, EPOCH: 35, train_loss: 0.020685591320357015\n",
      "FOLD: 9, EPOCH: 35, valid_loss: 0.01729603298008442\n",
      "FOLD: 9, EPOCH: 36, train_loss: 0.020428116343194438\n",
      "FOLD: 9, EPOCH: 36, valid_loss: 0.016983673597375553\n",
      "FOLD: 9, EPOCH: 37, train_loss: 0.02020775507534704\n",
      "FOLD: 9, EPOCH: 37, valid_loss: 0.017012133470012084\n",
      "FOLD: 9, EPOCH: 38, train_loss: 0.020374175834078943\n",
      "FOLD: 9, EPOCH: 38, valid_loss: 0.017228165537946753\n",
      "FOLD: 9, EPOCH: 39, train_loss: 0.02034349355005449\n",
      "FOLD: 9, EPOCH: 39, valid_loss: 0.01706464671426349\n",
      "FOLD: 9, EPOCH: 40, train_loss: 0.019948062817415884\n",
      "FOLD: 9, EPOCH: 40, valid_loss: 0.016972043551504612\n",
      "FOLD: 9, EPOCH: 41, train_loss: 0.01989552367839121\n",
      "FOLD: 9, EPOCH: 41, valid_loss: 0.016999653695772093\n",
      "FOLD: 9, EPOCH: 42, train_loss: 0.019724035996102517\n",
      "FOLD: 9, EPOCH: 42, valid_loss: 0.01688910886231396\n",
      "FOLD: 9, EPOCH: 43, train_loss: 0.01956187603214095\n",
      "FOLD: 9, EPOCH: 43, valid_loss: 0.016857425785726972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 9, EPOCH: 44, train_loss: 0.01942183448662681\n",
      "FOLD: 9, EPOCH: 44, valid_loss: 0.016726150539600186\n",
      "FOLD: 9, EPOCH: 45, train_loss: 0.019335934579853088\n",
      "FOLD: 9, EPOCH: 45, valid_loss: 0.016865828177995153\n",
      "FOLD: 9, EPOCH: 46, train_loss: 0.019048704062738727\n",
      "FOLD: 9, EPOCH: 46, valid_loss: 0.016895799690650568\n",
      "FOLD: 9, EPOCH: 47, train_loss: 0.01889652795488796\n",
      "FOLD: 9, EPOCH: 47, valid_loss: 0.016750028615610466\n",
      "FOLD: 9, EPOCH: 48, train_loss: 0.01872402430181542\n",
      "FOLD: 9, EPOCH: 48, valid_loss: 0.016691248915675614\n",
      "FOLD: 9, EPOCH: 49, train_loss: 0.018484930369642473\n",
      "FOLD: 9, EPOCH: 49, valid_loss: 0.01658610896103912\n",
      "FOLD: 9, EPOCH: 50, train_loss: 0.018296139272710968\n",
      "FOLD: 9, EPOCH: 50, valid_loss: 0.016635489132669237\n",
      "FOLD: 9, EPOCH: 51, train_loss: 0.018008807902374576\n",
      "FOLD: 9, EPOCH: 51, valid_loss: 0.016691686275104683\n",
      "FOLD: 9, EPOCH: 52, train_loss: 0.017844531967514947\n",
      "FOLD: 9, EPOCH: 52, valid_loss: 0.016736523248255253\n",
      "FOLD: 9, EPOCH: 53, train_loss: 0.01762381631640657\n",
      "FOLD: 9, EPOCH: 53, valid_loss: 0.016705308626923297\n",
      "FOLD: 9, EPOCH: 54, train_loss: 0.017417221744695018\n",
      "FOLD: 9, EPOCH: 54, valid_loss: 0.016698419426878292\n",
      "FOLD: 9, EPOCH: 55, train_loss: 0.017317082708881746\n",
      "FOLD: 9, EPOCH: 55, valid_loss: 0.016682933653808303\n",
      "FOLD: 9, EPOCH: 56, train_loss: 0.01712649125125139\n",
      "FOLD: 9, EPOCH: 56, valid_loss: 0.016757046648611624\n",
      "FOLD: 9, EPOCH: 57, train_loss: 0.016982204334870462\n",
      "FOLD: 9, EPOCH: 57, valid_loss: 0.016696570130685966\n",
      "FOLD: 9, EPOCH: 58, train_loss: 0.01702140425482104\n",
      "FOLD: 9, EPOCH: 58, valid_loss: 0.01680118181846208\n",
      "FOLD: 9, EPOCH: 59, train_loss: 0.016994986160387915\n",
      "FOLD: 9, EPOCH: 59, valid_loss: 0.016691902031501133\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6761989524287563\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.37480762074975404\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.06106337796776525\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.021338406292831198\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023267038478966683\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.019738832050386595\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.02278380647542015\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.02760237148579429\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.022510454827739345\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01846013174337499\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.02062690188327143\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018210414906635004\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02112577040829966\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01835505697218811\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020537786678441108\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.018134455689612555\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020397660977417423\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018195886712740448\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020397275409871532\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01816255708827692\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020401158400120273\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01779794736820109\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.020526195101199612\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01827799342572689\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.0205732682779912\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018366965739166036\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.02060053940982588\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.018176438177333158\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.020685209934749912\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01835082591894795\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.0207144875560076\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.018580374910550958\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.02077230366487657\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.018943856963339972\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.02110764938256433\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01861586542252232\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.020966666900823192\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01845625853713821\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.020908803168323734\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.018674211357446277\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.02090272347052251\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018350140794235116\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.0208635647090212\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.018637058927732354\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.02089098690738601\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01817803062936839\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.020909528266037664\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.018020791932940483\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.020840059136671404\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.018352421767571393\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.02090405226955491\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.018515547627911848\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.020818546210085193\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.018053850159049034\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.020747240957233213\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01844790336840293\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.020729420334100725\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.0181066834313028\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.020706630834648687\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018162651316208\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.02058321051299572\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.01789380018325413\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.02052848043461\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.017890164409490192\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.020459506264136684\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.017845456871916267\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.020357347628281963\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.018054426373804316\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.020310098233242188\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.017649590530816245\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.020128712815142447\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.01780944865416078\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.02004395671669514\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.017563532490064118\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.01990829864817281\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.01759384462938589\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.019789142161607744\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.017591919859542567\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.019705292834870276\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.017576540546382174\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.019552222903697722\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.01751493290066719\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.019427409677976563\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.017549785675809663\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.019303787283359037\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.017575657214311993\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.019219874782908347\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.01747480730580933\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.019026040778525415\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.017390398527769482\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.018864802896015106\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.017315657754593036\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.018709289871396556\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.01746560983798083\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.01859593636566593\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.017287560793406823\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.01838247707534221\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.01735214965746683\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.018193041124651508\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.017348493558957297\n",
      "FOLD: 0, EPOCH: 50, train_loss: 0.018003185688247603\n",
      "FOLD: 0, EPOCH: 50, valid_loss: 0.017315724590683684\n",
      "FOLD: 0, EPOCH: 51, train_loss: 0.017796220612381734\n",
      "FOLD: 0, EPOCH: 51, valid_loss: 0.017259040847420692\n",
      "FOLD: 0, EPOCH: 52, train_loss: 0.017633600905537606\n",
      "FOLD: 0, EPOCH: 52, valid_loss: 0.017355245483272216\n",
      "FOLD: 0, EPOCH: 53, train_loss: 0.017467458065479034\n",
      "FOLD: 0, EPOCH: 53, valid_loss: 0.017294166719212252\n",
      "FOLD: 0, EPOCH: 54, train_loss: 0.017369661510231033\n",
      "FOLD: 0, EPOCH: 54, valid_loss: 0.017273916862905025\n",
      "FOLD: 0, EPOCH: 55, train_loss: 0.017285153492083472\n",
      "FOLD: 0, EPOCH: 55, valid_loss: 0.017282152712783393\n",
      "FOLD: 0, EPOCH: 56, train_loss: 0.017136097002413964\n",
      "FOLD: 0, EPOCH: 56, valid_loss: 0.01730096132001456\n",
      "FOLD: 0, EPOCH: 57, train_loss: 0.01707556829938004\n",
      "FOLD: 0, EPOCH: 57, valid_loss: 0.017325556179618135\n",
      "FOLD: 0, EPOCH: 58, train_loss: 0.017003471866971064\n",
      "FOLD: 0, EPOCH: 58, valid_loss: 0.017298827550428754\n",
      "FOLD: 0, EPOCH: 59, train_loss: 0.01699913632605345\n",
      "FOLD: 0, EPOCH: 59, valid_loss: 0.017297864672453964\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6764162436608345\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.3703865276442634\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.061806381049175414\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02129992392535011\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02315900236848862\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.020638242622630462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 3, train_loss: 0.022326319736819113\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.02566093584108684\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.024390986477655748\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.021035381748030584\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.021822298750762015\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.019072235354946718\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020941400780312477\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.018371542915701866\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.02067583894297\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.018275018367502425\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.02063609781044145\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.018695689013434783\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020584447910228083\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.018207459710538387\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.020575759800211077\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.018389536171323724\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020594223156090705\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018404803652730253\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.02066136822104454\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.018278488734116156\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.02057446839828645\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01846344117075205\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.020704478698392068\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01877988616211547\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.02062486139757018\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018375361131297216\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.020651993119428235\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.018162787426263094\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.02072929028541811\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01821640030377441\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.02076555020626514\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01828159112483263\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.020739631967679147\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01846436442186435\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.02078361693889864\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01852943670625488\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.0208256630647567\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01856130589213636\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.020751892402768136\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.018356209362132683\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.020726354432202155\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018271496726406947\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.02077476271698552\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01867434884318047\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.020757082957894572\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.01889464357453916\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.020725003918332437\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.018333265299184456\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.020667876351264214\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.018458758843027882\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.020591299163718376\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.018612433845798176\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.020578522102967386\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.018261389134244785\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.0205462001023754\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.018288407009094954\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.020410647567722106\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.01830478571355343\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.020365880489830047\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018411889620539214\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.02023518843756568\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.017992440352423325\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.020158876190262458\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.018343608515957992\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.02010758841230023\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.01808866382473045\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.01997501137516191\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.018080492245240345\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.019902479023702683\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.01787025848817494\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.019728478765295397\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.018199940781212516\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.019666576709958816\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.01788794585607118\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.019518856391791375\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.017819540885587532\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.01939836513371237\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.01784001999638147\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.019253909275416405\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.01775517909684115\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.01914852027210497\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.017508186399936676\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.019045779902127483\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.017696501790649362\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.018863531838982334\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.01764425950952702\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.01870737582925827\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.017609160186515913\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.018518981463726488\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.017649715352389548\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.018374190287243936\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.01762129392267929\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.018144666415549095\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.017545044732590515\n",
      "FOLD: 1, EPOCH: 50, train_loss: 0.01801917265740133\n",
      "FOLD: 1, EPOCH: 50, valid_loss: 0.01755763983560933\n",
      "FOLD: 1, EPOCH: 51, train_loss: 0.017814435773799497\n",
      "FOLD: 1, EPOCH: 51, valid_loss: 0.017601731336779065\n",
      "FOLD: 1, EPOCH: 52, train_loss: 0.017657349877540144\n",
      "FOLD: 1, EPOCH: 52, valid_loss: 0.017499931311855715\n",
      "FOLD: 1, EPOCH: 53, train_loss: 0.017513552500355627\n",
      "FOLD: 1, EPOCH: 53, valid_loss: 0.017623715206152864\n",
      "FOLD: 1, EPOCH: 54, train_loss: 0.017381729774417414\n",
      "FOLD: 1, EPOCH: 54, valid_loss: 0.017482735578798585\n",
      "FOLD: 1, EPOCH: 55, train_loss: 0.01726055577878029\n",
      "FOLD: 1, EPOCH: 55, valid_loss: 0.017499353891859453\n",
      "FOLD: 1, EPOCH: 56, train_loss: 0.01717989531856391\n",
      "FOLD: 1, EPOCH: 56, valid_loss: 0.017556457521600857\n",
      "FOLD: 1, EPOCH: 57, train_loss: 0.017094828182410808\n",
      "FOLD: 1, EPOCH: 57, valid_loss: 0.01753941359412339\n",
      "FOLD: 1, EPOCH: 58, train_loss: 0.01703569633105109\n",
      "FOLD: 1, EPOCH: 58, valid_loss: 0.01754337243942751\n",
      "FOLD: 1, EPOCH: 59, train_loss: 0.017039866673369562\n",
      "FOLD: 1, EPOCH: 59, valid_loss: 0.01750546947328581\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6764493473114506\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.3639860484335158\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.061346394736920634\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.02171451153440608\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02302698661242762\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01978076932330926\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.02265832449399656\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.02073406283226278\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.023715949719471316\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018661579272399347\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.021421798246522104\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.021895359063314065\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.0209530908974909\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.01843978961308797\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.02060073033696221\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018536034557554457\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.02051997405867423\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.018310904709829226\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.020460135453651027\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.018311990424990654\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.020487833275429666\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.018441055797868304\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.020483571170799193\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018852533565627203\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.020625754734200814\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.0183875089407795\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.020674676003475344\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01855453248653147\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.02064464057405149\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018674815953191783\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.020716009781725945\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.018238673710988626\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.020768928804224537\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.018739180794606607\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.020828020813003664\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.018595953109777637\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.02083144876505098\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.018534767855372693\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.020851934556999515\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.018404208020203643\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.02086901748853345\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.018507561646401882\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.02087491360162535\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.018632510314799018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 22, train_loss: 0.020925608770020546\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018454800308164623\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.020915057065506136\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01896169978297419\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.020964028878558066\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018456254050963454\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.0208838872851864\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.01853175347463952\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.020798375024910897\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01819894602522254\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.020778601292160248\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01833810533086459\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.02078852031019426\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.01815296828539835\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.020685891939267037\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.018209404467294615\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.020696177213422713\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.017891247601558764\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.020551180082463448\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.017973780683759186\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.020447840938164343\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017912641892002687\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.020447948767292883\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017813463022725448\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.020342319302501216\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.017775401059124205\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.0203162832365882\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.01778404963099294\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.020142771447858504\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.017629409001933202\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.01999698369012725\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.01789195126750403\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.019917453476978885\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.017672282540135913\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.019771983498527157\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.017580118754671678\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.019638529684274427\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.017503427393320534\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.019558511656378546\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.01727361645963457\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.019478602743437212\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.017242374260806374\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.019241365706247668\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.0173984804811577\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.019111468534796467\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017383611036671534\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.018994537230220532\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017329635719458263\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.018864713200638372\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.017259349425633747\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.018652488789971798\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.01734724175184965\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.01850877720261774\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.017298816806740232\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.018327811564649306\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.01739745716460877\n",
      "FOLD: 2, EPOCH: 50, train_loss: 0.01813672496787002\n",
      "FOLD: 2, EPOCH: 50, valid_loss: 0.017296832830955584\n",
      "FOLD: 2, EPOCH: 51, train_loss: 0.017921205471840597\n",
      "FOLD: 2, EPOCH: 51, valid_loss: 0.017298053277449474\n",
      "FOLD: 2, EPOCH: 52, train_loss: 0.017757798376823626\n",
      "FOLD: 2, EPOCH: 52, valid_loss: 0.01727235337926282\n",
      "FOLD: 2, EPOCH: 53, train_loss: 0.01764576112430903\n",
      "FOLD: 2, EPOCH: 53, valid_loss: 0.0172600283080505\n",
      "FOLD: 2, EPOCH: 54, train_loss: 0.017515943626001958\n",
      "FOLD: 2, EPOCH: 54, valid_loss: 0.01721528669198354\n",
      "FOLD: 2, EPOCH: 55, train_loss: 0.017379563397938204\n",
      "FOLD: 2, EPOCH: 55, valid_loss: 0.017232242816438276\n",
      "FOLD: 2, EPOCH: 56, train_loss: 0.017318480551963854\n",
      "FOLD: 2, EPOCH: 56, valid_loss: 0.017261403768012922\n",
      "FOLD: 2, EPOCH: 57, train_loss: 0.017194104663306668\n",
      "FOLD: 2, EPOCH: 57, valid_loss: 0.01723659307592445\n",
      "FOLD: 2, EPOCH: 58, train_loss: 0.01716790400565632\n",
      "FOLD: 2, EPOCH: 58, valid_loss: 0.01723428505162398\n",
      "FOLD: 2, EPOCH: 59, train_loss: 0.01712679136544466\n",
      "FOLD: 2, EPOCH: 59, valid_loss: 0.01723495591431856\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6755816050114171\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.3566955344544517\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.06130889640940774\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020612351596355438\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02338084770787147\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.021101419917411275\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.022851280447456143\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018220983031723235\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.021422072067376105\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 1.290783491399553\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.023682778376725413\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.018727452752904758\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.021244389635901296\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01810848956099815\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02091355435550213\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.018197741876873706\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.02083134332731847\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017935529092533722\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.02079462180695226\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017989331080267828\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.020701948793665055\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.018149070700423584\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.02073550650910024\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017815961347271998\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.020688296758359478\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.018022908104790583\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.020669358716376367\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01813023713313871\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.020776241945643578\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.0181037666172617\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.020809928051406336\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01799575596426924\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.020805803578226797\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.018158150785085227\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.020842926504631196\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017772839301162295\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.020847596744856527\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017919688019901514\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.02080792967350252\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.018094935609648626\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020810614309964642\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.0180739454097218\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.020847878340751896\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.018265311502748065\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.020840518549084662\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017848142164034977\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020878878500192394\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017804287632720336\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020872908422062474\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017973777631090745\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.0208475032520871\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.017795422942274146\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.02074399568861531\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.017889312675429717\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.020655659189628018\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.018207601478530303\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.020725574488601378\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.017671472392976284\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.020572475079567203\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.01793839218508866\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.020554167633095095\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.01768356975581911\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.020469351701678767\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.017628592180295125\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.020455847872841743\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.017501276452094316\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.020354834186934654\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.017389112048678927\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.020208515455165218\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.01752632799454861\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.020066632138144587\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.01721120962045259\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.019993954932978078\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.017351180780678988\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.019928546778617367\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017217344138771296\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.01985034757564145\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.017136319850881893\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.019677320363060122\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.01721546731682287\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.01963248705912021\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017017264384776354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 41, train_loss: 0.01945027480082166\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.017169830285840564\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.01932198132478422\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.016971409062130585\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.019207326034384388\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.01707780873402953\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.019088207041063617\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.016931880731135607\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.018918042533820675\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.016741851137744054\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.018737136752855394\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.01678968474475874\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.018566794146693523\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.01672014609600107\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.018407156967347668\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.01680222831459509\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.01820589356845425\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.01678796200495627\n",
      "FOLD: 3, EPOCH: 50, train_loss: 0.018057946289979643\n",
      "FOLD: 3, EPOCH: 50, valid_loss: 0.016803254890773032\n",
      "FOLD: 3, EPOCH: 51, train_loss: 0.017840818369821196\n",
      "FOLD: 3, EPOCH: 51, valid_loss: 0.016845196899440553\n",
      "FOLD: 3, EPOCH: 52, train_loss: 0.017659402806912698\n",
      "FOLD: 3, EPOCH: 52, valid_loss: 0.016775491802642744\n",
      "FOLD: 3, EPOCH: 53, train_loss: 0.017563338030970866\n",
      "FOLD: 3, EPOCH: 53, valid_loss: 0.0168232635801865\n",
      "FOLD: 3, EPOCH: 54, train_loss: 0.017399449928873968\n",
      "FOLD: 3, EPOCH: 54, valid_loss: 0.016792570137315325\n",
      "FOLD: 3, EPOCH: 55, train_loss: 0.017260305793775667\n",
      "FOLD: 3, EPOCH: 55, valid_loss: 0.016778846530036792\n",
      "FOLD: 3, EPOCH: 56, train_loss: 0.017141388921487716\n",
      "FOLD: 3, EPOCH: 56, valid_loss: 0.01680367502073447\n",
      "FOLD: 3, EPOCH: 57, train_loss: 0.017092382781688245\n",
      "FOLD: 3, EPOCH: 57, valid_loss: 0.016807924386941724\n",
      "FOLD: 3, EPOCH: 58, train_loss: 0.01702953822790615\n",
      "FOLD: 3, EPOCH: 58, valid_loss: 0.016803615260869265\n",
      "FOLD: 3, EPOCH: 59, train_loss: 0.017004348914469444\n",
      "FOLD: 3, EPOCH: 59, valid_loss: 0.016804622951895\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6752865660575128\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.3593650394015842\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.06148297767485342\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020265090072320566\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023539981089772715\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.019512457669609122\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.022558706974790944\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017793907473484676\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.02402918312338091\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018268752222259838\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.021229340580682602\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017598269145107932\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020644580993440843\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.018555958134432633\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.020606986192926283\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.018956544602082834\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.020626939628874102\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017438045961575374\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.020427103148352714\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017681669754286606\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.02052713103832737\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017888431230352983\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.02052144254407575\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01784416971107324\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.020630504767740927\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017868425283167098\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.020715608483841342\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017924503112832706\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.020664561371649466\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017672605398628447\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.020735309260987465\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.01759354852967792\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.02081162576233187\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.0179715259000659\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.02080011792000263\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01776925815890233\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.021007876747077513\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01766479139526685\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.020867501535723285\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01804558736168676\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.02091672734147118\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.019196646391517587\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.020945127728965975\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017830721671796508\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.020949823625626102\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01782981927196185\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.020958478135928032\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01820541571618782\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.020954916854539225\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01811002567410469\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.020925356748123323\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.01787920803245571\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.02090136967599392\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.017701996645579737\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.02081596540106881\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.01762424088600609\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.0208224065842167\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.01790420224683152\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.02074722042006831\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01757228798750374\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.020675030663128823\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.01737657417025831\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.02065810046849712\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.01748716515592403\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.020551969579631284\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017279306271423895\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.02043971428948064\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.01760790145231618\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.02035925711595243\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.01736767352041271\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.020241697276792217\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.01702259165338344\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.02018710091229408\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.017036689911037683\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.020090358944669845\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.01724038774975472\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.01994293365747698\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017105756120549306\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.019786108201069217\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.016948738031917147\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.0196781495285611\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.017010367527190182\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.019563780040029555\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.017099619584365025\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.019497392879378413\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.017045146526975766\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.01938385116236825\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.016774126432008214\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.01918714775914146\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.01678319513383839\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.019044763895292437\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.016743509150627587\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.01885397436638032\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.01680816730691327\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.018694310731464818\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.016660710589753255\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.018544805506544727\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.016617464367300272\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.018342608297544142\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.016623359225276444\n",
      "FOLD: 4, EPOCH: 50, train_loss: 0.018236482029239977\n",
      "FOLD: 4, EPOCH: 50, valid_loss: 0.016676225492523775\n",
      "FOLD: 4, EPOCH: 51, train_loss: 0.018036931945431618\n",
      "FOLD: 4, EPOCH: 51, valid_loss: 0.016681783729129367\n",
      "FOLD: 4, EPOCH: 52, train_loss: 0.017875511547730816\n",
      "FOLD: 4, EPOCH: 52, valid_loss: 0.01666978234425187\n",
      "FOLD: 4, EPOCH: 53, train_loss: 0.017705986011893517\n",
      "FOLD: 4, EPOCH: 53, valid_loss: 0.016668458986613486\n",
      "FOLD: 4, EPOCH: 54, train_loss: 0.01756587587897816\n",
      "FOLD: 4, EPOCH: 54, valid_loss: 0.016688674584858947\n",
      "FOLD: 4, EPOCH: 55, train_loss: 0.01750256450426194\n",
      "FOLD: 4, EPOCH: 55, valid_loss: 0.016637536748829816\n",
      "FOLD: 4, EPOCH: 56, train_loss: 0.017403811222362904\n",
      "FOLD: 4, EPOCH: 56, valid_loss: 0.016637453498939674\n",
      "FOLD: 4, EPOCH: 57, train_loss: 0.01729195401553185\n",
      "FOLD: 4, EPOCH: 57, valid_loss: 0.016654838756140735\n",
      "FOLD: 4, EPOCH: 58, train_loss: 0.017279616382814222\n",
      "FOLD: 4, EPOCH: 58, valid_loss: 0.016645255446847942\n",
      "FOLD: 4, EPOCH: 59, train_loss: 0.01726683640191632\n",
      "FOLD: 4, EPOCH: 59, valid_loss: 0.016648635785612795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 5, EPOCH: 0, train_loss: 0.676215232956794\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.3592497424946891\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.06188709120596609\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.020082700273229018\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.023257686966849912\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.019086479105883174\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.022315139780121465\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.026683359406888485\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.02305454596156074\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.022639671651025612\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.02191150855393179\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.018709778061343565\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.02086069530416881\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.0185842194284002\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.02048193587651176\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.019016487213472526\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.020492285634240798\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.018896686223646004\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.020471703297188205\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.018595214415755536\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.020434004705279105\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.018489370122551918\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.020460579616408195\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.018666914974649746\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.02047696844224007\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.018979478006561596\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.020588710964206728\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.01929663328660859\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.02083799781337861\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.018976701630486384\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.0207237777570563\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.018853488481707044\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.02071992462921527\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.01911011379626062\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.020939252213124305\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.018765623888207808\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.020899725501095093\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.018695416653321847\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.020886799164356724\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.019023347439037427\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.020864672778594877\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.01881131384935644\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.020924203650605294\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.019098200938767858\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.020886014413929756\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.01922339138885339\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.02097684548747155\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.020115309601856604\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.021146180901315904\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.018582866320179567\n",
      "FOLD: 5, EPOCH: 25, train_loss: 0.02095248046661577\n",
      "FOLD: 5, EPOCH: 25, valid_loss: 0.018800428344143763\n",
      "FOLD: 5, EPOCH: 26, train_loss: 0.02095339181682756\n",
      "FOLD: 5, EPOCH: 26, valid_loss: 0.018844927557640605\n",
      "FOLD: 5, EPOCH: 27, train_loss: 0.020770513650871094\n",
      "FOLD: 5, EPOCH: 27, valid_loss: 0.01851134157429139\n",
      "FOLD: 5, EPOCH: 28, train_loss: 0.020652697175260512\n",
      "FOLD: 5, EPOCH: 28, valid_loss: 0.018876874405476782\n",
      "FOLD: 5, EPOCH: 29, train_loss: 0.020647951816358874\n",
      "FOLD: 5, EPOCH: 29, valid_loss: 0.018436402910285525\n",
      "FOLD: 5, EPOCH: 30, train_loss: 0.02057864996454408\n",
      "FOLD: 5, EPOCH: 30, valid_loss: 0.018475720038016636\n",
      "FOLD: 5, EPOCH: 31, train_loss: 0.02056905088886138\n",
      "FOLD: 5, EPOCH: 31, valid_loss: 0.018368982813424535\n",
      "FOLD: 5, EPOCH: 32, train_loss: 0.02038537934422493\n",
      "FOLD: 5, EPOCH: 32, valid_loss: 0.01838863951464494\n",
      "FOLD: 5, EPOCH: 33, train_loss: 0.020380096041387127\n",
      "FOLD: 5, EPOCH: 33, valid_loss: 0.01855048920131392\n",
      "FOLD: 5, EPOCH: 34, train_loss: 0.020267437290280094\n",
      "FOLD: 5, EPOCH: 34, valid_loss: 0.01817962320314513\n",
      "FOLD: 5, EPOCH: 35, train_loss: 0.020098680858650516\n",
      "FOLD: 5, EPOCH: 35, valid_loss: 0.018200450473361544\n",
      "FOLD: 5, EPOCH: 36, train_loss: 0.020088663324713707\n",
      "FOLD: 5, EPOCH: 36, valid_loss: 0.0178915366737379\n",
      "FOLD: 5, EPOCH: 37, train_loss: 0.019972062279139797\n",
      "FOLD: 5, EPOCH: 37, valid_loss: 0.01802075881924894\n",
      "FOLD: 5, EPOCH: 38, train_loss: 0.01976981071695205\n",
      "FOLD: 5, EPOCH: 38, valid_loss: 0.018064081203192472\n",
      "FOLD: 5, EPOCH: 39, train_loss: 0.019710541144013403\n",
      "FOLD: 5, EPOCH: 39, valid_loss: 0.018099209138502676\n",
      "FOLD: 5, EPOCH: 40, train_loss: 0.01963944689881417\n",
      "FOLD: 5, EPOCH: 40, valid_loss: 0.017762398450738855\n",
      "FOLD: 5, EPOCH: 41, train_loss: 0.019509771201879748\n",
      "FOLD: 5, EPOCH: 41, valid_loss: 0.017931160827477772\n",
      "FOLD: 5, EPOCH: 42, train_loss: 0.019308903356713633\n",
      "FOLD: 5, EPOCH: 42, valid_loss: 0.017812866251915693\n",
      "FOLD: 5, EPOCH: 43, train_loss: 0.019264922963996088\n",
      "FOLD: 5, EPOCH: 43, valid_loss: 0.017840919447027974\n",
      "FOLD: 5, EPOCH: 44, train_loss: 0.019024455481238902\n",
      "FOLD: 5, EPOCH: 44, valid_loss: 0.017719475655919976\n",
      "FOLD: 5, EPOCH: 45, train_loss: 0.01896600373569996\n",
      "FOLD: 5, EPOCH: 45, valid_loss: 0.017692496844877798\n",
      "FOLD: 5, EPOCH: 46, train_loss: 0.018746622219201058\n",
      "FOLD: 5, EPOCH: 46, valid_loss: 0.017767607958780393\n",
      "FOLD: 5, EPOCH: 47, train_loss: 0.01865292393392132\n",
      "FOLD: 5, EPOCH: 47, valid_loss: 0.017888288013637066\n",
      "FOLD: 5, EPOCH: 48, train_loss: 0.018500373464438225\n",
      "FOLD: 5, EPOCH: 48, valid_loss: 0.017757088566819828\n",
      "FOLD: 5, EPOCH: 49, train_loss: 0.018339918878289962\n",
      "FOLD: 5, EPOCH: 49, valid_loss: 0.01779053406789899\n",
      "FOLD: 5, EPOCH: 50, train_loss: 0.01811884552120201\n",
      "FOLD: 5, EPOCH: 50, valid_loss: 0.017777051517946854\n",
      "FOLD: 5, EPOCH: 51, train_loss: 0.017956548610762242\n",
      "FOLD: 5, EPOCH: 51, valid_loss: 0.01779710760133134\n",
      "FOLD: 5, EPOCH: 52, train_loss: 0.01779003364424552\n",
      "FOLD: 5, EPOCH: 52, valid_loss: 0.017740799424548943\n",
      "FOLD: 5, EPOCH: 53, train_loss: 0.017613583376571054\n",
      "FOLD: 5, EPOCH: 53, valid_loss: 0.017806977033615112\n",
      "FOLD: 5, EPOCH: 54, train_loss: 0.017565904046979643\n",
      "FOLD: 5, EPOCH: 54, valid_loss: 0.017738631202114954\n",
      "FOLD: 5, EPOCH: 55, train_loss: 0.017370584661201123\n",
      "FOLD: 5, EPOCH: 55, valid_loss: 0.017753786717851956\n",
      "FOLD: 5, EPOCH: 56, train_loss: 0.01727555597261075\n",
      "FOLD: 5, EPOCH: 56, valid_loss: 0.01773342593676514\n",
      "FOLD: 5, EPOCH: 57, train_loss: 0.017236167673141727\n",
      "FOLD: 5, EPOCH: 57, valid_loss: 0.017749986456086237\n",
      "FOLD: 5, EPOCH: 58, train_loss: 0.017190167049486792\n",
      "FOLD: 5, EPOCH: 58, valid_loss: 0.017741332658463053\n",
      "FOLD: 5, EPOCH: 59, train_loss: 0.017173258185146315\n",
      "FOLD: 5, EPOCH: 59, valid_loss: 0.01777324742741055\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.6762321793263958\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.36236562097773833\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.06155407547710404\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.020635999739170074\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.02276404753567711\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.01993005405015805\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.02326043401995013\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.02011754341861781\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.02252175163838171\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.02109695686136975\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.021633499259910274\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.018906510051558998\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.020576817338024415\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.018548025366138008\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.02047579051746476\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.01878211154218982\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.020490759262634863\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.01867004604462315\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.020376940576299546\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.018641461344326243\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.02044002708167799\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.018761499730103156\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.020477785434453718\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.018812195890966582\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.020525465737427435\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.018765491269090596\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.020546070269999966\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.018758836914511287\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.020634599630871126\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.01888924530323814\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.02062026279107217\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.018823603935101452\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.02069737800667363\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.01874602509333807\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.020736399461184777\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.018612083266763127\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.020751889025972737\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.019019581925343063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 6, EPOCH: 19, train_loss: 0.02080620482804314\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.01868705396704814\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.02082988381866486\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.0189444041427444\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.020789842211431073\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.018882442704018426\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.020817792391584766\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.01866276836132302\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.02077920171281984\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.019153222112971192\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.020796660502110757\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.01883952067617108\n",
      "FOLD: 6, EPOCH: 25, train_loss: 0.020779325704901448\n",
      "FOLD: 6, EPOCH: 25, valid_loss: 0.018885467530173415\n",
      "FOLD: 6, EPOCH: 26, train_loss: 0.020712023709089526\n",
      "FOLD: 6, EPOCH: 26, valid_loss: 0.018734775921877694\n",
      "FOLD: 6, EPOCH: 27, train_loss: 0.020739384295959628\n",
      "FOLD: 6, EPOCH: 27, valid_loss: 0.018529872245648327\n",
      "FOLD: 6, EPOCH: 28, train_loss: 0.02067241984749994\n",
      "FOLD: 6, EPOCH: 28, valid_loss: 0.01885353116428151\n",
      "FOLD: 6, EPOCH: 29, train_loss: 0.020671938491925116\n",
      "FOLD: 6, EPOCH: 29, valid_loss: 0.018912013948840255\n",
      "FOLD: 6, EPOCH: 30, train_loss: 0.02054852016510502\n",
      "FOLD: 6, EPOCH: 30, valid_loss: 0.018757465350277284\n",
      "FOLD: 6, EPOCH: 31, train_loss: 0.02041348818569414\n",
      "FOLD: 6, EPOCH: 31, valid_loss: 0.018437639919712263\n",
      "FOLD: 6, EPOCH: 32, train_loss: 0.02037950220607942\n",
      "FOLD: 6, EPOCH: 32, valid_loss: 0.018494228010668474\n",
      "FOLD: 6, EPOCH: 33, train_loss: 0.020323127424043994\n",
      "FOLD: 6, EPOCH: 33, valid_loss: 0.018476613413761642\n",
      "FOLD: 6, EPOCH: 34, train_loss: 0.020194078212784183\n",
      "FOLD: 6, EPOCH: 34, valid_loss: 0.018374391776673934\n",
      "FOLD: 6, EPOCH: 35, train_loss: 0.020112020113775806\n",
      "FOLD: 6, EPOCH: 35, valid_loss: 0.01835396354470183\n",
      "FOLD: 6, EPOCH: 36, train_loss: 0.01999941410556916\n",
      "FOLD: 6, EPOCH: 36, valid_loss: 0.01834278553724289\n",
      "FOLD: 6, EPOCH: 37, train_loss: 0.01990645861914081\n",
      "FOLD: 6, EPOCH: 37, valid_loss: 0.01836956577265964\n",
      "FOLD: 6, EPOCH: 38, train_loss: 0.01982289987706369\n",
      "FOLD: 6, EPOCH: 38, valid_loss: 0.01809489737977\n",
      "FOLD: 6, EPOCH: 39, train_loss: 0.01966769122067959\n",
      "FOLD: 6, EPOCH: 39, valid_loss: 0.01824165683458833\n",
      "FOLD: 6, EPOCH: 40, train_loss: 0.019554635942462952\n",
      "FOLD: 6, EPOCH: 40, valid_loss: 0.018069825189955094\n",
      "FOLD: 6, EPOCH: 41, train_loss: 0.019405143882238095\n",
      "FOLD: 6, EPOCH: 41, valid_loss: 0.01818850724136128\n",
      "FOLD: 6, EPOCH: 42, train_loss: 0.019317506421958248\n",
      "FOLD: 6, EPOCH: 42, valid_loss: 0.01792160821530749\n",
      "FOLD: 6, EPOCH: 43, train_loss: 0.01914446541378575\n",
      "FOLD: 6, EPOCH: 43, valid_loss: 0.01786311430966153\n",
      "FOLD: 6, EPOCH: 44, train_loss: 0.01905594351551225\n",
      "FOLD: 6, EPOCH: 44, valid_loss: 0.017824055681772092\n",
      "FOLD: 6, EPOCH: 45, train_loss: 0.018854544083437612\n",
      "FOLD: 6, EPOCH: 45, valid_loss: 0.017891235540018362\n",
      "FOLD: 6, EPOCH: 46, train_loss: 0.018709406376846375\n",
      "FOLD: 6, EPOCH: 46, valid_loss: 0.017844163977047977\n",
      "FOLD: 6, EPOCH: 47, train_loss: 0.01854433646846202\n",
      "FOLD: 6, EPOCH: 47, valid_loss: 0.01786695108475054\n",
      "FOLD: 6, EPOCH: 48, train_loss: 0.018384391868547085\n",
      "FOLD: 6, EPOCH: 48, valid_loss: 0.017797551665674236\n",
      "FOLD: 6, EPOCH: 49, train_loss: 0.018218710579939425\n",
      "FOLD: 6, EPOCH: 49, valid_loss: 0.017831860274514732\n",
      "FOLD: 6, EPOCH: 50, train_loss: 0.018098661219400743\n",
      "FOLD: 6, EPOCH: 50, valid_loss: 0.017776330220786965\n",
      "FOLD: 6, EPOCH: 51, train_loss: 0.01792913639257031\n",
      "FOLD: 6, EPOCH: 51, valid_loss: 0.0177020560402204\n",
      "FOLD: 6, EPOCH: 52, train_loss: 0.0177579534149939\n",
      "FOLD: 6, EPOCH: 52, valid_loss: 0.01781004009877934\n",
      "FOLD: 6, EPOCH: 53, train_loss: 0.01758871208275518\n",
      "FOLD: 6, EPOCH: 53, valid_loss: 0.017768942805774072\n",
      "FOLD: 6, EPOCH: 54, train_loss: 0.017468270328977416\n",
      "FOLD: 6, EPOCH: 54, valid_loss: 0.017768729094635036\n",
      "FOLD: 6, EPOCH: 55, train_loss: 0.017361681601933895\n",
      "FOLD: 6, EPOCH: 55, valid_loss: 0.01774415757287951\n",
      "FOLD: 6, EPOCH: 56, train_loss: 0.017273905867290114\n",
      "FOLD: 6, EPOCH: 56, valid_loss: 0.01776980756617644\n",
      "FOLD: 6, EPOCH: 57, train_loss: 0.017161929583357226\n",
      "FOLD: 6, EPOCH: 57, valid_loss: 0.017756006132592175\n",
      "FOLD: 6, EPOCH: 58, train_loss: 0.01718354693223392\n",
      "FOLD: 6, EPOCH: 58, valid_loss: 0.017731195808771777\n",
      "FOLD: 6, EPOCH: 59, train_loss: 0.017113718210208802\n",
      "FOLD: 6, EPOCH: 59, valid_loss: 0.017755286439376718\n",
      "FOLD: 7, EPOCH: 0, train_loss: 0.6763820453997581\n",
      "FOLD: 7, EPOCH: 0, valid_loss: 0.36272284563849955\n",
      "FOLD: 7, EPOCH: 1, train_loss: 0.06254132132857076\n",
      "FOLD: 7, EPOCH: 1, valid_loss: 0.02038158564006581\n",
      "FOLD: 7, EPOCH: 2, train_loss: 0.023128874299506986\n",
      "FOLD: 7, EPOCH: 2, valid_loss: 0.01879071247051744\n",
      "FOLD: 7, EPOCH: 3, train_loss: 0.023209730812138125\n",
      "FOLD: 7, EPOCH: 3, valid_loss: 0.018587047015042865\n",
      "FOLD: 7, EPOCH: 4, train_loss: 0.022025716557137427\n",
      "FOLD: 7, EPOCH: 4, valid_loss: 0.017925760873100337\n",
      "FOLD: 7, EPOCH: 5, train_loss: 0.023607365017937077\n",
      "FOLD: 7, EPOCH: 5, valid_loss: 0.01854108241112793\n",
      "FOLD: 7, EPOCH: 6, train_loss: 0.021503025197213695\n",
      "FOLD: 7, EPOCH: 6, valid_loss: 0.01824316382408142\n",
      "FOLD: 7, EPOCH: 7, train_loss: 0.02104608175014296\n",
      "FOLD: 7, EPOCH: 7, valid_loss: 0.017859395922106856\n",
      "FOLD: 7, EPOCH: 8, train_loss: 0.02072085328400135\n",
      "FOLD: 7, EPOCH: 8, valid_loss: 0.017798525336034158\n",
      "FOLD: 7, EPOCH: 9, train_loss: 0.020690795923432995\n",
      "FOLD: 7, EPOCH: 9, valid_loss: 0.01798068841590601\n",
      "FOLD: 7, EPOCH: 10, train_loss: 0.020592737173841847\n",
      "FOLD: 7, EPOCH: 10, valid_loss: 0.018053908996722278\n",
      "FOLD: 7, EPOCH: 11, train_loss: 0.020590989532009246\n",
      "FOLD: 7, EPOCH: 11, valid_loss: 0.01793146286817158\n",
      "FOLD: 7, EPOCH: 12, train_loss: 0.020644353113828166\n",
      "FOLD: 7, EPOCH: 12, valid_loss: 0.01817767815116574\n",
      "FOLD: 7, EPOCH: 13, train_loss: 0.020665196257252848\n",
      "FOLD: 7, EPOCH: 13, valid_loss: 0.018108789644697133\n",
      "FOLD: 7, EPOCH: 14, train_loss: 0.020588832997506665\n",
      "FOLD: 7, EPOCH: 14, valid_loss: 0.01782016401343486\n",
      "FOLD: 7, EPOCH: 15, train_loss: 0.02063332051038742\n",
      "FOLD: 7, EPOCH: 15, valid_loss: 0.018114082843941802\n",
      "FOLD: 7, EPOCH: 16, train_loss: 0.02070653389298147\n",
      "FOLD: 7, EPOCH: 16, valid_loss: 0.017790919388918316\n",
      "FOLD: 7, EPOCH: 17, train_loss: 0.020749460461158907\n",
      "FOLD: 7, EPOCH: 17, valid_loss: 0.018160947324598536\n",
      "FOLD: 7, EPOCH: 18, train_loss: 0.020771707354053374\n",
      "FOLD: 7, EPOCH: 18, valid_loss: 0.018038318218553766\n",
      "FOLD: 7, EPOCH: 19, train_loss: 0.020796830831996856\n",
      "FOLD: 7, EPOCH: 19, valid_loss: 0.017812056905206514\n",
      "FOLD: 7, EPOCH: 20, train_loss: 0.020819294861247464\n",
      "FOLD: 7, EPOCH: 20, valid_loss: 0.018056341611287174\n",
      "FOLD: 7, EPOCH: 21, train_loss: 0.02082900090082999\n",
      "FOLD: 7, EPOCH: 21, valid_loss: 0.01795620657503605\n",
      "FOLD: 7, EPOCH: 22, train_loss: 0.020832803689183728\n",
      "FOLD: 7, EPOCH: 22, valid_loss: 0.018162135801771107\n",
      "FOLD: 7, EPOCH: 23, train_loss: 0.02080589939028986\n",
      "FOLD: 7, EPOCH: 23, valid_loss: 0.017999738016549277\n",
      "FOLD: 7, EPOCH: 24, train_loss: 0.020815259506625515\n",
      "FOLD: 7, EPOCH: 24, valid_loss: 0.018306442919899437\n",
      "FOLD: 7, EPOCH: 25, train_loss: 0.02080949200016837\n",
      "FOLD: 7, EPOCH: 25, valid_loss: 0.017875619561356658\n",
      "FOLD: 7, EPOCH: 26, train_loss: 0.02075172727627139\n",
      "FOLD: 7, EPOCH: 26, valid_loss: 0.018344005569815636\n",
      "FOLD: 7, EPOCH: 27, train_loss: 0.020721420225116513\n",
      "FOLD: 7, EPOCH: 27, valid_loss: 0.01799383551320609\n",
      "FOLD: 7, EPOCH: 28, train_loss: 0.02062821704293451\n",
      "FOLD: 7, EPOCH: 28, valid_loss: 0.017886747660882333\n",
      "FOLD: 7, EPOCH: 29, train_loss: 0.020597887339611206\n",
      "FOLD: 7, EPOCH: 29, valid_loss: 0.017873880617758808\n",
      "FOLD: 7, EPOCH: 30, train_loss: 0.0205951860595134\n",
      "FOLD: 7, EPOCH: 30, valid_loss: 0.017760054043987217\n",
      "FOLD: 7, EPOCH: 31, train_loss: 0.0204858876884945\n",
      "FOLD: 7, EPOCH: 31, valid_loss: 0.017865729134748962\n",
      "FOLD: 7, EPOCH: 32, train_loss: 0.020396574598646935\n",
      "FOLD: 7, EPOCH: 32, valid_loss: 0.017857569434186992\n",
      "FOLD: 7, EPOCH: 33, train_loss: 0.020307253938048116\n",
      "FOLD: 7, EPOCH: 33, valid_loss: 0.017613305984174505\n",
      "FOLD: 7, EPOCH: 34, train_loss: 0.020179274978656923\n",
      "FOLD: 7, EPOCH: 34, valid_loss: 0.017827122746145025\n",
      "FOLD: 7, EPOCH: 35, train_loss: 0.020142137054954806\n",
      "FOLD: 7, EPOCH: 35, valid_loss: 0.01772418147062554\n",
      "FOLD: 7, EPOCH: 36, train_loss: 0.020031287869618785\n",
      "FOLD: 7, EPOCH: 36, valid_loss: 0.01761494785108987\n",
      "FOLD: 7, EPOCH: 37, train_loss: 0.01988988712189659\n",
      "FOLD: 7, EPOCH: 37, valid_loss: 0.017527198309407514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 7, EPOCH: 38, train_loss: 0.019772344695464256\n",
      "FOLD: 7, EPOCH: 38, valid_loss: 0.017376893035629216\n",
      "FOLD: 7, EPOCH: 39, train_loss: 0.01973449729623333\n",
      "FOLD: 7, EPOCH: 39, valid_loss: 0.0174755074960344\n",
      "FOLD: 7, EPOCH: 40, train_loss: 0.019632033426915444\n",
      "FOLD: 7, EPOCH: 40, valid_loss: 0.01741932683131274\n",
      "FOLD: 7, EPOCH: 41, train_loss: 0.019384156552053267\n",
      "FOLD: 7, EPOCH: 41, valid_loss: 0.017415983164135146\n",
      "FOLD: 7, EPOCH: 42, train_loss: 0.01934403576437504\n",
      "FOLD: 7, EPOCH: 42, valid_loss: 0.017108744996435502\n",
      "FOLD: 7, EPOCH: 43, train_loss: 0.019218970534782255\n",
      "FOLD: 7, EPOCH: 43, valid_loss: 0.017220099840094063\n",
      "FOLD: 7, EPOCH: 44, train_loss: 0.01905538796056663\n",
      "FOLD: 7, EPOCH: 44, valid_loss: 0.01717733602751704\n",
      "FOLD: 7, EPOCH: 45, train_loss: 0.018912303940423075\n",
      "FOLD: 7, EPOCH: 45, valid_loss: 0.01714862768045243\n",
      "FOLD: 7, EPOCH: 46, train_loss: 0.018736149262516728\n",
      "FOLD: 7, EPOCH: 46, valid_loss: 0.017164762186653474\n",
      "FOLD: 7, EPOCH: 47, train_loss: 0.018576940245205356\n",
      "FOLD: 7, EPOCH: 47, valid_loss: 0.01709556727505782\n",
      "FOLD: 7, EPOCH: 48, train_loss: 0.018429451435804368\n",
      "FOLD: 7, EPOCH: 48, valid_loss: 0.017179027692798304\n",
      "FOLD: 7, EPOCH: 49, train_loss: 0.018233147215458656\n",
      "FOLD: 7, EPOCH: 49, valid_loss: 0.01714491778436829\n",
      "FOLD: 7, EPOCH: 50, train_loss: 0.018066705643169343\n",
      "FOLD: 7, EPOCH: 50, valid_loss: 0.017159997869063828\n",
      "FOLD: 7, EPOCH: 51, train_loss: 0.01791099565283906\n",
      "FOLD: 7, EPOCH: 51, valid_loss: 0.01712220359374495\n",
      "FOLD: 7, EPOCH: 52, train_loss: 0.017734972748064227\n",
      "FOLD: 7, EPOCH: 52, valid_loss: 0.017137089086806074\n",
      "FOLD: 7, EPOCH: 53, train_loss: 0.017623273343328506\n",
      "FOLD: 7, EPOCH: 53, valid_loss: 0.017136666649842962\n",
      "FOLD: 7, EPOCH: 54, train_loss: 0.017462267005635846\n",
      "FOLD: 7, EPOCH: 54, valid_loss: 0.017134004765573668\n",
      "FOLD: 7, EPOCH: 55, train_loss: 0.017349765708129253\n",
      "FOLD: 7, EPOCH: 55, valid_loss: 0.01714120728566366\n",
      "FOLD: 7, EPOCH: 56, train_loss: 0.01724937035431785\n",
      "FOLD: 7, EPOCH: 56, valid_loss: 0.0171052822843194\n",
      "FOLD: 7, EPOCH: 57, train_loss: 0.0171928541434388\n",
      "FOLD: 7, EPOCH: 57, valid_loss: 0.017124265322790426\n",
      "FOLD: 7, EPOCH: 58, train_loss: 0.017137278526300384\n",
      "FOLD: 7, EPOCH: 58, valid_loss: 0.017112477079910392\n",
      "FOLD: 7, EPOCH: 59, train_loss: 0.017124959429906262\n",
      "FOLD: 7, EPOCH: 59, valid_loss: 0.017099555965293858\n",
      "FOLD: 8, EPOCH: 0, train_loss: 0.676092113602546\n",
      "FOLD: 8, EPOCH: 0, valid_loss: 0.3650657418701384\n",
      "FOLD: 8, EPOCH: 1, train_loss: 0.06096352714925043\n",
      "FOLD: 8, EPOCH: 1, valid_loss: 0.019714163823260203\n",
      "FOLD: 8, EPOCH: 2, train_loss: 0.023157789966752454\n",
      "FOLD: 8, EPOCH: 2, valid_loss: 0.020046397319270506\n",
      "FOLD: 8, EPOCH: 3, train_loss: 0.02437910013381512\n",
      "FOLD: 8, EPOCH: 3, valid_loss: 0.01804598094895482\n",
      "FOLD: 8, EPOCH: 4, train_loss: 0.02234454096084641\n",
      "FOLD: 8, EPOCH: 4, valid_loss: 0.14267404770685566\n",
      "FOLD: 8, EPOCH: 5, train_loss: 0.022846678271889687\n",
      "FOLD: 8, EPOCH: 5, valid_loss: 0.01794237115730842\n",
      "FOLD: 8, EPOCH: 6, train_loss: 0.02123312493485789\n",
      "FOLD: 8, EPOCH: 6, valid_loss: 0.018086978130870394\n",
      "FOLD: 8, EPOCH: 7, train_loss: 0.020815974510004442\n",
      "FOLD: 8, EPOCH: 7, valid_loss: 0.018006973072058625\n",
      "FOLD: 8, EPOCH: 8, train_loss: 0.02072401306321544\n",
      "FOLD: 8, EPOCH: 8, valid_loss: 0.017919270011285942\n",
      "FOLD: 8, EPOCH: 9, train_loss: 0.020679518640522036\n",
      "FOLD: 8, EPOCH: 9, valid_loss: 0.017966965523858864\n",
      "FOLD: 8, EPOCH: 10, train_loss: 0.02061952848828608\n",
      "FOLD: 8, EPOCH: 10, valid_loss: 0.017873642966151237\n",
      "FOLD: 8, EPOCH: 11, train_loss: 0.020667031082895495\n",
      "FOLD: 8, EPOCH: 11, valid_loss: 0.017938047130074766\n",
      "FOLD: 8, EPOCH: 12, train_loss: 0.020668257364342288\n",
      "FOLD: 8, EPOCH: 12, valid_loss: 0.018063860686702862\n",
      "FOLD: 8, EPOCH: 13, train_loss: 0.020725551019272495\n",
      "FOLD: 8, EPOCH: 13, valid_loss: 0.01813661079439852\n",
      "FOLD: 8, EPOCH: 14, train_loss: 0.020774957645804653\n",
      "FOLD: 8, EPOCH: 14, valid_loss: 0.01812755549326539\n",
      "FOLD: 8, EPOCH: 15, train_loss: 0.02084231739563327\n",
      "FOLD: 8, EPOCH: 15, valid_loss: 0.018172730433030262\n",
      "FOLD: 8, EPOCH: 16, train_loss: 0.020865440032174512\n",
      "FOLD: 8, EPOCH: 16, valid_loss: 0.018151101759738393\n",
      "FOLD: 8, EPOCH: 17, train_loss: 0.020802997821761714\n",
      "FOLD: 8, EPOCH: 17, valid_loss: 0.01797977752155728\n",
      "FOLD: 8, EPOCH: 18, train_loss: 0.020889897235939578\n",
      "FOLD: 8, EPOCH: 18, valid_loss: 0.018272402075429756\n",
      "FOLD: 8, EPOCH: 19, train_loss: 0.02083291741869142\n",
      "FOLD: 8, EPOCH: 19, valid_loss: 0.018017182178381417\n",
      "FOLD: 8, EPOCH: 20, train_loss: 0.020941769824393334\n",
      "FOLD: 8, EPOCH: 20, valid_loss: 0.017979052228232224\n",
      "FOLD: 8, EPOCH: 21, train_loss: 0.0208404645804436\n",
      "FOLD: 8, EPOCH: 21, valid_loss: 0.017987952567636967\n",
      "FOLD: 8, EPOCH: 22, train_loss: 0.02089889018285659\n",
      "FOLD: 8, EPOCH: 22, valid_loss: 0.018520868590308562\n",
      "FOLD: 8, EPOCH: 23, train_loss: 0.020844763709652808\n",
      "FOLD: 8, EPOCH: 23, valid_loss: 0.017805547039541934\n",
      "FOLD: 8, EPOCH: 24, train_loss: 0.020802594505010114\n",
      "FOLD: 8, EPOCH: 24, valid_loss: 0.017933567468490865\n",
      "FOLD: 8, EPOCH: 25, train_loss: 0.020805921225297834\n",
      "FOLD: 8, EPOCH: 25, valid_loss: 0.017867232103728585\n",
      "FOLD: 8, EPOCH: 26, train_loss: 0.02084173042206995\n",
      "FOLD: 8, EPOCH: 26, valid_loss: 0.017908528602371614\n",
      "FOLD: 8, EPOCH: 27, train_loss: 0.020712958732920308\n",
      "FOLD: 8, EPOCH: 27, valid_loss: 0.017798222187492583\n",
      "FOLD: 8, EPOCH: 28, train_loss: 0.020660100576858367\n",
      "FOLD: 8, EPOCH: 28, valid_loss: 0.01787933350230257\n",
      "FOLD: 8, EPOCH: 29, train_loss: 0.020675950569491234\n",
      "FOLD: 8, EPOCH: 29, valid_loss: 0.017779481131583452\n",
      "FOLD: 8, EPOCH: 30, train_loss: 0.02059756685649195\n",
      "FOLD: 8, EPOCH: 30, valid_loss: 0.017776284211625654\n",
      "FOLD: 8, EPOCH: 31, train_loss: 0.020496737067737886\n",
      "FOLD: 8, EPOCH: 31, valid_loss: 0.017804437420434423\n",
      "FOLD: 8, EPOCH: 32, train_loss: 0.020410725955040225\n",
      "FOLD: 8, EPOCH: 32, valid_loss: 0.017462590140187077\n",
      "FOLD: 8, EPOCH: 33, train_loss: 0.02033613369830193\n",
      "FOLD: 8, EPOCH: 33, valid_loss: 0.017712894051025312\n",
      "FOLD: 8, EPOCH: 34, train_loss: 0.02021061577383549\n",
      "FOLD: 8, EPOCH: 34, valid_loss: 0.017559536111851532\n",
      "FOLD: 8, EPOCH: 35, train_loss: 0.020153010924977642\n",
      "FOLD: 8, EPOCH: 35, valid_loss: 0.0172464140276942\n",
      "FOLD: 8, EPOCH: 36, train_loss: 0.019993295280202744\n",
      "FOLD: 8, EPOCH: 36, valid_loss: 0.01758232479915023\n",
      "FOLD: 8, EPOCH: 37, train_loss: 0.019939416160266246\n",
      "FOLD: 8, EPOCH: 37, valid_loss: 0.017459658491942618\n",
      "FOLD: 8, EPOCH: 38, train_loss: 0.019809423819664985\n",
      "FOLD: 8, EPOCH: 38, valid_loss: 0.01724642613488767\n",
      "FOLD: 8, EPOCH: 39, train_loss: 0.019730882719159126\n",
      "FOLD: 8, EPOCH: 39, valid_loss: 0.017226588032725785\n",
      "FOLD: 8, EPOCH: 40, train_loss: 0.019632110888919523\n",
      "FOLD: 8, EPOCH: 40, valid_loss: 0.017169029658867255\n",
      "FOLD: 8, EPOCH: 41, train_loss: 0.019501435708615088\n",
      "FOLD: 8, EPOCH: 41, valid_loss: 0.01731569314789441\n",
      "FOLD: 8, EPOCH: 42, train_loss: 0.019352123838278557\n",
      "FOLD: 8, EPOCH: 42, valid_loss: 0.017422249902867608\n",
      "FOLD: 8, EPOCH: 43, train_loss: 0.0192113560414122\n",
      "FOLD: 8, EPOCH: 43, valid_loss: 0.01713944614554445\n",
      "FOLD: 8, EPOCH: 44, train_loss: 0.019152454743462225\n",
      "FOLD: 8, EPOCH: 44, valid_loss: 0.01699590025883582\n",
      "FOLD: 8, EPOCH: 45, train_loss: 0.01897455566833096\n",
      "FOLD: 8, EPOCH: 45, valid_loss: 0.017102168096850317\n",
      "FOLD: 8, EPOCH: 46, train_loss: 0.01874834750328333\n",
      "FOLD: 8, EPOCH: 46, valid_loss: 0.017080803143067494\n",
      "FOLD: 8, EPOCH: 47, train_loss: 0.018634228985155783\n",
      "FOLD: 8, EPOCH: 47, valid_loss: 0.017024484049114916\n",
      "FOLD: 8, EPOCH: 48, train_loss: 0.01847812621103179\n",
      "FOLD: 8, EPOCH: 48, valid_loss: 0.01697031905253728\n",
      "FOLD: 8, EPOCH: 49, train_loss: 0.018303593308214218\n",
      "FOLD: 8, EPOCH: 49, valid_loss: 0.01709837057731218\n",
      "FOLD: 8, EPOCH: 50, train_loss: 0.018117855357066278\n",
      "FOLD: 8, EPOCH: 50, valid_loss: 0.017085073722733393\n",
      "FOLD: 8, EPOCH: 51, train_loss: 0.017958464557605407\n",
      "FOLD: 8, EPOCH: 51, valid_loss: 0.017109295301553275\n",
      "FOLD: 8, EPOCH: 52, train_loss: 0.017780098108755003\n",
      "FOLD: 8, EPOCH: 52, valid_loss: 0.01701019202462501\n",
      "FOLD: 8, EPOCH: 53, train_loss: 0.01768511598629336\n",
      "FOLD: 8, EPOCH: 53, valid_loss: 0.017054450646456745\n",
      "FOLD: 8, EPOCH: 54, train_loss: 0.017528381330832357\n",
      "FOLD: 8, EPOCH: 54, valid_loss: 0.017066455239223108\n",
      "FOLD: 8, EPOCH: 55, train_loss: 0.017403879984011574\n",
      "FOLD: 8, EPOCH: 55, valid_loss: 0.017059833483977452\n",
      "FOLD: 8, EPOCH: 56, train_loss: 0.01734810838055226\n",
      "FOLD: 8, EPOCH: 56, valid_loss: 0.017053860964046583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 8, EPOCH: 57, train_loss: 0.017250533576213544\n",
      "FOLD: 8, EPOCH: 57, valid_loss: 0.017039755100591317\n",
      "FOLD: 8, EPOCH: 58, train_loss: 0.01719000329293551\n",
      "FOLD: 8, EPOCH: 58, valid_loss: 0.017043010900831886\n",
      "FOLD: 8, EPOCH: 59, train_loss: 0.017162880631944825\n",
      "FOLD: 8, EPOCH: 59, valid_loss: 0.017057817688004837\n",
      "FOLD: 9, EPOCH: 0, train_loss: 0.6753692334698093\n",
      "FOLD: 9, EPOCH: 0, valid_loss: 0.3618292262156804\n",
      "FOLD: 9, EPOCH: 1, train_loss: 0.061336985639026086\n",
      "FOLD: 9, EPOCH: 1, valid_loss: 0.02044227295037773\n",
      "FOLD: 9, EPOCH: 2, train_loss: 0.023399666396360243\n",
      "FOLD: 9, EPOCH: 2, valid_loss: 0.020969405873782106\n",
      "FOLD: 9, EPOCH: 3, train_loss: 0.023787214510863828\n",
      "FOLD: 9, EPOCH: 3, valid_loss: 0.06778700546258026\n",
      "FOLD: 9, EPOCH: 4, train_loss: 0.024321437230513943\n",
      "FOLD: 9, EPOCH: 4, valid_loss: 0.025722222195731267\n",
      "FOLD: 9, EPOCH: 5, train_loss: 0.0218041694693027\n",
      "FOLD: 9, EPOCH: 5, valid_loss: 0.018032710895770125\n",
      "FOLD: 9, EPOCH: 6, train_loss: 0.021044766193916722\n",
      "FOLD: 9, EPOCH: 6, valid_loss: 0.02046419649074475\n",
      "FOLD: 9, EPOCH: 7, train_loss: 0.020875665064780943\n",
      "FOLD: 9, EPOCH: 7, valid_loss: 0.018648804993265204\n",
      "FOLD: 9, EPOCH: 8, train_loss: 0.020690736198617565\n",
      "FOLD: 9, EPOCH: 8, valid_loss: 0.017634384851488803\n",
      "FOLD: 9, EPOCH: 9, train_loss: 0.020586539624679472\n",
      "FOLD: 9, EPOCH: 9, valid_loss: 0.02197369146678183\n",
      "FOLD: 9, EPOCH: 10, train_loss: 0.02094901275009878\n",
      "FOLD: 9, EPOCH: 10, valid_loss: 0.01829467962185542\n",
      "FOLD: 9, EPOCH: 11, train_loss: 0.020701318426478293\n",
      "FOLD: 9, EPOCH: 11, valid_loss: 0.018434999096724723\n",
      "FOLD: 9, EPOCH: 12, train_loss: 0.02075260223880891\n",
      "FOLD: 9, EPOCH: 12, valid_loss: 0.02050729561597109\n",
      "FOLD: 9, EPOCH: 13, train_loss: 0.020917868301753077\n",
      "FOLD: 9, EPOCH: 13, valid_loss: 0.01939062111907535\n",
      "FOLD: 9, EPOCH: 14, train_loss: 0.020962070072850874\n",
      "FOLD: 9, EPOCH: 14, valid_loss: 0.01968697179108858\n",
      "FOLD: 9, EPOCH: 15, train_loss: 0.020944775556845048\n",
      "FOLD: 9, EPOCH: 15, valid_loss: 0.0249183586695128\n",
      "FOLD: 9, EPOCH: 16, train_loss: 0.021134047823086862\n",
      "FOLD: 9, EPOCH: 16, valid_loss: 0.02507506176415417\n",
      "FOLD: 9, EPOCH: 17, train_loss: 0.021221024290688575\n",
      "FOLD: 9, EPOCH: 17, valid_loss: 0.019960000697109435\n",
      "FOLD: 9, EPOCH: 18, train_loss: 0.021057980916192456\n",
      "FOLD: 9, EPOCH: 18, valid_loss: 0.019863285538223054\n",
      "FOLD: 9, EPOCH: 19, train_loss: 0.021048870838938222\n",
      "FOLD: 9, EPOCH: 19, valid_loss: 0.01827561917404334\n",
      "FOLD: 9, EPOCH: 20, train_loss: 0.02101912274956703\n",
      "FOLD: 9, EPOCH: 20, valid_loss: 0.01762554422020912\n",
      "FOLD: 9, EPOCH: 21, train_loss: 0.020972464930626655\n",
      "FOLD: 9, EPOCH: 21, valid_loss: 0.018349333459304437\n",
      "FOLD: 9, EPOCH: 22, train_loss: 0.020977760647093096\n",
      "FOLD: 9, EPOCH: 22, valid_loss: 0.018939785452352628\n",
      "FOLD: 9, EPOCH: 23, train_loss: 0.020937120073264644\n",
      "FOLD: 9, EPOCH: 23, valid_loss: 0.019611956655151315\n",
      "FOLD: 9, EPOCH: 24, train_loss: 0.02105177842801617\n",
      "FOLD: 9, EPOCH: 24, valid_loss: 0.018379120466609795\n",
      "FOLD: 9, EPOCH: 25, train_loss: 0.021126834687686735\n",
      "FOLD: 9, EPOCH: 25, valid_loss: 0.01802296212149991\n",
      "FOLD: 9, EPOCH: 26, train_loss: 0.020885440563001942\n",
      "FOLD: 9, EPOCH: 26, valid_loss: 0.017576966538197465\n",
      "FOLD: 9, EPOCH: 27, train_loss: 0.021056227434066033\n",
      "FOLD: 9, EPOCH: 27, valid_loss: 0.018075995250708528\n",
      "FOLD: 9, EPOCH: 28, train_loss: 0.021140511093601103\n",
      "FOLD: 9, EPOCH: 28, valid_loss: 0.017532366327941418\n",
      "FOLD: 9, EPOCH: 29, train_loss: 0.020884437234170976\n",
      "FOLD: 9, EPOCH: 29, valid_loss: 0.017673587012622092\n",
      "FOLD: 9, EPOCH: 30, train_loss: 0.020835348368892746\n",
      "FOLD: 9, EPOCH: 30, valid_loss: 0.017345477930373616\n",
      "FOLD: 9, EPOCH: 31, train_loss: 0.02058888212327034\n",
      "FOLD: 9, EPOCH: 31, valid_loss: 0.017451217501527734\n",
      "FOLD: 9, EPOCH: 32, train_loss: 0.020686921092771714\n",
      "FOLD: 9, EPOCH: 32, valid_loss: 0.017560314904484484\n",
      "FOLD: 9, EPOCH: 33, train_loss: 0.02057277915939208\n",
      "FOLD: 9, EPOCH: 33, valid_loss: 0.017573515470657084\n",
      "FOLD: 9, EPOCH: 34, train_loss: 0.020566091830691982\n",
      "FOLD: 9, EPOCH: 34, valid_loss: 0.017376860707170434\n",
      "FOLD: 9, EPOCH: 35, train_loss: 0.020281488463402757\n",
      "FOLD: 9, EPOCH: 35, valid_loss: 0.017002003629588418\n",
      "FOLD: 9, EPOCH: 36, train_loss: 0.020139653824510113\n",
      "FOLD: 9, EPOCH: 36, valid_loss: 0.017073687579896715\n",
      "FOLD: 9, EPOCH: 37, train_loss: 0.020086487142309067\n",
      "FOLD: 9, EPOCH: 37, valid_loss: 0.016950335457093187\n",
      "FOLD: 9, EPOCH: 38, train_loss: 0.019949476661220673\n",
      "FOLD: 9, EPOCH: 38, valid_loss: 0.016921056900173426\n",
      "FOLD: 9, EPOCH: 39, train_loss: 0.019921375895219466\n",
      "FOLD: 9, EPOCH: 39, valid_loss: 0.01693343122800191\n",
      "FOLD: 9, EPOCH: 40, train_loss: 0.01971843905987278\n",
      "FOLD: 9, EPOCH: 40, valid_loss: 0.01689182511634297\n",
      "FOLD: 9, EPOCH: 41, train_loss: 0.01973078306163511\n",
      "FOLD: 9, EPOCH: 41, valid_loss: 0.01678187343188458\n",
      "FOLD: 9, EPOCH: 42, train_loss: 0.019568833576575403\n",
      "FOLD: 9, EPOCH: 42, valid_loss: 0.0167850319089161\n",
      "FOLD: 9, EPOCH: 43, train_loss: 0.019510384985516147\n",
      "FOLD: 9, EPOCH: 43, valid_loss: 0.01673653359628386\n",
      "FOLD: 9, EPOCH: 44, train_loss: 0.01940778240321144\n",
      "FOLD: 9, EPOCH: 44, valid_loss: 0.016792603251006868\n",
      "FOLD: 9, EPOCH: 45, train_loss: 0.019205541223768264\n",
      "FOLD: 9, EPOCH: 45, valid_loss: 0.016612332728173997\n",
      "FOLD: 9, EPOCH: 46, train_loss: 0.019206631568170363\n",
      "FOLD: 9, EPOCH: 46, valid_loss: 0.0167935392819345\n",
      "FOLD: 9, EPOCH: 47, train_loss: 0.01886932487569509\n",
      "FOLD: 9, EPOCH: 47, valid_loss: 0.016658150487475924\n",
      "FOLD: 9, EPOCH: 48, train_loss: 0.01871398910880089\n",
      "FOLD: 9, EPOCH: 48, valid_loss: 0.016610826313909557\n",
      "FOLD: 9, EPOCH: 49, train_loss: 0.01867305104049944\n",
      "FOLD: 9, EPOCH: 49, valid_loss: 0.016717410025497276\n",
      "FOLD: 9, EPOCH: 50, train_loss: 0.018440894662372528\n",
      "FOLD: 9, EPOCH: 50, valid_loss: 0.01659436606698566\n",
      "FOLD: 9, EPOCH: 51, train_loss: 0.018489295496575294\n",
      "FOLD: 9, EPOCH: 51, valid_loss: 0.01660126152758797\n",
      "FOLD: 9, EPOCH: 52, train_loss: 0.01817750569072462\n",
      "FOLD: 9, EPOCH: 52, valid_loss: 0.016626814897689555\n",
      "FOLD: 9, EPOCH: 53, train_loss: 0.01805860978821593\n",
      "FOLD: 9, EPOCH: 53, valid_loss: 0.016634679399430752\n",
      "FOLD: 9, EPOCH: 54, train_loss: 0.017925475748075594\n",
      "FOLD: 9, EPOCH: 54, valid_loss: 0.016608754949023325\n",
      "FOLD: 9, EPOCH: 55, train_loss: 0.01779754741057273\n",
      "FOLD: 9, EPOCH: 55, valid_loss: 0.016605480522331264\n",
      "FOLD: 9, EPOCH: 56, train_loss: 0.017691396933890158\n",
      "FOLD: 9, EPOCH: 56, valid_loss: 0.016586842636267345\n",
      "FOLD: 9, EPOCH: 57, train_loss: 0.017528929891845874\n",
      "FOLD: 9, EPOCH: 57, valid_loss: 0.016611964131395023\n",
      "FOLD: 9, EPOCH: 58, train_loss: 0.017600574620789098\n",
      "FOLD: 9, EPOCH: 58, valid_loss: 0.01663045362672872\n",
      "FOLD: 9, EPOCH: 59, train_loss: 0.017517974924656652\n",
      "FOLD: 9, EPOCH: 59, valid_loss: 0.01659444600550665\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.67547737321546\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.36050572640755596\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.060800218522067996\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.020217474769143498\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023195576884092822\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.020548524115892017\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.022466018423438074\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.019542265245143103\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.024820453998061917\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01990388793980374\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.022419640950618252\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018714386969804764\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.021251004958345043\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01959813857341514\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020958047264045286\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01821705063476282\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020766402901180328\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01841319352388382\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020695040483147867\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01814140982049353\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.02070471328352728\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.018375287051586545\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.020692113017843617\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01821905089651837\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.020638126194957765\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018264284028726464\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.02063637845698864\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.018275663256645203\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.020724444547968526\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.018382470506955597\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.020740372867834183\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.018648354994023546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 16, train_loss: 0.020747293243485114\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.018565621555728072\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.020708074480775863\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01810995993368766\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.020715538099888832\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.018497577265781516\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.02076985987444078\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01823751431177644\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.02073370315615208\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018381263841600978\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.02077154389792873\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.018733874620760187\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.020758757800344498\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.018348563133793717\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.020808537328435527\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.018738035003052038\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.020704988822821648\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.018621942904942176\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.02075063977991381\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.018598095787798658\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.020714522249275637\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.018421501359518838\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.020647576042721348\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.0181785589631866\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.02065340862158806\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.018416942480732414\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.02055539614971607\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.01796447956825004\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.02049640095041644\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.01776316433268435\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.020449207783226044\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.01782075600589023\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.020323349607567633\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.018028619534829083\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.02022560735143\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.01777627253357102\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.020194737517064618\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.01763991649974795\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.020014997836082214\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.01782422008759835\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.01992676838511421\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.017751515897757867\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.01989176766045632\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.017874853575930875\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.01977965608239174\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.017792859059922835\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.019669236699419636\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.01773144567714018\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.019526107639314668\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.017594110001535976\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.0193829111154041\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.017459682572413895\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.019282190862201874\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.01757430745398297\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.019163129274402894\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.017433923285673645\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.018945816147231287\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.017388483892907116\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.018829503355007018\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.017292677589199123\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.018660536035895348\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.01739940419793129\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.018533746561696453\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.017378728398505378\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.018346829940715143\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.017279964159516728\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.01815092472900306\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.017293036038822988\n",
      "FOLD: 0, EPOCH: 50, train_loss: 0.017999087340168415\n",
      "FOLD: 0, EPOCH: 50, valid_loss: 0.017312813111964392\n",
      "FOLD: 0, EPOCH: 51, train_loss: 0.017838982042045363\n",
      "FOLD: 0, EPOCH: 51, valid_loss: 0.017277655356070575\n",
      "FOLD: 0, EPOCH: 52, train_loss: 0.01765403718116783\n",
      "FOLD: 0, EPOCH: 52, valid_loss: 0.017350183252026054\n",
      "FOLD: 0, EPOCH: 53, train_loss: 0.017496257425556258\n",
      "FOLD: 0, EPOCH: 53, valid_loss: 0.017392370082876262\n",
      "FOLD: 0, EPOCH: 54, train_loss: 0.01737533317458245\n",
      "FOLD: 0, EPOCH: 54, valid_loss: 0.01735644436934415\n",
      "FOLD: 0, EPOCH: 55, train_loss: 0.01719817396013006\n",
      "FOLD: 0, EPOCH: 55, valid_loss: 0.017329784822376335\n",
      "FOLD: 0, EPOCH: 56, train_loss: 0.017078078135607706\n",
      "FOLD: 0, EPOCH: 56, valid_loss: 0.01732633975060547\n",
      "FOLD: 0, EPOCH: 57, train_loss: 0.017008445694321587\n",
      "FOLD: 0, EPOCH: 57, valid_loss: 0.017342324313872\n",
      "FOLD: 0, EPOCH: 58, train_loss: 0.016964313063410022\n",
      "FOLD: 0, EPOCH: 58, valid_loss: 0.017333001446198013\n",
      "FOLD: 0, EPOCH: 59, train_loss: 0.01693098119670345\n",
      "FOLD: 0, EPOCH: 59, valid_loss: 0.0173621864112861\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6755922040631694\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.36527283986409503\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.060895788897910426\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020648203272786405\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.022916551210707233\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.019868443047420845\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.022008865855393873\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.0248265805033346\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.021580947935581206\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.018177272079305515\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02194314172431346\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.0182248717173934\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020745765730257958\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.019744102480924793\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.020441506394455508\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.018126608441687293\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.02026623866010097\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.018359556690686278\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020275482775703554\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.018287508231070306\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.0203581138363769\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01863330587123831\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.02047110999063138\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018392910456491843\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.020452094955309745\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01828054545654191\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.0205233896691953\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.018824888600243464\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.020657753800192188\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.018205254286941554\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.020618333331038876\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01860073860734701\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.02076089564831026\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.018454726009319227\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.020715387670263166\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.018368403944704268\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.020761424339106008\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.018933876262356836\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.02069584605914931\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.018690729772465095\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.020779938767513922\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01891997575552927\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.02079763840283117\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.018463940204431612\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.02081748120967419\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01826131483539939\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.020729752005107942\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018306957609537575\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.020790220496635283\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.018738861713144515\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.020710071224358775\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.018530841865059402\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.020692318545714503\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.018629288611312706\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.020643420024744927\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.01845897428898348\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.02069888397330238\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.018577530048787594\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.020538693858731177\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.018613559607830312\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.02057741197847551\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.018298054941826396\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.0204164556798435\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018376458798431687\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.02038119365611384\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018207590975281265\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.02031201395776964\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.018298278666204877\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.020210804165371004\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.018084115555716887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 35, train_loss: 0.020109753983636056\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.018083864719503455\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.02003810185818903\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.01791933836001489\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.019913657586420736\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.0182976757383181\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.019780159591426774\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.017912038653675053\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.01961093842983246\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.01798403076827526\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.0195638072646914\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.01812181088866459\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.019401713773127525\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.017600299428320594\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.019227920965321603\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.01781394813830654\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.01916265770071937\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.017750475866099198\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.019032513470418993\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.017756168213155534\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.018845681557732245\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.017787390595508948\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.01869889635953211\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.01779717781270544\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.01857318233458265\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.017670075357374217\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.018385902041148754\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.01764911511499021\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.018224136134789837\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.017579731272740498\n",
      "FOLD: 1, EPOCH: 50, train_loss: 0.018054838304317766\n",
      "FOLD: 1, EPOCH: 50, valid_loss: 0.01753747473574347\n",
      "FOLD: 1, EPOCH: 51, train_loss: 0.017881464249184055\n",
      "FOLD: 1, EPOCH: 51, valid_loss: 0.01760763457665841\n",
      "FOLD: 1, EPOCH: 52, train_loss: 0.017723087347563237\n",
      "FOLD: 1, EPOCH: 52, valid_loss: 0.017642416008230712\n",
      "FOLD: 1, EPOCH: 53, train_loss: 0.01757643521432915\n",
      "FOLD: 1, EPOCH: 53, valid_loss: 0.017581981606781483\n",
      "FOLD: 1, EPOCH: 54, train_loss: 0.01741847726366212\n",
      "FOLD: 1, EPOCH: 54, valid_loss: 0.01758679199135966\n",
      "FOLD: 1, EPOCH: 55, train_loss: 0.017282190149830234\n",
      "FOLD: 1, EPOCH: 55, valid_loss: 0.017595822198523417\n",
      "FOLD: 1, EPOCH: 56, train_loss: 0.01720932693851571\n",
      "FOLD: 1, EPOCH: 56, valid_loss: 0.017572481806079548\n",
      "FOLD: 1, EPOCH: 57, train_loss: 0.017159689728531144\n",
      "FOLD: 1, EPOCH: 57, valid_loss: 0.017558536492288113\n",
      "FOLD: 1, EPOCH: 58, train_loss: 0.017116525312585215\n",
      "FOLD: 1, EPOCH: 58, valid_loss: 0.017574655099047556\n",
      "FOLD: 1, EPOCH: 59, train_loss: 0.017056261405589117\n",
      "FOLD: 1, EPOCH: 59, valid_loss: 0.01757429912686348\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6759046200783022\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.3743830853038364\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.061174663420646425\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020713239080376096\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02318680580825575\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01966963170303239\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.02387556764146974\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.03519065077934\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.025941295969870784\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.019964862821830645\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02193307361054805\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.018840875166157883\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.021233805941958582\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018897812399599288\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020784101394876357\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018240317805773683\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020660740786021755\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.018536072948740587\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.020534972822473897\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.018286808756076627\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.020617990688450875\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.018296394341935713\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.02052937027427458\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018461612053215504\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.020584887963148855\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018556505752106506\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.02062144881534961\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.018665414665722184\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.020599884666021792\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01848176959902048\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.020616284649698963\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.018633658376832802\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.020806088550917565\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.018486814469926886\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.020738801720642273\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.017965193165259227\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.020719973178159806\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.018523299290488165\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.02078834198895962\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01816455792221758\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.020889317983340833\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.018538807725740805\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.020789848796782955\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.018891466367575858\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.020794683202139792\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018258708994835615\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.020813693574840024\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.018174502377708752\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.0207270665755195\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018221655964023538\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.020723501112191907\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.018225766925348177\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.020753048829013302\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.018483998409161966\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.020750186580323404\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01835487291423811\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.020659454347145174\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.018460731022059917\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.020635690744365415\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.01828207763739758\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.020579723869600604\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.018236065800819132\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.020489617929823938\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.018484492786228657\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.02042024252155135\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.01792427980237537\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.020326850599338933\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017682785375250712\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.020199606507535904\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.01779321901914146\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.020125331008626568\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.01767732772148318\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.019998615259124386\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.01783192851063278\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.019930438108501897\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.017510044440213177\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.01983303919194206\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.0177013176596827\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.01974444898866838\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.01763924288873871\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.019565920784108102\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.017523847934272554\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.019490083967966417\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.01759789666781823\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.019288071256972128\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.01751116823611988\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.019170502921746622\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.01736364249760906\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.018981379703167947\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017209283127966855\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.018853550356241963\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017218735793398485\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.018687339836070613\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.017235602096964914\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.01854267442418683\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.017215318615651794\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.0183777000454645\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.0171983086814483\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.018224091431306256\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.017166590214603476\n",
      "FOLD: 2, EPOCH: 50, train_loss: 0.01803976141156689\n",
      "FOLD: 2, EPOCH: 50, valid_loss: 0.01723846493081914\n",
      "FOLD: 2, EPOCH: 51, train_loss: 0.0178356520290817\n",
      "FOLD: 2, EPOCH: 51, valid_loss: 0.017232164326641295\n",
      "FOLD: 2, EPOCH: 52, train_loss: 0.01763518083720438\n",
      "FOLD: 2, EPOCH: 52, valid_loss: 0.017179414940377075\n",
      "FOLD: 2, EPOCH: 53, train_loss: 0.017501230291541544\n",
      "FOLD: 2, EPOCH: 53, valid_loss: 0.01714245943973462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 54, train_loss: 0.017354236158632463\n",
      "FOLD: 2, EPOCH: 54, valid_loss: 0.0171479438431561\n",
      "FOLD: 2, EPOCH: 55, train_loss: 0.01721027163007567\n",
      "FOLD: 2, EPOCH: 55, valid_loss: 0.017221225943002436\n",
      "FOLD: 2, EPOCH: 56, train_loss: 0.017088111225635774\n",
      "FOLD: 2, EPOCH: 56, valid_loss: 0.017200509707132976\n",
      "FOLD: 2, EPOCH: 57, train_loss: 0.01700128734472298\n",
      "FOLD: 2, EPOCH: 57, valid_loss: 0.017213735832936235\n",
      "FOLD: 2, EPOCH: 58, train_loss: 0.016949572083690474\n",
      "FOLD: 2, EPOCH: 58, valid_loss: 0.01722630185799466\n",
      "FOLD: 2, EPOCH: 59, train_loss: 0.016963488224052612\n",
      "FOLD: 2, EPOCH: 59, valid_loss: 0.01720678640736474\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6755921750299392\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.36938707364930046\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.06152806808390925\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020403819158673286\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.023169799209121735\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.019518899110456307\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.02243336723937142\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.022407911407450836\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.02234319289845805\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017697757575660944\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.02605754909736495\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.018737647785908647\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.021503448041696703\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.018165787164535787\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.021110728947866347\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.018084997000793617\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.020933716587962642\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.018012709087795682\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020940461862952477\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01792287231526441\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.020776724406788426\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017906142812636163\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.020819815344387486\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017974059252689283\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.020819451383525325\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.018118602844576042\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.021097820600675\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01813901158877545\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.02082683245741552\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017898828877756994\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.02083429569198239\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01763829283623232\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.020865299300320685\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.018061183393001556\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.02093279248764438\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017839483295877773\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.020912228957299262\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.018205013695276447\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.020892748404895106\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01838483940809965\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020871376342350437\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.018170143477618694\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.02090022829511473\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01804622169584036\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.020883298196619555\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01801481982693076\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020871854897949002\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.018305036704987288\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020836444463460675\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017615671838737197\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.020852827749425366\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.018029402682764664\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.020822685356101683\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.017737483657482598\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.02076668075976833\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.017853081692010164\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.020653370863968325\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01757446112525132\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.020672030458527228\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.01765039407958587\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.02054058879373535\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.01742770957450072\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.02055602694951719\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.01763623621728685\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.020439129274698997\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.01739407077224718\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.020333557311565647\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.01746291506828533\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.02022063245456065\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.01718297279957268\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.020122365401156486\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.017275227492468223\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.020030895428311442\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.017302163514412112\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.01995861607213174\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017275936694608793\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.01985519199121383\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.017190311207539506\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.01968259913546424\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.01717191215397583\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.019612926172633324\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.01699314375097553\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.019498908111164646\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.01703268118823568\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.01939125194424583\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.017023052502837446\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.019240829733110244\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.01692414852894015\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.0190822149777124\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.01693192258891132\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.018965704787162044\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.0167556701021062\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.0188221660112181\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.016888376118408308\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.018678277911197756\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.01677496037963364\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.01844259669944163\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.016840162376562755\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.01831276932911527\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.016707381854454677\n",
      "FOLD: 3, EPOCH: 50, train_loss: 0.018138905722768075\n",
      "FOLD: 3, EPOCH: 50, valid_loss: 0.016753379307273362\n",
      "FOLD: 3, EPOCH: 51, train_loss: 0.017973112525238144\n",
      "FOLD: 3, EPOCH: 51, valid_loss: 0.016796216627375946\n",
      "FOLD: 3, EPOCH: 52, train_loss: 0.017797876882456962\n",
      "FOLD: 3, EPOCH: 52, valid_loss: 0.01680895375708739\n",
      "FOLD: 3, EPOCH: 53, train_loss: 0.017638991370556818\n",
      "FOLD: 3, EPOCH: 53, valid_loss: 0.01677070480460922\n",
      "FOLD: 3, EPOCH: 54, train_loss: 0.017488948418007744\n",
      "FOLD: 3, EPOCH: 54, valid_loss: 0.016798328039132886\n",
      "FOLD: 3, EPOCH: 55, train_loss: 0.017378224306289228\n",
      "FOLD: 3, EPOCH: 55, valid_loss: 0.0167598578458031\n",
      "FOLD: 3, EPOCH: 56, train_loss: 0.01727924316280311\n",
      "FOLD: 3, EPOCH: 56, valid_loss: 0.016735465886692207\n",
      "FOLD: 3, EPOCH: 57, train_loss: 0.017203152978852873\n",
      "FOLD: 3, EPOCH: 57, valid_loss: 0.016745078636126384\n",
      "FOLD: 3, EPOCH: 58, train_loss: 0.01719162541651918\n",
      "FOLD: 3, EPOCH: 58, valid_loss: 0.01675546427981721\n",
      "FOLD: 3, EPOCH: 59, train_loss: 0.01712164845798285\n",
      "FOLD: 3, EPOCH: 59, valid_loss: 0.016763144069247775\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6760832032849712\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.36311858395735425\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.06136050548764967\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.01997957295841641\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023328609211790946\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.019425524191723928\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.022457278700124834\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01819066930976179\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.022518896431692186\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017913257599704795\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.02113766175123953\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017512088641524315\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020516624505962096\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017256660335179832\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.020397396758198738\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017565867967075773\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.020353784255923765\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01744571974914935\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.02043095288738128\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017859493899676535\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020489019612150806\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017971854915635452\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.020581412183180933\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017971419936252966\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.02065126707236613\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01800747365794248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4, EPOCH: 13, train_loss: 0.02071363555808221\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017482542639805213\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.02070662912822539\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.018105001499255497\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.020786917498034817\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017822259933584265\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.020830423048427027\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01771492526556055\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.02080848484991058\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.017845588891456526\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.020839732921411915\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.017989817075431347\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.020952379895794775\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01802859791657991\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.020980721267481003\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01802572426903579\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.020956404987842805\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017684053526156478\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.020968198680108595\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.018216930743720796\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.020980226609014694\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.017558808334999614\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.020911725934955383\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.0175052671175864\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.020862233879104738\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.017870048267973795\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.020874762691317068\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.01779698704679807\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.020785678550601004\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.017647686310940318\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.020903905961782702\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.017410569876018498\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.020777583374611792\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.017597288307216432\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.020684819680548482\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.017542386427521706\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.02069964642005582\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.017447395094980795\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.020509220094930742\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017587933792836137\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.020449747974353453\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.017296097344822355\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.02033882769605806\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.01726285337160031\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.02028929543110632\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.017449024236864515\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.020129213602312148\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.017104535260134272\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.020072443831351497\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.017048730825384457\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.0199648191611613\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017080007690108485\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.019807266720360324\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.017095456934637494\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.019642327401426532\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.016883207847260766\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.019596527228432317\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.016907726414501667\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.01939159958593307\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.016852009524073865\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.019249549892640883\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.016964985109451745\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.019128651105828825\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.01696648562533988\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.018978933124772963\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.016801097637249365\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.018801567907775603\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.01671324877275361\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.0185711631010617\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.016728365586863622\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.018463918446533143\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.016849867947813537\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.01829169746488333\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.01683257571938965\n",
      "FOLD: 4, EPOCH: 50, train_loss: 0.0180913609242247\n",
      "FOLD: 4, EPOCH: 50, valid_loss: 0.016770984718783036\n",
      "FOLD: 4, EPOCH: 51, train_loss: 0.017904147559836988\n",
      "FOLD: 4, EPOCH: 51, valid_loss: 0.01675194300090273\n",
      "FOLD: 4, EPOCH: 52, train_loss: 0.017763744691206562\n",
      "FOLD: 4, EPOCH: 52, valid_loss: 0.016745914860318106\n",
      "FOLD: 4, EPOCH: 53, train_loss: 0.017609644567053166\n",
      "FOLD: 4, EPOCH: 53, valid_loss: 0.016770491635219917\n",
      "FOLD: 4, EPOCH: 54, train_loss: 0.01742217016796912\n",
      "FOLD: 4, EPOCH: 54, valid_loss: 0.016730647585872147\n",
      "FOLD: 4, EPOCH: 55, train_loss: 0.0172963700767967\n",
      "FOLD: 4, EPOCH: 55, valid_loss: 0.016713015269488096\n",
      "FOLD: 4, EPOCH: 56, train_loss: 0.017165597414057102\n",
      "FOLD: 4, EPOCH: 56, valid_loss: 0.016766140444411173\n",
      "FOLD: 4, EPOCH: 57, train_loss: 0.01714611242134725\n",
      "FOLD: 4, EPOCH: 57, valid_loss: 0.01674337654064099\n",
      "FOLD: 4, EPOCH: 58, train_loss: 0.01709928405020506\n",
      "FOLD: 4, EPOCH: 58, valid_loss: 0.016734504761795204\n",
      "FOLD: 4, EPOCH: 59, train_loss: 0.01703753840298422\n",
      "FOLD: 4, EPOCH: 59, valid_loss: 0.016734739765524864\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.6758574076237217\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.36438163452678257\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.0613314472018711\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.01999976930932866\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.023168694600462912\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.019873580067521997\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.02640468079236246\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.020585107203159068\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.02327946979672678\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.01890546352499061\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.022088940369506035\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.019162265066471364\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.02102839299026997\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.018787502725091245\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.02059426580465609\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.018226885340280004\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.02060929170298961\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.01877472787681553\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.020548876086550375\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.01868440272907416\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.020471266536943374\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.01844951520777411\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.020484089454816234\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.01852196216997173\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.020420479425980197\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.018486652419798903\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.02069982813010293\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.01887905007849137\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.020611717233494406\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.019373161097367603\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.020642647531724744\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.019546460049847763\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.020721147702105584\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.018734816254840955\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.02066992164379166\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.018735878376497164\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.020731001707815354\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.019106548900405567\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.020757627198773047\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.018665988515648577\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.02085412893324129\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.019374749209317896\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.020896264273793468\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.01917845683379306\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.020742008726923698\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.01912506700803836\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.020793918436092716\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.018913759849965572\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.020792133000589186\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.0192585252225399\n",
      "FOLD: 5, EPOCH: 25, train_loss: 0.02089174430697195\n",
      "FOLD: 5, EPOCH: 25, valid_loss: 0.019091886468231678\n",
      "FOLD: 5, EPOCH: 26, train_loss: 0.02087503958853983\n",
      "FOLD: 5, EPOCH: 26, valid_loss: 0.018481782430575952\n",
      "FOLD: 5, EPOCH: 27, train_loss: 0.020689366024828727\n",
      "FOLD: 5, EPOCH: 27, valid_loss: 0.01866009200198783\n",
      "FOLD: 5, EPOCH: 28, train_loss: 0.020608791817099816\n",
      "FOLD: 5, EPOCH: 28, valid_loss: 0.018796652348505125\n",
      "FOLD: 5, EPOCH: 29, train_loss: 0.02060829184709057\n",
      "FOLD: 5, EPOCH: 29, valid_loss: 0.01881417290618022\n",
      "FOLD: 5, EPOCH: 30, train_loss: 0.020514889157587483\n",
      "FOLD: 5, EPOCH: 30, valid_loss: 0.01846768960563673\n",
      "FOLD: 5, EPOCH: 31, train_loss: 0.02049398260010827\n",
      "FOLD: 5, EPOCH: 31, valid_loss: 0.018540678545832634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 5, EPOCH: 32, train_loss: 0.020422084761723396\n",
      "FOLD: 5, EPOCH: 32, valid_loss: 0.018631766964164045\n",
      "FOLD: 5, EPOCH: 33, train_loss: 0.020320776657712075\n",
      "FOLD: 5, EPOCH: 33, valid_loss: 0.018531257286667824\n",
      "FOLD: 5, EPOCH: 34, train_loss: 0.020235067497818702\n",
      "FOLD: 5, EPOCH: 34, valid_loss: 0.01804334546128909\n",
      "FOLD: 5, EPOCH: 35, train_loss: 0.020120913282998146\n",
      "FOLD: 5, EPOCH: 35, valid_loss: 0.018309678468439314\n",
      "FOLD: 5, EPOCH: 36, train_loss: 0.02009158541838969\n",
      "FOLD: 5, EPOCH: 36, valid_loss: 0.018324281916850142\n",
      "FOLD: 5, EPOCH: 37, train_loss: 0.019930849861233463\n",
      "FOLD: 5, EPOCH: 37, valid_loss: 0.018266167129493423\n",
      "FOLD: 5, EPOCH: 38, train_loss: 0.019800408364784333\n",
      "FOLD: 5, EPOCH: 38, valid_loss: 0.01815420849662688\n",
      "FOLD: 5, EPOCH: 39, train_loss: 0.01967234770136495\n",
      "FOLD: 5, EPOCH: 39, valid_loss: 0.017975584603846073\n",
      "FOLD: 5, EPOCH: 40, train_loss: 0.019611008321085283\n",
      "FOLD: 5, EPOCH: 40, valid_loss: 0.018166592655082543\n",
      "FOLD: 5, EPOCH: 41, train_loss: 0.019421471775539458\n",
      "FOLD: 5, EPOCH: 41, valid_loss: 0.017990124825802114\n",
      "FOLD: 5, EPOCH: 42, train_loss: 0.019280342301053386\n",
      "FOLD: 5, EPOCH: 42, valid_loss: 0.01796269054628081\n",
      "FOLD: 5, EPOCH: 43, train_loss: 0.019139612814591776\n",
      "FOLD: 5, EPOCH: 43, valid_loss: 0.017804177581436105\n",
      "FOLD: 5, EPOCH: 44, train_loss: 0.019016902707517148\n",
      "FOLD: 5, EPOCH: 44, valid_loss: 0.017844327311548922\n",
      "FOLD: 5, EPOCH: 45, train_loss: 0.01883366174034534\n",
      "FOLD: 5, EPOCH: 45, valid_loss: 0.017713387755470142\n",
      "FOLD: 5, EPOCH: 46, train_loss: 0.01873067462396237\n",
      "FOLD: 5, EPOCH: 46, valid_loss: 0.01792735678868161\n",
      "FOLD: 5, EPOCH: 47, train_loss: 0.018537141803291537\n",
      "FOLD: 5, EPOCH: 47, valid_loss: 0.017688236561500363\n",
      "FOLD: 5, EPOCH: 48, train_loss: 0.018398463209309886\n",
      "FOLD: 5, EPOCH: 48, valid_loss: 0.017746941548668675\n",
      "FOLD: 5, EPOCH: 49, train_loss: 0.018233815232111563\n",
      "FOLD: 5, EPOCH: 49, valid_loss: 0.01783440003378524\n",
      "FOLD: 5, EPOCH: 50, train_loss: 0.01811007300331708\n",
      "FOLD: 5, EPOCH: 50, valid_loss: 0.017722573079582717\n",
      "FOLD: 5, EPOCH: 51, train_loss: 0.01788030247534475\n",
      "FOLD: 5, EPOCH: 51, valid_loss: 0.01778394470198287\n",
      "FOLD: 5, EPOCH: 52, train_loss: 0.01767515362270417\n",
      "FOLD: 5, EPOCH: 52, valid_loss: 0.01779625823514329\n",
      "FOLD: 5, EPOCH: 53, train_loss: 0.017573719688000217\n",
      "FOLD: 5, EPOCH: 53, valid_loss: 0.01775171271421843\n",
      "FOLD: 5, EPOCH: 54, train_loss: 0.01740528668967947\n",
      "FOLD: 5, EPOCH: 54, valid_loss: 0.01777140547831853\n",
      "FOLD: 5, EPOCH: 55, train_loss: 0.01725172199789555\n",
      "FOLD: 5, EPOCH: 55, valid_loss: 0.01778231840580702\n",
      "FOLD: 5, EPOCH: 56, train_loss: 0.017149206112709738\n",
      "FOLD: 5, EPOCH: 56, valid_loss: 0.017783211181975074\n",
      "FOLD: 5, EPOCH: 57, train_loss: 0.017151997274448796\n",
      "FOLD: 5, EPOCH: 57, valid_loss: 0.01779939327389002\n",
      "FOLD: 5, EPOCH: 58, train_loss: 0.017072501904781788\n",
      "FOLD: 5, EPOCH: 58, valid_loss: 0.017796514711032312\n",
      "FOLD: 5, EPOCH: 59, train_loss: 0.017069236141058708\n",
      "FOLD: 5, EPOCH: 59, valid_loss: 0.017820868382437363\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.6757160775123104\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.3640255051500657\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.06078548207879066\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.021009459653321433\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.022891531980806783\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.019622962154886302\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.023190876372879553\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.019316712832626176\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.02203981773026528\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.019105939961531582\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.020867645848662623\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.019105333944453913\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.020374564958676216\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.01894632715950994\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.020400221669866193\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.01857673190534115\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.0203167806830137\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.018900638007942366\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.02029013017252568\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.01908922863795477\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.02042566029535186\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.018821531030185083\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.020459649207130556\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.018735128400080344\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.020471202149506536\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.01963490346337066\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.020602421895150217\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.01873595519539188\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.020628249801455004\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.018809167777790743\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.020603057657999378\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.01875642708995763\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.020700677580410436\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.018588208976913902\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.02068473268901148\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.019007000743466264\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.020768502787236246\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.01930801888160846\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.020793423188790197\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.018934094840112853\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.02081393351958644\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.018653645673218894\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.02080269285267399\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.01856914009241497\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.020787472746545268\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.019173689843977198\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.020824936645165566\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.01908737201901043\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.02081140807319072\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.01890721281661707\n",
      "FOLD: 6, EPOCH: 25, train_loss: 0.02078669503811867\n",
      "FOLD: 6, EPOCH: 25, valid_loss: 0.01867619321188506\n",
      "FOLD: 6, EPOCH: 26, train_loss: 0.02077454592912428\n",
      "FOLD: 6, EPOCH: 26, valid_loss: 0.0185907921370338\n",
      "FOLD: 6, EPOCH: 27, train_loss: 0.020758181173474558\n",
      "FOLD: 6, EPOCH: 27, valid_loss: 0.018526136656017864\n",
      "FOLD: 6, EPOCH: 28, train_loss: 0.020730790423770105\n",
      "FOLD: 6, EPOCH: 28, valid_loss: 0.018526965094839826\n",
      "FOLD: 6, EPOCH: 29, train_loss: 0.02059194234109694\n",
      "FOLD: 6, EPOCH: 29, valid_loss: 0.01887667365372181\n",
      "FOLD: 6, EPOCH: 30, train_loss: 0.020548132951221158\n",
      "FOLD: 6, EPOCH: 30, valid_loss: 0.018346015418715337\n",
      "FOLD: 6, EPOCH: 31, train_loss: 0.020508599942249635\n",
      "FOLD: 6, EPOCH: 31, valid_loss: 0.019143460099311435\n",
      "FOLD: 6, EPOCH: 32, train_loss: 0.02042058464740553\n",
      "FOLD: 6, EPOCH: 32, valid_loss: 0.018582991598283544\n",
      "FOLD: 6, EPOCH: 33, train_loss: 0.020284029913525427\n",
      "FOLD: 6, EPOCH: 33, valid_loss: 0.01872730813920498\n",
      "FOLD: 6, EPOCH: 34, train_loss: 0.0202459761211949\n",
      "FOLD: 6, EPOCH: 34, valid_loss: 0.018580235540866852\n",
      "FOLD: 6, EPOCH: 35, train_loss: 0.020103279765575164\n",
      "FOLD: 6, EPOCH: 35, valid_loss: 0.018288944847881794\n",
      "FOLD: 6, EPOCH: 36, train_loss: 0.020041942368111302\n",
      "FOLD: 6, EPOCH: 36, valid_loss: 0.01842282449497896\n",
      "FOLD: 6, EPOCH: 37, train_loss: 0.019889488215408018\n",
      "FOLD: 6, EPOCH: 37, valid_loss: 0.01822915059678695\n",
      "FOLD: 6, EPOCH: 38, train_loss: 0.019757012914746037\n",
      "FOLD: 6, EPOCH: 38, valid_loss: 0.018070059116272366\n",
      "FOLD: 6, EPOCH: 39, train_loss: 0.019696206118791335\n",
      "FOLD: 6, EPOCH: 39, valid_loss: 0.018300695125670993\n",
      "FOLD: 6, EPOCH: 40, train_loss: 0.019593565190030682\n",
      "FOLD: 6, EPOCH: 40, valid_loss: 0.01796657422228771\n",
      "FOLD: 6, EPOCH: 41, train_loss: 0.01939063967475968\n",
      "FOLD: 6, EPOCH: 41, valid_loss: 0.018204831189530736\n",
      "FOLD: 6, EPOCH: 42, train_loss: 0.019339807031135404\n",
      "FOLD: 6, EPOCH: 42, valid_loss: 0.01802346937577514\n",
      "FOLD: 6, EPOCH: 43, train_loss: 0.01917870805388497\n",
      "FOLD: 6, EPOCH: 43, valid_loss: 0.018150906790705287\n",
      "FOLD: 6, EPOCH: 44, train_loss: 0.019001711364234647\n",
      "FOLD: 6, EPOCH: 44, valid_loss: 0.018014314255731946\n",
      "FOLD: 6, EPOCH: 45, train_loss: 0.018854937474093128\n",
      "FOLD: 6, EPOCH: 45, valid_loss: 0.017863055581555647\n",
      "FOLD: 6, EPOCH: 46, train_loss: 0.0186799336705477\n",
      "FOLD: 6, EPOCH: 46, valid_loss: 0.017914154895526523\n",
      "FOLD: 6, EPOCH: 47, train_loss: 0.01850570740118142\n",
      "FOLD: 6, EPOCH: 47, valid_loss: 0.01786044398870538\n",
      "FOLD: 6, EPOCH: 48, train_loss: 0.01834376163540348\n",
      "FOLD: 6, EPOCH: 48, valid_loss: 0.017856558839626172\n",
      "FOLD: 6, EPOCH: 49, train_loss: 0.018220893527951934\n",
      "FOLD: 6, EPOCH: 49, valid_loss: 0.017808425130651277\n",
      "FOLD: 6, EPOCH: 50, train_loss: 0.018022932538822773\n",
      "FOLD: 6, EPOCH: 50, valid_loss: 0.01774598899133065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 6, EPOCH: 51, train_loss: 0.017831400463417652\n",
      "FOLD: 6, EPOCH: 51, valid_loss: 0.017872224452302736\n",
      "FOLD: 6, EPOCH: 52, train_loss: 0.01767910693081156\n",
      "FOLD: 6, EPOCH: 52, valid_loss: 0.017721559085390148\n",
      "FOLD: 6, EPOCH: 53, train_loss: 0.017535622429943856\n",
      "FOLD: 6, EPOCH: 53, valid_loss: 0.017729916719391066\n",
      "FOLD: 6, EPOCH: 54, train_loss: 0.017410298929579796\n",
      "FOLD: 6, EPOCH: 54, valid_loss: 0.017758364789187908\n",
      "FOLD: 6, EPOCH: 55, train_loss: 0.017297714690287267\n",
      "FOLD: 6, EPOCH: 55, valid_loss: 0.017752767759649193\n",
      "FOLD: 6, EPOCH: 56, train_loss: 0.017242960451591398\n",
      "FOLD: 6, EPOCH: 56, valid_loss: 0.017784906660809237\n",
      "FOLD: 6, EPOCH: 57, train_loss: 0.01714477170739443\n",
      "FOLD: 6, EPOCH: 57, valid_loss: 0.01777326567646335\n",
      "FOLD: 6, EPOCH: 58, train_loss: 0.017092537086817527\n",
      "FOLD: 6, EPOCH: 58, valid_loss: 0.017785316716660473\n",
      "FOLD: 6, EPOCH: 59, train_loss: 0.01706447550245831\n",
      "FOLD: 6, EPOCH: 59, valid_loss: 0.01780780788291903\n",
      "FOLD: 7, EPOCH: 0, train_loss: 0.6757169690824324\n",
      "FOLD: 7, EPOCH: 0, valid_loss: 0.36486368494875293\n",
      "FOLD: 7, EPOCH: 1, train_loss: 0.06102042217408457\n",
      "FOLD: 7, EPOCH: 1, valid_loss: 0.01976173940826865\n",
      "FOLD: 7, EPOCH: 2, train_loss: 0.022975843676155613\n",
      "FOLD: 7, EPOCH: 2, valid_loss: 0.018744068110690397\n",
      "FOLD: 7, EPOCH: 3, train_loss: 0.025439753299278597\n",
      "FOLD: 7, EPOCH: 3, valid_loss: 0.023906939169939828\n",
      "FOLD: 7, EPOCH: 4, train_loss: 0.02509053732839323\n",
      "FOLD: 7, EPOCH: 4, valid_loss: 0.01927656932350467\n",
      "FOLD: 7, EPOCH: 5, train_loss: 0.021848905783507132\n",
      "FOLD: 7, EPOCH: 5, valid_loss: 0.01830321451758637\n",
      "FOLD: 7, EPOCH: 6, train_loss: 0.02118292533822598\n",
      "FOLD: 7, EPOCH: 6, valid_loss: 0.018063212251838517\n",
      "FOLD: 7, EPOCH: 7, train_loss: 0.02092713947978712\n",
      "FOLD: 7, EPOCH: 7, valid_loss: 0.018012081327683786\n",
      "FOLD: 7, EPOCH: 8, train_loss: 0.02065600708367363\n",
      "FOLD: 7, EPOCH: 8, valid_loss: 0.018039925790884915\n",
      "FOLD: 7, EPOCH: 9, train_loss: 0.0205006648696238\n",
      "FOLD: 7, EPOCH: 9, valid_loss: 0.018951051156310475\n",
      "FOLD: 7, EPOCH: 10, train_loss: 0.020536358570379595\n",
      "FOLD: 7, EPOCH: 10, valid_loss: 0.017903474871726596\n",
      "FOLD: 7, EPOCH: 11, train_loss: 0.02048674440912662\n",
      "FOLD: 7, EPOCH: 11, valid_loss: 0.01793424313997521\n",
      "FOLD: 7, EPOCH: 12, train_loss: 0.020499788404953097\n",
      "FOLD: 7, EPOCH: 12, valid_loss: 0.017975523739176637\n",
      "FOLD: 7, EPOCH: 13, train_loss: 0.020580053341484838\n",
      "FOLD: 7, EPOCH: 13, valid_loss: 0.018154321238398552\n",
      "FOLD: 7, EPOCH: 14, train_loss: 0.020636326110651415\n",
      "FOLD: 7, EPOCH: 14, valid_loss: 0.017872247954501826\n",
      "FOLD: 7, EPOCH: 15, train_loss: 0.020561065584901842\n",
      "FOLD: 7, EPOCH: 15, valid_loss: 0.01806130413623417\n",
      "FOLD: 7, EPOCH: 16, train_loss: 0.020684424703640323\n",
      "FOLD: 7, EPOCH: 16, valid_loss: 0.017871883533456746\n",
      "FOLD: 7, EPOCH: 17, train_loss: 0.02069571614265442\n",
      "FOLD: 7, EPOCH: 17, valid_loss: 0.01843401658184388\n",
      "FOLD: 7, EPOCH: 18, train_loss: 0.02071865466573546\n",
      "FOLD: 7, EPOCH: 18, valid_loss: 0.018112793893498534\n",
      "FOLD: 7, EPOCH: 19, train_loss: 0.020748208871772214\n",
      "FOLD: 7, EPOCH: 19, valid_loss: 0.018356943503022194\n",
      "FOLD: 7, EPOCH: 20, train_loss: 0.020797115960909475\n",
      "FOLD: 7, EPOCH: 20, valid_loss: 0.01831375259686919\n",
      "FOLD: 7, EPOCH: 21, train_loss: 0.020825184905721297\n",
      "FOLD: 7, EPOCH: 21, valid_loss: 0.018086043131702086\n",
      "FOLD: 7, EPOCH: 22, train_loss: 0.020784104435193924\n",
      "FOLD: 7, EPOCH: 22, valid_loss: 0.018114296500297153\n",
      "FOLD: 7, EPOCH: 23, train_loss: 0.020837071225527793\n",
      "FOLD: 7, EPOCH: 23, valid_loss: 0.018095153219559613\n",
      "FOLD: 7, EPOCH: 24, train_loss: 0.020832347725668263\n",
      "FOLD: 7, EPOCH: 24, valid_loss: 0.01798812595798689\n",
      "FOLD: 7, EPOCH: 25, train_loss: 0.020739078473660254\n",
      "FOLD: 7, EPOCH: 25, valid_loss: 0.017889819710570222\n",
      "FOLD: 7, EPOCH: 26, train_loss: 0.020733647421002387\n",
      "FOLD: 7, EPOCH: 26, valid_loss: 0.017853091963950324\n",
      "FOLD: 7, EPOCH: 27, train_loss: 0.020762520668006712\n",
      "FOLD: 7, EPOCH: 27, valid_loss: 0.01791113373987815\n",
      "FOLD: 7, EPOCH: 28, train_loss: 0.02063975168331977\n",
      "FOLD: 7, EPOCH: 28, valid_loss: 0.018194517887690487\n",
      "FOLD: 7, EPOCH: 29, train_loss: 0.02064071390176973\n",
      "FOLD: 7, EPOCH: 29, valid_loss: 0.017925534616498387\n",
      "FOLD: 7, EPOCH: 30, train_loss: 0.020621284770388756\n",
      "FOLD: 7, EPOCH: 30, valid_loss: 0.018039684085284963\n",
      "FOLD: 7, EPOCH: 31, train_loss: 0.020538989045927603\n",
      "FOLD: 7, EPOCH: 31, valid_loss: 0.017895863884512114\n",
      "FOLD: 7, EPOCH: 32, train_loss: 0.02037340945774509\n",
      "FOLD: 7, EPOCH: 32, valid_loss: 0.01765539321829291\n",
      "FOLD: 7, EPOCH: 33, train_loss: 0.02030420796044411\n",
      "FOLD: 7, EPOCH: 33, valid_loss: 0.017756858183180586\n",
      "FOLD: 7, EPOCH: 34, train_loss: 0.020239348577395563\n",
      "FOLD: 7, EPOCH: 34, valid_loss: 0.01777557174072546\n",
      "FOLD: 7, EPOCH: 35, train_loss: 0.020070341289524108\n",
      "FOLD: 7, EPOCH: 35, valid_loss: 0.01754018313744489\n",
      "FOLD: 7, EPOCH: 36, train_loss: 0.020003806367035835\n",
      "FOLD: 7, EPOCH: 36, valid_loss: 0.01744123942711774\n",
      "FOLD: 7, EPOCH: 37, train_loss: 0.01988270475018409\n",
      "FOLD: 7, EPOCH: 37, valid_loss: 0.01754993518047473\n",
      "FOLD: 7, EPOCH: 38, train_loss: 0.019805603101849555\n",
      "FOLD: 7, EPOCH: 38, valid_loss: 0.017474822316537884\n",
      "FOLD: 7, EPOCH: 39, train_loss: 0.01968249280846888\n",
      "FOLD: 7, EPOCH: 39, valid_loss: 0.017546193235937285\n",
      "FOLD: 7, EPOCH: 40, train_loss: 0.019550479624059893\n",
      "FOLD: 7, EPOCH: 40, valid_loss: 0.017449546440997544\n",
      "FOLD: 7, EPOCH: 41, train_loss: 0.01939556721237398\n",
      "FOLD: 7, EPOCH: 41, valid_loss: 0.017452047809081918\n",
      "FOLD: 7, EPOCH: 42, train_loss: 0.01930254948956351\n",
      "FOLD: 7, EPOCH: 42, valid_loss: 0.01729569775874124\n",
      "FOLD: 7, EPOCH: 43, train_loss: 0.019161215304367003\n",
      "FOLD: 7, EPOCH: 43, valid_loss: 0.01723828725516796\n",
      "FOLD: 7, EPOCH: 44, train_loss: 0.019007516472089675\n",
      "FOLD: 7, EPOCH: 44, valid_loss: 0.017280898988246918\n",
      "FOLD: 7, EPOCH: 45, train_loss: 0.018842001631855964\n",
      "FOLD: 7, EPOCH: 45, valid_loss: 0.01716581332113813\n",
      "FOLD: 7, EPOCH: 46, train_loss: 0.018652992719604123\n",
      "FOLD: 7, EPOCH: 46, valid_loss: 0.017212410950485396\n",
      "FOLD: 7, EPOCH: 47, train_loss: 0.018543283118596002\n",
      "FOLD: 7, EPOCH: 47, valid_loss: 0.017294866635518914\n",
      "FOLD: 7, EPOCH: 48, train_loss: 0.018365690136148083\n",
      "FOLD: 7, EPOCH: 48, valid_loss: 0.01713708317016854\n",
      "FOLD: 7, EPOCH: 49, train_loss: 0.018170435942949786\n",
      "FOLD: 7, EPOCH: 49, valid_loss: 0.017225451274391484\n",
      "FOLD: 7, EPOCH: 50, train_loss: 0.017994273958667633\n",
      "FOLD: 7, EPOCH: 50, valid_loss: 0.017164870822692618\n",
      "FOLD: 7, EPOCH: 51, train_loss: 0.017799083618146756\n",
      "FOLD: 7, EPOCH: 51, valid_loss: 0.017162168234148446\n",
      "FOLD: 7, EPOCH: 52, train_loss: 0.017640066585473475\n",
      "FOLD: 7, EPOCH: 52, valid_loss: 0.01719227372942602\n",
      "FOLD: 7, EPOCH: 53, train_loss: 0.01746765245953875\n",
      "FOLD: 7, EPOCH: 53, valid_loss: 0.017234109780367685\n",
      "FOLD: 7, EPOCH: 54, train_loss: 0.01730391406003506\n",
      "FOLD: 7, EPOCH: 54, valid_loss: 0.017204855294788584\n",
      "FOLD: 7, EPOCH: 55, train_loss: 0.01720460801114959\n",
      "FOLD: 7, EPOCH: 55, valid_loss: 0.017214848659932613\n",
      "FOLD: 7, EPOCH: 56, train_loss: 0.017132375419380202\n",
      "FOLD: 7, EPOCH: 56, valid_loss: 0.017199532128870487\n",
      "FOLD: 7, EPOCH: 57, train_loss: 0.017028463307407593\n",
      "FOLD: 7, EPOCH: 57, valid_loss: 0.01718179678873104\n",
      "FOLD: 7, EPOCH: 58, train_loss: 0.01697371350901742\n",
      "FOLD: 7, EPOCH: 58, valid_loss: 0.017185986754210555\n",
      "FOLD: 7, EPOCH: 59, train_loss: 0.016955078639570745\n",
      "FOLD: 7, EPOCH: 59, valid_loss: 0.017195835545220795\n",
      "FOLD: 8, EPOCH: 0, train_loss: 0.67562489855674\n",
      "FOLD: 8, EPOCH: 0, valid_loss: 0.3657408919599321\n",
      "FOLD: 8, EPOCH: 1, train_loss: 0.06039476100235216\n",
      "FOLD: 8, EPOCH: 1, valid_loss: 0.019555662862128682\n",
      "FOLD: 8, EPOCH: 2, train_loss: 0.022855703676900554\n",
      "FOLD: 8, EPOCH: 2, valid_loss: 0.01887366786185238\n",
      "FOLD: 8, EPOCH: 3, train_loss: 0.02299399177633947\n",
      "FOLD: 8, EPOCH: 3, valid_loss: 0.018592760898172855\n",
      "FOLD: 8, EPOCH: 4, train_loss: 0.021280946089856086\n",
      "FOLD: 8, EPOCH: 4, valid_loss: 0.01881655952375796\n",
      "FOLD: 8, EPOCH: 5, train_loss: 0.020932470238016497\n",
      "FOLD: 8, EPOCH: 5, valid_loss: 0.01916581904515624\n",
      "FOLD: 8, EPOCH: 6, train_loss: 0.020449117330774185\n",
      "FOLD: 8, EPOCH: 6, valid_loss: 0.01776022370904684\n",
      "FOLD: 8, EPOCH: 7, train_loss: 0.02051028635713362\n",
      "FOLD: 8, EPOCH: 7, valid_loss: 0.017730899931242067\n",
      "FOLD: 8, EPOCH: 8, train_loss: 0.02031180916293975\n",
      "FOLD: 8, EPOCH: 8, valid_loss: 0.017936248539222613\n",
      "FOLD: 8, EPOCH: 9, train_loss: 0.02037904796100432\n",
      "FOLD: 8, EPOCH: 9, valid_loss: 0.018116357529328928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 8, EPOCH: 10, train_loss: 0.020429047088949912\n",
      "FOLD: 8, EPOCH: 10, valid_loss: 0.017881054017278884\n",
      "FOLD: 8, EPOCH: 11, train_loss: 0.020493722755101418\n",
      "FOLD: 8, EPOCH: 11, valid_loss: 0.017977361256877582\n",
      "FOLD: 8, EPOCH: 12, train_loss: 0.02054811553849328\n",
      "FOLD: 8, EPOCH: 12, valid_loss: 0.018087607756670978\n",
      "FOLD: 8, EPOCH: 13, train_loss: 0.020657338406289777\n",
      "FOLD: 8, EPOCH: 13, valid_loss: 0.018017779777033463\n",
      "FOLD: 8, EPOCH: 14, train_loss: 0.020661823703877386\n",
      "FOLD: 8, EPOCH: 14, valid_loss: 0.018016928444719978\n",
      "FOLD: 8, EPOCH: 15, train_loss: 0.02076904678777341\n",
      "FOLD: 8, EPOCH: 15, valid_loss: 0.01785773587309652\n",
      "FOLD: 8, EPOCH: 16, train_loss: 0.02079709574820534\n",
      "FOLD: 8, EPOCH: 16, valid_loss: 0.01820435318061047\n",
      "FOLD: 8, EPOCH: 17, train_loss: 0.020812913018368906\n",
      "FOLD: 8, EPOCH: 17, valid_loss: 0.018073087247709434\n",
      "FOLD: 8, EPOCH: 18, train_loss: 0.02083689009229983\n",
      "FOLD: 8, EPOCH: 18, valid_loss: 0.017933851521876123\n",
      "FOLD: 8, EPOCH: 19, train_loss: 0.020849412331177344\n",
      "FOLD: 8, EPOCH: 19, valid_loss: 0.018213782614717882\n",
      "FOLD: 8, EPOCH: 20, train_loss: 0.02093420345937052\n",
      "FOLD: 8, EPOCH: 20, valid_loss: 0.018162076516697805\n",
      "FOLD: 8, EPOCH: 21, train_loss: 0.021025606881706946\n",
      "FOLD: 8, EPOCH: 21, valid_loss: 0.01854689558967948\n",
      "FOLD: 8, EPOCH: 22, train_loss: 0.020926476558369975\n",
      "FOLD: 8, EPOCH: 22, valid_loss: 0.017955478073822126\n",
      "FOLD: 8, EPOCH: 23, train_loss: 0.0209232694319179\n",
      "FOLD: 8, EPOCH: 23, valid_loss: 0.018172475095424388\n",
      "FOLD: 8, EPOCH: 24, train_loss: 0.020928091423646097\n",
      "FOLD: 8, EPOCH: 24, valid_loss: 0.01812797634758883\n",
      "FOLD: 8, EPOCH: 25, train_loss: 0.020771116895541068\n",
      "FOLD: 8, EPOCH: 25, valid_loss: 0.01788808736536238\n",
      "FOLD: 8, EPOCH: 26, train_loss: 0.0208709045643768\n",
      "FOLD: 8, EPOCH: 26, valid_loss: 0.017677675880905654\n",
      "FOLD: 8, EPOCH: 27, train_loss: 0.020825066489558067\n",
      "FOLD: 8, EPOCH: 27, valid_loss: 0.017849162841836613\n",
      "FOLD: 8, EPOCH: 28, train_loss: 0.020695982332671843\n",
      "FOLD: 8, EPOCH: 28, valid_loss: 0.017882933633195028\n",
      "FOLD: 8, EPOCH: 29, train_loss: 0.020732424215924354\n",
      "FOLD: 8, EPOCH: 29, valid_loss: 0.01761475722822878\n",
      "FOLD: 8, EPOCH: 30, train_loss: 0.02062310700214678\n",
      "FOLD: 8, EPOCH: 30, valid_loss: 0.01795525559120708\n",
      "FOLD: 8, EPOCH: 31, train_loss: 0.020573838812208946\n",
      "FOLD: 8, EPOCH: 31, valid_loss: 0.017882266340570316\n",
      "FOLD: 8, EPOCH: 32, train_loss: 0.020481097313665573\n",
      "FOLD: 8, EPOCH: 32, valid_loss: 0.01766439527273178\n",
      "FOLD: 8, EPOCH: 33, train_loss: 0.020280533416136618\n",
      "FOLD: 8, EPOCH: 33, valid_loss: 0.017790944781154394\n",
      "FOLD: 8, EPOCH: 34, train_loss: 0.020222033500190705\n",
      "FOLD: 8, EPOCH: 34, valid_loss: 0.017742663001020748\n",
      "FOLD: 8, EPOCH: 35, train_loss: 0.020161903685619754\n",
      "FOLD: 8, EPOCH: 35, valid_loss: 0.01762183445195357\n",
      "FOLD: 8, EPOCH: 36, train_loss: 0.020060321147884093\n",
      "FOLD: 8, EPOCH: 36, valid_loss: 0.017434337072902255\n",
      "FOLD: 8, EPOCH: 37, train_loss: 0.019981505373312582\n",
      "FOLD: 8, EPOCH: 37, valid_loss: 0.017585719987336133\n",
      "FOLD: 8, EPOCH: 38, train_loss: 0.019825109382790904\n",
      "FOLD: 8, EPOCH: 38, valid_loss: 0.017504447295020025\n",
      "FOLD: 8, EPOCH: 39, train_loss: 0.01976038852045613\n",
      "FOLD: 8, EPOCH: 39, valid_loss: 0.01726223435252905\n",
      "FOLD: 8, EPOCH: 40, train_loss: 0.0196271100472058\n",
      "FOLD: 8, EPOCH: 40, valid_loss: 0.017175200964427657\n",
      "FOLD: 8, EPOCH: 41, train_loss: 0.019540139720324548\n",
      "FOLD: 8, EPOCH: 41, valid_loss: 0.0172280329797003\n",
      "FOLD: 8, EPOCH: 42, train_loss: 0.019303081497069326\n",
      "FOLD: 8, EPOCH: 42, valid_loss: 0.017293144172678392\n",
      "FOLD: 8, EPOCH: 43, train_loss: 0.019196620535465978\n",
      "FOLD: 8, EPOCH: 43, valid_loss: 0.017256417725649145\n",
      "FOLD: 8, EPOCH: 44, train_loss: 0.01909862796385442\n",
      "FOLD: 8, EPOCH: 44, valid_loss: 0.017236957223051123\n",
      "FOLD: 8, EPOCH: 45, train_loss: 0.018900893652631392\n",
      "FOLD: 8, EPOCH: 45, valid_loss: 0.01729256059560511\n",
      "FOLD: 8, EPOCH: 46, train_loss: 0.018755034585633587\n",
      "FOLD: 8, EPOCH: 46, valid_loss: 0.017267057206481695\n",
      "FOLD: 8, EPOCH: 47, train_loss: 0.018619059807350558\n",
      "FOLD: 8, EPOCH: 47, valid_loss: 0.01713755964818928\n",
      "FOLD: 8, EPOCH: 48, train_loss: 0.018464481373948436\n",
      "FOLD: 8, EPOCH: 48, valid_loss: 0.01707216129741735\n",
      "FOLD: 8, EPOCH: 49, train_loss: 0.01826703033500141\n",
      "FOLD: 8, EPOCH: 49, valid_loss: 0.017092973821692996\n",
      "FOLD: 8, EPOCH: 50, train_loss: 0.01808987400464473\n",
      "FOLD: 8, EPOCH: 50, valid_loss: 0.017003238511582214\n",
      "FOLD: 8, EPOCH: 51, train_loss: 0.01793006616494348\n",
      "FOLD: 8, EPOCH: 51, valid_loss: 0.01707740867924359\n",
      "FOLD: 8, EPOCH: 52, train_loss: 0.017779366852295014\n",
      "FOLD: 8, EPOCH: 52, valid_loss: 0.017035202951067023\n",
      "FOLD: 8, EPOCH: 53, train_loss: 0.01764122897819165\n",
      "FOLD: 8, EPOCH: 53, valid_loss: 0.017036890248871513\n",
      "FOLD: 8, EPOCH: 54, train_loss: 0.017455525870525068\n",
      "FOLD: 8, EPOCH: 54, valid_loss: 0.017107986327674653\n",
      "FOLD: 8, EPOCH: 55, train_loss: 0.017363528240351908\n",
      "FOLD: 8, EPOCH: 55, valid_loss: 0.017052953855858907\n",
      "FOLD: 8, EPOCH: 56, train_loss: 0.0172692327670032\n",
      "FOLD: 8, EPOCH: 56, valid_loss: 0.017039564593384664\n",
      "FOLD: 8, EPOCH: 57, train_loss: 0.017249603641609993\n",
      "FOLD: 8, EPOCH: 57, valid_loss: 0.017028773565673165\n",
      "FOLD: 8, EPOCH: 58, train_loss: 0.017183989136209412\n",
      "FOLD: 8, EPOCH: 58, valid_loss: 0.01706315220023195\n",
      "FOLD: 8, EPOCH: 59, train_loss: 0.017193119498270175\n",
      "FOLD: 8, EPOCH: 59, valid_loss: 0.01703601289126608\n",
      "FOLD: 9, EPOCH: 0, train_loss: 0.6750427694089951\n",
      "FOLD: 9, EPOCH: 0, valid_loss: 0.3441930347018772\n",
      "FOLD: 9, EPOCH: 1, train_loss: 0.06182495507021104\n",
      "FOLD: 9, EPOCH: 1, valid_loss: 0.019675405282113288\n",
      "FOLD: 9, EPOCH: 2, train_loss: 0.023514123633503914\n",
      "FOLD: 9, EPOCH: 2, valid_loss: 0.020082186286648113\n",
      "FOLD: 9, EPOCH: 3, train_loss: 0.024293128785587127\n",
      "FOLD: 9, EPOCH: 3, valid_loss: 0.018715286006530125\n",
      "FOLD: 9, EPOCH: 4, train_loss: 0.023503797513342674\n",
      "FOLD: 9, EPOCH: 4, valid_loss: 0.020699745664993923\n",
      "FOLD: 9, EPOCH: 5, train_loss: 0.021800603777650866\n",
      "FOLD: 9, EPOCH: 5, valid_loss: 0.017994177113804553\n",
      "FOLD: 9, EPOCH: 6, train_loss: 0.021033348707902817\n",
      "FOLD: 9, EPOCH: 6, valid_loss: 0.02083598832703299\n",
      "FOLD: 9, EPOCH: 7, train_loss: 0.0207612729481151\n",
      "FOLD: 9, EPOCH: 7, valid_loss: 0.018834735059903726\n",
      "FOLD: 9, EPOCH: 8, train_loss: 0.020500070709855326\n",
      "FOLD: 9, EPOCH: 8, valid_loss: 0.01767112345745166\n",
      "FOLD: 9, EPOCH: 9, train_loss: 0.020402580451580787\n",
      "FOLD: 9, EPOCH: 9, valid_loss: 0.0192060022511416\n",
      "FOLD: 9, EPOCH: 10, train_loss: 0.02063006007623288\n",
      "FOLD: 9, EPOCH: 10, valid_loss: 0.019288281082279153\n",
      "FOLD: 9, EPOCH: 11, train_loss: 0.020529716714255273\n",
      "FOLD: 9, EPOCH: 11, valid_loss: 0.01848317517174615\n",
      "FOLD: 9, EPOCH: 12, train_loss: 0.020570527449730903\n",
      "FOLD: 9, EPOCH: 12, valid_loss: 0.024936590964595478\n",
      "FOLD: 9, EPOCH: 13, train_loss: 0.02068545651291647\n",
      "FOLD: 9, EPOCH: 13, valid_loss: 0.017689649429586198\n",
      "FOLD: 9, EPOCH: 14, train_loss: 0.020504590340199007\n",
      "FOLD: 9, EPOCH: 14, valid_loss: 0.01850048007650508\n",
      "FOLD: 9, EPOCH: 15, train_loss: 0.02042597497422849\n",
      "FOLD: 9, EPOCH: 15, valid_loss: 0.017192915288938418\n",
      "FOLD: 9, EPOCH: 16, train_loss: 0.020255899861935645\n",
      "FOLD: 9, EPOCH: 16, valid_loss: 0.02105323038995266\n",
      "FOLD: 9, EPOCH: 17, train_loss: 0.020692563249218848\n",
      "FOLD: 9, EPOCH: 17, valid_loss: 0.027532488832043275\n",
      "FOLD: 9, EPOCH: 18, train_loss: 0.020947075911587284\n",
      "FOLD: 9, EPOCH: 18, valid_loss: 0.017950975543095007\n",
      "FOLD: 9, EPOCH: 19, train_loss: 0.020807932425410517\n",
      "FOLD: 9, EPOCH: 19, valid_loss: 0.019904426712956693\n",
      "FOLD: 9, EPOCH: 20, train_loss: 0.02093849727703679\n",
      "FOLD: 9, EPOCH: 20, valid_loss: 0.019265203840202756\n",
      "FOLD: 9, EPOCH: 21, train_loss: 0.021153327017541853\n",
      "FOLD: 9, EPOCH: 21, valid_loss: 0.018315730926891167\n",
      "FOLD: 9, EPOCH: 22, train_loss: 0.02084879466602879\n",
      "FOLD: 9, EPOCH: 22, valid_loss: 0.018662516338129837\n",
      "FOLD: 9, EPOCH: 23, train_loss: 0.02133828382338247\n",
      "FOLD: 9, EPOCH: 23, valid_loss: 0.0213047553681665\n",
      "FOLD: 9, EPOCH: 24, train_loss: 0.021129205414364416\n",
      "FOLD: 9, EPOCH: 24, valid_loss: 0.01827152559740676\n",
      "FOLD: 9, EPOCH: 25, train_loss: 0.020834976879339065\n",
      "FOLD: 9, EPOCH: 25, valid_loss: 0.0177462346230944\n",
      "FOLD: 9, EPOCH: 26, train_loss: 0.02083370842400097\n",
      "FOLD: 9, EPOCH: 26, valid_loss: 0.01779633274094926\n",
      "FOLD: 9, EPOCH: 27, train_loss: 0.020682557552091536\n",
      "FOLD: 9, EPOCH: 27, valid_loss: 0.017484896298911836\n",
      "FOLD: 9, EPOCH: 28, train_loss: 0.020800765555712485\n",
      "FOLD: 9, EPOCH: 28, valid_loss: 0.01853940077126026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 9, EPOCH: 29, train_loss: 0.021089406287477862\n",
      "FOLD: 9, EPOCH: 29, valid_loss: 0.017985102203157213\n",
      "FOLD: 9, EPOCH: 30, train_loss: 0.020629431103025713\n",
      "FOLD: 9, EPOCH: 30, valid_loss: 0.0174796251166198\n",
      "FOLD: 9, EPOCH: 31, train_loss: 0.020496423566533674\n",
      "FOLD: 9, EPOCH: 31, valid_loss: 0.017436556207636993\n",
      "FOLD: 9, EPOCH: 32, train_loss: 0.020395172345301797\n",
      "FOLD: 9, EPOCH: 32, valid_loss: 0.017538265739050176\n",
      "FOLD: 9, EPOCH: 33, train_loss: 0.0203360571255607\n",
      "FOLD: 9, EPOCH: 33, valid_loss: 0.017278456543054845\n",
      "FOLD: 9, EPOCH: 34, train_loss: 0.020442814355896365\n",
      "FOLD: 9, EPOCH: 34, valid_loss: 0.017236355123006634\n",
      "FOLD: 9, EPOCH: 35, train_loss: 0.02021494924781784\n",
      "FOLD: 9, EPOCH: 35, valid_loss: 0.01737020992570453\n",
      "FOLD: 9, EPOCH: 36, train_loss: 0.020118959067809965\n",
      "FOLD: 9, EPOCH: 36, valid_loss: 0.017115365092953045\n",
      "FOLD: 9, EPOCH: 37, train_loss: 0.020010641649846107\n",
      "FOLD: 9, EPOCH: 37, valid_loss: 0.017200665031042364\n",
      "FOLD: 9, EPOCH: 38, train_loss: 0.01995804944346028\n",
      "FOLD: 9, EPOCH: 38, valid_loss: 0.017056403164234426\n",
      "FOLD: 9, EPOCH: 39, train_loss: 0.019884535598178064\n",
      "FOLD: 9, EPOCH: 39, valid_loss: 0.017081651474452682\n",
      "FOLD: 9, EPOCH: 40, train_loss: 0.019616986769101313\n",
      "FOLD: 9, EPOCH: 40, valid_loss: 0.01688444624758429\n",
      "FOLD: 9, EPOCH: 41, train_loss: 0.019564101051899693\n",
      "FOLD: 9, EPOCH: 41, valid_loss: 0.016831684598906174\n",
      "FOLD: 9, EPOCH: 42, train_loss: 0.019487715452428788\n",
      "FOLD: 9, EPOCH: 42, valid_loss: 0.016819214293112356\n",
      "FOLD: 9, EPOCH: 43, train_loss: 0.01938325253825995\n",
      "FOLD: 9, EPOCH: 43, valid_loss: 0.016807875440766413\n",
      "FOLD: 9, EPOCH: 44, train_loss: 0.019227820382483544\n",
      "FOLD: 9, EPOCH: 44, valid_loss: 0.016752069867733452\n",
      "FOLD: 9, EPOCH: 45, train_loss: 0.01910124636225162\n",
      "FOLD: 9, EPOCH: 45, valid_loss: 0.016800449695438147\n",
      "FOLD: 9, EPOCH: 46, train_loss: 0.018939380311677533\n",
      "FOLD: 9, EPOCH: 46, valid_loss: 0.016728221180124417\n",
      "FOLD: 9, EPOCH: 47, train_loss: 0.0187606233322332\n",
      "FOLD: 9, EPOCH: 47, valid_loss: 0.016665766274349555\n",
      "FOLD: 9, EPOCH: 48, train_loss: 0.01854477471882297\n",
      "FOLD: 9, EPOCH: 48, valid_loss: 0.016657032020803954\n",
      "FOLD: 9, EPOCH: 49, train_loss: 0.01846764616427883\n",
      "FOLD: 9, EPOCH: 49, valid_loss: 0.016630843178265624\n",
      "FOLD: 9, EPOCH: 50, train_loss: 0.01828837430765552\n",
      "FOLD: 9, EPOCH: 50, valid_loss: 0.016668088371968932\n",
      "FOLD: 9, EPOCH: 51, train_loss: 0.0180598339546592\n",
      "FOLD: 9, EPOCH: 51, valid_loss: 0.016592174044085875\n",
      "FOLD: 9, EPOCH: 52, train_loss: 0.017936696088121783\n",
      "FOLD: 9, EPOCH: 52, valid_loss: 0.016690526675019\n",
      "FOLD: 9, EPOCH: 53, train_loss: 0.017730577091776556\n",
      "FOLD: 9, EPOCH: 53, valid_loss: 0.016716846264898777\n",
      "FOLD: 9, EPOCH: 54, train_loss: 0.017670051429060196\n",
      "FOLD: 9, EPOCH: 54, valid_loss: 0.01661816451491581\n",
      "FOLD: 9, EPOCH: 55, train_loss: 0.01768533941358328\n",
      "FOLD: 9, EPOCH: 55, valid_loss: 0.016788082766450114\n",
      "FOLD: 9, EPOCH: 56, train_loss: 0.01734837449846729\n",
      "FOLD: 9, EPOCH: 56, valid_loss: 0.0166603388885657\n",
      "FOLD: 9, EPOCH: 57, train_loss: 0.017258310648462463\n",
      "FOLD: 9, EPOCH: 57, valid_loss: 0.01671195397567418\n",
      "FOLD: 9, EPOCH: 58, train_loss: 0.017203020418603575\n",
      "FOLD: 9, EPOCH: 58, valid_loss: 0.016617133282124996\n",
      "FOLD: 9, EPOCH: 59, train_loss: 0.017301190217896816\n",
      "FOLD: 9, EPOCH: 59, valid_loss: 0.016687139196114406\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6760033322918799\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.37395558637731213\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.061466348291404786\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.020225086085060063\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.022905275934646207\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018828232170027846\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.022390271170485403\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.022068460198009714\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.023387701340740728\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.018250647603588945\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.020768348692405608\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017932154128656667\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.020446510793220612\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01794869704719852\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.02035174855301457\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017993031617473152\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020301293978287328\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01811998085502316\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020346556039106463\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01814265373875113\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020345215463349896\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.018166770062902394\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.02042515017092228\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01838922664961394\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.02052080035209656\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01831877330208526\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.02060357818920766\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01815700125606621\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.020679389108573237\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.018274271093747196\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.02068864938712889\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.018297444700318223\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.020747612296573577\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.018434623365893084\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.020765102041825172\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.018411350819994423\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.020860649873652767\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.0181343425065279\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.020827214852456123\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.018379815470646408\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.020786232513285454\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.01832922296050717\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.020876610928004788\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.019047666669768447\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.020888223787469247\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.018374284291092086\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.020922208745633403\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.018596723566160482\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.02087873512458417\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.018539813182809773\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.020746590197086336\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.018032028723288986\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.020788637068002453\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.018623048987458733\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.020841562820057714\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.018230467486907456\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.020730223074074714\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01811558917603072\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.020751006997400713\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.018611310926430365\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.020578610752859425\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.01833097669569885\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.020523341348575006\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.01791041097877657\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.02044694370800449\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.017977769322255078\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.02038713035083586\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.01799647685359506\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.020281731697820847\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.01799238341696122\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.020151325603646617\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.017811837113078904\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.02007276884490444\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.01777288197156261\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.019963148188206457\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.01758206679540522\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.019847133611479113\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.017508216202259064\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.01969895172984369\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.01755975016995388\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.01962773367281883\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.01768140500301824\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.019476167376964323\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.017416528535678107\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.019325892489042974\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.017558860428193036\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.019222812306496403\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.017466027399196345\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.01909228919013854\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.017453096916570383\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.018901622163191918\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.01745562786784242\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.018747005431402113\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.017274462782284793\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.018586968570466964\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.01727870156002395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 48, train_loss: 0.018438621994949157\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.017320752856047714\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.018250360724426085\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.017299349364988944\n",
      "FOLD: 0, EPOCH: 50, train_loss: 0.018111458769248377\n",
      "FOLD: 0, EPOCH: 50, valid_loss: 0.017199276946485043\n",
      "FOLD: 0, EPOCH: 51, train_loss: 0.01792693452368821\n",
      "FOLD: 0, EPOCH: 51, valid_loss: 0.017282147234415308\n",
      "FOLD: 0, EPOCH: 52, train_loss: 0.017780271731317042\n",
      "FOLD: 0, EPOCH: 52, valid_loss: 0.017226649393491885\n",
      "FOLD: 0, EPOCH: 53, train_loss: 0.01760803640729958\n",
      "FOLD: 0, EPOCH: 53, valid_loss: 0.017226019709864083\n",
      "FOLD: 0, EPOCH: 54, train_loss: 0.017502926902905586\n",
      "FOLD: 0, EPOCH: 54, valid_loss: 0.01724357278469731\n",
      "FOLD: 0, EPOCH: 55, train_loss: 0.017355860277049003\n",
      "FOLD: 0, EPOCH: 55, valid_loss: 0.017209003460319602\n",
      "FOLD: 0, EPOCH: 56, train_loss: 0.017275361566533965\n",
      "FOLD: 0, EPOCH: 56, valid_loss: 0.01720972978236044\n",
      "FOLD: 0, EPOCH: 57, train_loss: 0.017255357466638088\n",
      "FOLD: 0, EPOCH: 57, valid_loss: 0.017203068415469983\n",
      "FOLD: 0, EPOCH: 58, train_loss: 0.01717004827674358\n",
      "FOLD: 0, EPOCH: 58, valid_loss: 0.017204724580926055\n",
      "FOLD: 0, EPOCH: 59, train_loss: 0.017150559805093273\n",
      "FOLD: 0, EPOCH: 59, valid_loss: 0.017214615007533747\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.675175682767745\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.36047450535827213\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.06089945912601486\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.021042068126714893\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.022936456289983566\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.020196686861001782\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.023542408705238372\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.019550206398384437\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.021345748836475033\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01825486309826374\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.020710401140874433\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.018872157153156068\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.021023894089364236\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.019603519545247156\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.021079793007623766\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01842469059758716\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020584890330510756\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.018314966569758125\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020450214717176653\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.018255075853731897\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.020503881381404014\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01859480416816142\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020462621940720467\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018342549809151225\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.020512697256861195\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.018078773178988032\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.020540628161641858\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017995977619041998\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.020587049520784807\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01845862354255385\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.020645210507415957\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018703047186136246\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.020695437430854766\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.018516814853582118\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.020704933784661754\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.018337671231064532\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.020687437514143606\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.018547677124540012\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.020792569772851082\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.018669989477429125\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.020785855766265623\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.018472732406937413\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.02077295745332395\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.018522425709913175\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.020761590042421896\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.018506939109000895\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.02079489467845809\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.018657514308061864\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.020791078947724834\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.018620564188394282\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.020756331590875504\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.018586742639955547\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.02067929699776634\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.01846590100063218\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.020624421332632342\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.01862852404721909\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.020638232053287568\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.018485356122255325\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.020594550008254667\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.018396103495938912\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.020494433083841877\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.01807368112107118\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.020438968894943114\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018452123842305608\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.02036581719594617\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.01840395185475548\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.020270766245742\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.01820263970229361\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.020176024951281086\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.018004251488794882\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.020100397376283524\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.018084431998431683\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.01997481165153365\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.018241050290978618\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.019854370817061394\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.018057218701061275\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.019715877646400082\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.01773418377464016\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.019663959236875656\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.01791311562475231\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.019544196501374244\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.01792078118564354\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.01939621007730884\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.017697169704155788\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.01928232444390174\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.01768851585479246\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.019172845468405756\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.017754117026925087\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.01902434916025208\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.01782475592982438\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.01886949167857247\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.017782062550799713\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.018664183677925217\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.0175043772906065\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.018510621119170418\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.017705164280616574\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.018353684090318217\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.017585518976880446\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.01816022071026025\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.017582055543445878\n",
      "FOLD: 1, EPOCH: 50, train_loss: 0.017991172149777412\n",
      "FOLD: 1, EPOCH: 50, valid_loss: 0.01761437559293376\n",
      "FOLD: 1, EPOCH: 51, train_loss: 0.01778997048254936\n",
      "FOLD: 1, EPOCH: 51, valid_loss: 0.01764243008154962\n",
      "FOLD: 1, EPOCH: 52, train_loss: 0.017664977090974008\n",
      "FOLD: 1, EPOCH: 52, valid_loss: 0.017591622709814046\n",
      "FOLD: 1, EPOCH: 53, train_loss: 0.017490000494064822\n",
      "FOLD: 1, EPOCH: 53, valid_loss: 0.017578662062684696\n",
      "FOLD: 1, EPOCH: 54, train_loss: 0.017338842508052624\n",
      "FOLD: 1, EPOCH: 54, valid_loss: 0.01760823352055417\n",
      "FOLD: 1, EPOCH: 55, train_loss: 0.017257774531120255\n",
      "FOLD: 1, EPOCH: 55, valid_loss: 0.017638371015588444\n",
      "FOLD: 1, EPOCH: 56, train_loss: 0.017154864281896623\n",
      "FOLD: 1, EPOCH: 56, valid_loss: 0.017616866984301142\n",
      "FOLD: 1, EPOCH: 57, train_loss: 0.0170844096810587\n",
      "FOLD: 1, EPOCH: 57, valid_loss: 0.017630225150949426\n",
      "FOLD: 1, EPOCH: 58, train_loss: 0.01701603149093928\n",
      "FOLD: 1, EPOCH: 58, valid_loss: 0.017628483939915895\n",
      "FOLD: 1, EPOCH: 59, train_loss: 0.01701431084544428\n",
      "FOLD: 1, EPOCH: 59, valid_loss: 0.017582053111659154\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6752366938898641\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.3666723271210988\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.06161864785657775\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.02119640799032317\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023251838056791214\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019899807456466887\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.023359230473156897\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.0193000885968407\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.022583017366067056\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.020921918770505324\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02129110203635308\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01840148690260119\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.020571883527501937\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018928761180076335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 7, train_loss: 0.02057334650908747\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017917666015111737\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020390889373037124\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.018011133910881147\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.020456016916901836\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.018820649219883814\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.020501302350913325\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01811650250520971\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.020472647333818098\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01824221144326859\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.02055318049125133\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018462394467658468\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.020563980997089417\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.018633714359667566\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.020665361756278623\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018475287697381444\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.020749232172966002\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01816687246577607\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.020705459747583636\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.018595205309490364\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.020843143256441238\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01823063236143854\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.020816116095069916\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.018369610317879252\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.020895830361593155\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.018456744857960276\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.020845989065785563\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.018261757161882188\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.020848460399335432\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.018600845709443092\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.020802747494270725\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018898970033559535\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.020797777644568874\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.018444944587018754\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.02087987324883861\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018198492626349132\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.02080559887953343\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.01841752665738265\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.02086830586194992\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.018398154940870073\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.020764856941757663\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01846663948769371\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.02079387278326096\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.01798374428310328\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.020708960703303737\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.01815962925967243\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.020585531140527417\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.01858647395339277\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.020547952611119517\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.01830066440420018\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.020548489882100014\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.01790149685823255\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.02041858612529693\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.017899367182205122\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.020320445275114427\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.018143233532706898\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.020315942624884266\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.017947729987402756\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.020113942928371892\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.017746882720126048\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.02014378300837932\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.01770085236057639\n",
      "FOLD: 2, EPOCH: 38, train_loss: 0.019966083260313156\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.017421155288401578\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.019807111964591086\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.017431296459916566\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.019759801787234122\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.01737445442833834\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.01947984688224331\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.01732993374268214\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.01933894495089208\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.017352959813757077\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.019246307303828578\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.01734343119379547\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.019096780532310086\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017303879527995985\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.018897345890441248\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.01734416548990541\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.0188412677737013\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.017194035980436537\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.0186005117672105\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.017228824500408437\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.018434797365578914\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.01713246251973841\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.01824846777824625\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.017270462690956064\n",
      "FOLD: 2, EPOCH: 50, train_loss: 0.01803943662633819\n",
      "FOLD: 2, EPOCH: 50, valid_loss: 0.017245787971963484\n",
      "FOLD: 2, EPOCH: 51, train_loss: 0.017871191304537556\n",
      "FOLD: 2, EPOCH: 51, valid_loss: 0.0172476254714032\n",
      "FOLD: 2, EPOCH: 52, train_loss: 0.017712391011657252\n",
      "FOLD: 2, EPOCH: 52, valid_loss: 0.017191085550520156\n",
      "FOLD: 2, EPOCH: 53, train_loss: 0.017563074106170286\n",
      "FOLD: 2, EPOCH: 53, valid_loss: 0.01724859264989694\n",
      "FOLD: 2, EPOCH: 54, train_loss: 0.01737215080328526\n",
      "FOLD: 2, EPOCH: 54, valid_loss: 0.017213619107173547\n",
      "FOLD: 2, EPOCH: 55, train_loss: 0.01724099796265364\n",
      "FOLD: 2, EPOCH: 55, valid_loss: 0.017257701450337965\n",
      "FOLD: 2, EPOCH: 56, train_loss: 0.017130776554826768\n",
      "FOLD: 2, EPOCH: 56, valid_loss: 0.017223404823905893\n",
      "FOLD: 2, EPOCH: 57, train_loss: 0.017130987219993146\n",
      "FOLD: 2, EPOCH: 57, valid_loss: 0.017276217747065756\n",
      "FOLD: 2, EPOCH: 58, train_loss: 0.017004114095001452\n",
      "FOLD: 2, EPOCH: 58, valid_loss: 0.01724423183542159\n",
      "FOLD: 2, EPOCH: 59, train_loss: 0.016992354350945642\n",
      "FOLD: 2, EPOCH: 59, valid_loss: 0.01725799548957083\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.675625144281695\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.34010546571678585\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.06110876019923918\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020150155035985842\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.023133252272682807\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018909210856590006\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.022665868206850945\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018087624261776607\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.02202403820570438\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.018340955384903483\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.021504685078417102\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.018338688752717443\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.02125009649222897\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.0179923625352482\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020671018645648034\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017686105591969356\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.02055595690204251\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01782974409353402\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.02059767380837471\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017659290021078453\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.020482025355581315\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01757877439053522\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.02058146516642263\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017900569985310238\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.02059942838405409\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017865224844879575\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.02064635795691321\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.018058874644339085\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.02066048698559884\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017638390366401937\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.020808095136477103\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017826471736447677\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.02077690862840222\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01823284953004784\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.02082250830867598\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01800175616517663\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.02084558388638881\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01806353565512432\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.020917303631863286\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01778540677494473\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020925607892774766\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.018563307511309784\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.02091162262424346\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.018215980225553114\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.02099222240428771\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.018049507919285033\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.020909746327707843\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01813609328948789\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.020856650305851814\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.018134454730898142\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.020887237066222777\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.017698797449055646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 26, train_loss: 0.02084048116399396\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.018449941287851997\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.020846107866494885\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.017882489909728367\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.020809654494927776\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.017750561340815492\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.020621529233551796\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.01763645699247718\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.020654110189887786\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.01766769929478566\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.020545379625212763\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.017462339200493362\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.02048983722925186\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.01767967755181922\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.02047251408859607\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.01771329322622882\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.02028415511933065\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.017672341782599688\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.020220584061837965\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.01723268214199278\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.020088093355298042\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.017297707808514435\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.01999558151489304\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.01713356515392661\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.019954989273701946\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.017101417243894603\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.019844995354933122\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.01708681069107519\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.019638916417475668\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.016896607406023476\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.019581593777383527\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.016948061891727977\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.019359188598971212\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.017054968151367374\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.019224999316277042\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.01695500159015258\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.019127472958737804\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.016982070222083066\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.018906890216373626\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.016919596224195428\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.018798194705478607\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.016757476040058665\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.018648943857800575\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.016983605455607176\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.018493686400113566\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.01680825873174601\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.018282884185112293\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.016771102738049295\n",
      "FOLD: 3, EPOCH: 50, train_loss: 0.01811717633278139\n",
      "FOLD: 3, EPOCH: 50, valid_loss: 0.01680764328274462\n",
      "FOLD: 3, EPOCH: 51, train_loss: 0.017927242442965508\n",
      "FOLD: 3, EPOCH: 51, valid_loss: 0.016670355728516977\n",
      "FOLD: 3, EPOCH: 52, train_loss: 0.017757947646802472\n",
      "FOLD: 3, EPOCH: 52, valid_loss: 0.016725561012410455\n",
      "FOLD: 3, EPOCH: 53, train_loss: 0.017636281876794755\n",
      "FOLD: 3, EPOCH: 53, valid_loss: 0.01672817368267311\n",
      "FOLD: 3, EPOCH: 54, train_loss: 0.017476559057831763\n",
      "FOLD: 3, EPOCH: 54, valid_loss: 0.01672348804357979\n",
      "FOLD: 3, EPOCH: 55, train_loss: 0.01732906681755858\n",
      "FOLD: 3, EPOCH: 55, valid_loss: 0.01674439266531004\n",
      "FOLD: 3, EPOCH: 56, train_loss: 0.01722562082352177\n",
      "FOLD: 3, EPOCH: 56, valid_loss: 0.016720593493017886\n",
      "FOLD: 3, EPOCH: 57, train_loss: 0.017214084933361698\n",
      "FOLD: 3, EPOCH: 57, valid_loss: 0.016735419682744477\n",
      "FOLD: 3, EPOCH: 58, train_loss: 0.017153487210312197\n",
      "FOLD: 3, EPOCH: 58, valid_loss: 0.016756404708657\n",
      "FOLD: 3, EPOCH: 59, train_loss: 0.017134188085554107\n",
      "FOLD: 3, EPOCH: 59, valid_loss: 0.01677144267078903\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6755685564010374\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.38078316549460095\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.06267501326097596\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.021038869188891515\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023235529396803147\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.020625830110576417\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.02257190957184761\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.024942942791514926\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.026687149859724507\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018177176722221904\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.021737295365141285\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.018126580139829054\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02098136278650453\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017462804603079956\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.020742682091170743\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017443354189809825\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.020384872344232374\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01748855205045806\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.02035459266795266\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018448822303778596\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020413180008049935\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01758111423502366\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.020418381282398777\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017887211094299953\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.020499256565686196\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017736638016584847\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.020598126034582814\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017860049071411293\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.020632897028999946\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017981639752785366\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.02074210169094224\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017791679439445336\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.020686464468317647\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017829277863105137\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.020743522432542617\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.017581165716465976\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.02075338861153972\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01799510678069459\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.02081648339667628\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01806841195664472\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.02085098573757756\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.017569996261348326\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.020907713184433598\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017887145177357726\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.020957656925724398\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01764095610835486\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.020872387446222766\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01741022973631819\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.020891859298271517\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.017353206924680207\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.020794962923372944\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.017730659805238247\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.020876349412625835\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.017788190860301256\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.02078392714742691\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.018156371182865567\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.020730060110649755\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.017747438098821375\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.02067025785724963\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01761238996146454\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.02072511520837584\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.017682062565452523\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.0206602088265842\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.01774429426425033\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.020443065596684334\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.017184357831461564\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.020512908408718725\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.017526317698260147\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.020328137987563687\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.017409107699576352\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.0202559003306012\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.016951886367880635\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.02018295464015776\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.017242825590074062\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.02004832341786354\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.01720833933601777\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.01990313627306492\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017103503406461742\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.019804801191053083\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.01731580330265893\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.019735617322787162\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.01708517109768258\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.019593219350903263\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.01683590007531974\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.019436066080966305\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.016903693477312725\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.019291212938485607\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.016757143299198814\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.019162515190339856\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.01686276314366195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4, EPOCH: 45, train_loss: 0.018986529616578932\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.016703256250669558\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.018882195975991986\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.01685729033003251\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.01870467464529699\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.016695009130570624\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.018501335490615136\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.01663444387829966\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.018309173216262173\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.016587712439811893\n",
      "FOLD: 4, EPOCH: 50, train_loss: 0.018156266693146\n",
      "FOLD: 4, EPOCH: 50, valid_loss: 0.016647345386445522\n",
      "FOLD: 4, EPOCH: 51, train_loss: 0.01792459794951062\n",
      "FOLD: 4, EPOCH: 51, valid_loss: 0.016747826244682074\n",
      "FOLD: 4, EPOCH: 52, train_loss: 0.01780501094556624\n",
      "FOLD: 4, EPOCH: 52, valid_loss: 0.01671736283848683\n",
      "FOLD: 4, EPOCH: 53, train_loss: 0.01764733141228076\n",
      "FOLD: 4, EPOCH: 53, valid_loss: 0.01664638565853238\n",
      "FOLD: 4, EPOCH: 54, train_loss: 0.017514333164980335\n",
      "FOLD: 4, EPOCH: 54, valid_loss: 0.016625561078803405\n",
      "FOLD: 4, EPOCH: 55, train_loss: 0.017358015075085626\n",
      "FOLD: 4, EPOCH: 55, valid_loss: 0.01661045668232772\n",
      "FOLD: 4, EPOCH: 56, train_loss: 0.017240349041117774\n",
      "FOLD: 4, EPOCH: 56, valid_loss: 0.016590122806115284\n",
      "FOLD: 4, EPOCH: 57, train_loss: 0.017147633757802747\n",
      "FOLD: 4, EPOCH: 57, valid_loss: 0.016623039833373494\n",
      "FOLD: 4, EPOCH: 58, train_loss: 0.0171283176829738\n",
      "FOLD: 4, EPOCH: 58, valid_loss: 0.01661357381898496\n",
      "FOLD: 4, EPOCH: 59, train_loss: 0.017135716770445147\n",
      "FOLD: 4, EPOCH: 59, valid_loss: 0.016571616443494957\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.6756647473381412\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.36433519257439506\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.06266603516715188\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.020104140767620668\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.023476399865842636\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.021918822183377214\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.022385041956459323\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.018669320580859978\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.028573678962645992\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.02308435955395301\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.022468990484072315\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.018831666972902086\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.021471272240723333\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.029618233649267092\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.022709239106024466\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.018963188346889284\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.021418311074376105\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.019417479841245547\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.021174498262905305\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.018773239726821583\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.02103102339371558\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.018861959377924602\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.021012034567613757\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.01915456789235274\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.020952831917712765\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.018815668403274484\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.020954038659411093\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.018772836567627058\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.02093356234892722\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.01868008253061109\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.020972343269855746\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.018719696750243504\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.020962318189201818\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.019236515793535445\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.020877588420144973\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.01856468990445137\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.02081226730538953\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.01895569802986251\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.020939481006033957\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.018755124260981876\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.02080030801796144\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.018993646423849795\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.020821541343485156\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.01888390402826998\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.02081767593420321\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.01891095108456082\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.020931651371140635\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.01884395598123471\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.020792517234240807\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.018740648093322914\n",
      "FOLD: 5, EPOCH: 25, train_loss: 0.02081204282660638\n",
      "FOLD: 5, EPOCH: 25, valid_loss: 0.018687940306133695\n",
      "FOLD: 5, EPOCH: 26, train_loss: 0.020769919635307405\n",
      "FOLD: 5, EPOCH: 26, valid_loss: 0.018828554078936577\n",
      "FOLD: 5, EPOCH: 27, train_loss: 0.02078712727994688\n",
      "FOLD: 5, EPOCH: 27, valid_loss: 0.018757549735407036\n",
      "FOLD: 5, EPOCH: 28, train_loss: 0.020675993103894494\n",
      "FOLD: 5, EPOCH: 28, valid_loss: 0.01885439683165815\n",
      "FOLD: 5, EPOCH: 29, train_loss: 0.02064429420617319\n",
      "FOLD: 5, EPOCH: 29, valid_loss: 0.0186162396437592\n",
      "FOLD: 5, EPOCH: 30, train_loss: 0.02058441386588158\n",
      "FOLD: 5, EPOCH: 30, valid_loss: 0.018942543512417212\n",
      "FOLD: 5, EPOCH: 31, train_loss: 0.020481668016122234\n",
      "FOLD: 5, EPOCH: 31, valid_loss: 0.018344571606980428\n",
      "FOLD: 5, EPOCH: 32, train_loss: 0.020341769864241924\n",
      "FOLD: 5, EPOCH: 32, valid_loss: 0.01840039399555988\n",
      "FOLD: 5, EPOCH: 33, train_loss: 0.02030558512816506\n",
      "FOLD: 5, EPOCH: 33, valid_loss: 0.018326416456451017\n",
      "FOLD: 5, EPOCH: 34, train_loss: 0.020105697977687083\n",
      "FOLD: 5, EPOCH: 34, valid_loss: 0.01819141674786806\n",
      "FOLD: 5, EPOCH: 35, train_loss: 0.020156691055144033\n",
      "FOLD: 5, EPOCH: 35, valid_loss: 0.018453418380684324\n",
      "FOLD: 5, EPOCH: 36, train_loss: 0.020005556099837826\n",
      "FOLD: 5, EPOCH: 36, valid_loss: 0.018190329790943198\n",
      "FOLD: 5, EPOCH: 37, train_loss: 0.019933426428225733\n",
      "FOLD: 5, EPOCH: 37, valid_loss: 0.018116619386192825\n",
      "FOLD: 5, EPOCH: 38, train_loss: 0.019759777759111696\n",
      "FOLD: 5, EPOCH: 38, valid_loss: 0.01781876731870903\n",
      "FOLD: 5, EPOCH: 39, train_loss: 0.019615201555913495\n",
      "FOLD: 5, EPOCH: 39, valid_loss: 0.017952232000728447\n",
      "FOLD: 5, EPOCH: 40, train_loss: 0.01955359292126471\n",
      "FOLD: 5, EPOCH: 40, valid_loss: 0.017834469210356474\n",
      "FOLD: 5, EPOCH: 41, train_loss: 0.019448164213568934\n",
      "FOLD: 5, EPOCH: 41, valid_loss: 0.017875731457024813\n",
      "FOLD: 5, EPOCH: 42, train_loss: 0.019266392999599057\n",
      "FOLD: 5, EPOCH: 42, valid_loss: 0.017971464639736548\n",
      "FOLD: 5, EPOCH: 43, train_loss: 0.019138201710677916\n",
      "FOLD: 5, EPOCH: 43, valid_loss: 0.01792187217829956\n",
      "FOLD: 5, EPOCH: 44, train_loss: 0.018947631613381446\n",
      "FOLD: 5, EPOCH: 44, valid_loss: 0.017928793250272673\n",
      "FOLD: 5, EPOCH: 45, train_loss: 0.018823488158804753\n",
      "FOLD: 5, EPOCH: 45, valid_loss: 0.0180980298254225\n",
      "FOLD: 5, EPOCH: 46, train_loss: 0.01863374531028732\n",
      "FOLD: 5, EPOCH: 46, valid_loss: 0.017906727734953165\n",
      "FOLD: 5, EPOCH: 47, train_loss: 0.018486511334776877\n",
      "FOLD: 5, EPOCH: 47, valid_loss: 0.01776498830359843\n",
      "FOLD: 5, EPOCH: 48, train_loss: 0.018324430106628327\n",
      "FOLD: 5, EPOCH: 48, valid_loss: 0.017821842131929264\n",
      "FOLD: 5, EPOCH: 49, train_loss: 0.018227883127908552\n",
      "FOLD: 5, EPOCH: 49, valid_loss: 0.0179214332666662\n",
      "FOLD: 5, EPOCH: 50, train_loss: 0.017964457462151206\n",
      "FOLD: 5, EPOCH: 50, valid_loss: 0.017819411173048947\n",
      "FOLD: 5, EPOCH: 51, train_loss: 0.017768277035605524\n",
      "FOLD: 5, EPOCH: 51, valid_loss: 0.017815162582943838\n",
      "FOLD: 5, EPOCH: 52, train_loss: 0.01758478608342909\n",
      "FOLD: 5, EPOCH: 52, valid_loss: 0.017816298537784152\n",
      "FOLD: 5, EPOCH: 53, train_loss: 0.017413730330524905\n",
      "FOLD: 5, EPOCH: 53, valid_loss: 0.017859161883178685\n",
      "FOLD: 5, EPOCH: 54, train_loss: 0.01727874658761486\n",
      "FOLD: 5, EPOCH: 54, valid_loss: 0.01780563515300552\n",
      "FOLD: 5, EPOCH: 55, train_loss: 0.01712441399332977\n",
      "FOLD: 5, EPOCH: 55, valid_loss: 0.017803026518474024\n",
      "FOLD: 5, EPOCH: 56, train_loss: 0.017005130468356992\n",
      "FOLD: 5, EPOCH: 56, valid_loss: 0.01781576473472847\n",
      "FOLD: 5, EPOCH: 57, train_loss: 0.016886056923577863\n",
      "FOLD: 5, EPOCH: 57, valid_loss: 0.017848122037119336\n",
      "FOLD: 5, EPOCH: 58, train_loss: 0.016803776899412756\n",
      "FOLD: 5, EPOCH: 58, valid_loss: 0.017810255702998903\n",
      "FOLD: 5, EPOCH: 59, train_loss: 0.01682085515630822\n",
      "FOLD: 5, EPOCH: 59, valid_loss: 0.017800374939623807\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.6758396537073197\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.3749273805057301\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.0614402323240234\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.02075567195082412\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.023087650453371387\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.019990771680193788\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.022354363782271264\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.019998301477993235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 6, EPOCH: 4, train_loss: 0.02292351428299181\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.019837432157467392\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.022026016094511554\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.01901882525314303\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.02092851015829271\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.018813810585176245\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.020736480744615676\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.018696682527661324\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.020563231048084076\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.018860522876767552\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.020587025739012225\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.018773564630571532\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.020700813168960233\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.019009607351001573\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.02062966944950242\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.01869216758538695\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.020660094207813662\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.018891887958435452\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.020720959755201492\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.01897027179160539\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.02073316054959451\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.019076171933728105\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.020743296211284977\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.018812175621004665\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.020858370885252952\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.018947630682412314\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.02073537530677934\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.01887526472701746\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.020768196964936873\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.018761691911255613\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.020758559014047346\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.019249208490638173\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.020819282904267312\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.019135278266142395\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.020899440985052815\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.018678850220406756\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.02081406636824531\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.01849079460782163\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.02086815640570656\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.019074940177447656\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.020776151505208784\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.018742934198063964\n",
      "FOLD: 6, EPOCH: 25, train_loss: 0.02072446372720503\n",
      "FOLD: 6, EPOCH: 25, valid_loss: 0.018833674709586537\n",
      "FOLD: 6, EPOCH: 26, train_loss: 0.020731649439661732\n",
      "FOLD: 6, EPOCH: 26, valid_loss: 0.019029062460450566\n",
      "FOLD: 6, EPOCH: 27, train_loss: 0.020652423078014005\n",
      "FOLD: 6, EPOCH: 27, valid_loss: 0.01878040481139632\n",
      "FOLD: 6, EPOCH: 28, train_loss: 0.020650232991864605\n",
      "FOLD: 6, EPOCH: 28, valid_loss: 0.018563181271447855\n",
      "FOLD: 6, EPOCH: 29, train_loss: 0.020618750215057404\n",
      "FOLD: 6, EPOCH: 29, valid_loss: 0.018588915357694906\n",
      "FOLD: 6, EPOCH: 30, train_loss: 0.020492466647298105\n",
      "FOLD: 6, EPOCH: 30, valid_loss: 0.018595714450759047\n",
      "FOLD: 6, EPOCH: 31, train_loss: 0.020494062393423048\n",
      "FOLD: 6, EPOCH: 31, valid_loss: 0.018572055132073516\n",
      "FOLD: 6, EPOCH: 32, train_loss: 0.020412623762123046\n",
      "FOLD: 6, EPOCH: 32, valid_loss: 0.018576268216266352\n",
      "FOLD: 6, EPOCH: 33, train_loss: 0.020316801989270796\n",
      "FOLD: 6, EPOCH: 33, valid_loss: 0.01885958793847\n",
      "FOLD: 6, EPOCH: 34, train_loss: 0.02020470669432994\n",
      "FOLD: 6, EPOCH: 34, valid_loss: 0.018456666839911658\n",
      "FOLD: 6, EPOCH: 35, train_loss: 0.020077243915969326\n",
      "FOLD: 6, EPOCH: 35, valid_loss: 0.01836589230772327\n",
      "FOLD: 6, EPOCH: 36, train_loss: 0.020007503140837917\n",
      "FOLD: 6, EPOCH: 36, valid_loss: 0.018369884613682243\n",
      "FOLD: 6, EPOCH: 37, train_loss: 0.019936005026102065\n",
      "FOLD: 6, EPOCH: 37, valid_loss: 0.01828916124342119\n",
      "FOLD: 6, EPOCH: 38, train_loss: 0.01980350080036348\n",
      "FOLD: 6, EPOCH: 38, valid_loss: 0.018117253175553155\n",
      "FOLD: 6, EPOCH: 39, train_loss: 0.019722941253454456\n",
      "FOLD: 6, EPOCH: 39, valid_loss: 0.018280134591109613\n",
      "FOLD: 6, EPOCH: 40, train_loss: 0.019587566823728624\n",
      "FOLD: 6, EPOCH: 40, valid_loss: 0.018076549558078542\n",
      "FOLD: 6, EPOCH: 41, train_loss: 0.019447641627442454\n",
      "FOLD: 6, EPOCH: 41, valid_loss: 0.01804864395628957\n",
      "FOLD: 6, EPOCH: 42, train_loss: 0.01932345340929685\n",
      "FOLD: 6, EPOCH: 42, valid_loss: 0.017998968689318967\n",
      "FOLD: 6, EPOCH: 43, train_loss: 0.01917432354342553\n",
      "FOLD: 6, EPOCH: 43, valid_loss: 0.017937461133388913\n",
      "FOLD: 6, EPOCH: 44, train_loss: 0.018982909896200703\n",
      "FOLD: 6, EPOCH: 44, valid_loss: 0.01798739580108839\n",
      "FOLD: 6, EPOCH: 45, train_loss: 0.018889543396090308\n",
      "FOLD: 6, EPOCH: 45, valid_loss: 0.017761520000503343\n",
      "FOLD: 6, EPOCH: 46, train_loss: 0.018718635963816798\n",
      "FOLD: 6, EPOCH: 46, valid_loss: 0.017890149179626915\n",
      "FOLD: 6, EPOCH: 47, train_loss: 0.01858907950621459\n",
      "FOLD: 6, EPOCH: 47, valid_loss: 0.017863690688767853\n",
      "FOLD: 6, EPOCH: 48, train_loss: 0.01835606057317026\n",
      "FOLD: 6, EPOCH: 48, valid_loss: 0.017753596362822196\n",
      "FOLD: 6, EPOCH: 49, train_loss: 0.01822485862480056\n",
      "FOLD: 6, EPOCH: 49, valid_loss: 0.01782334891750532\n",
      "FOLD: 6, EPOCH: 50, train_loss: 0.01806537669993216\n",
      "FOLD: 6, EPOCH: 50, valid_loss: 0.017706370309871787\n",
      "FOLD: 6, EPOCH: 51, train_loss: 0.017890082401854378\n",
      "FOLD: 6, EPOCH: 51, valid_loss: 0.017882133834064007\n",
      "FOLD: 6, EPOCH: 52, train_loss: 0.01772904343182041\n",
      "FOLD: 6, EPOCH: 52, valid_loss: 0.017715308705673498\n",
      "FOLD: 6, EPOCH: 53, train_loss: 0.017567837725002918\n",
      "FOLD: 6, EPOCH: 53, valid_loss: 0.017716114025782135\n",
      "FOLD: 6, EPOCH: 54, train_loss: 0.01739473839200312\n",
      "FOLD: 6, EPOCH: 54, valid_loss: 0.01769528554423767\n",
      "FOLD: 6, EPOCH: 55, train_loss: 0.01729892214700099\n",
      "FOLD: 6, EPOCH: 55, valid_loss: 0.01775879002011874\n",
      "FOLD: 6, EPOCH: 56, train_loss: 0.01720859812152001\n",
      "FOLD: 6, EPOCH: 56, valid_loss: 0.017708334962234777\n",
      "FOLD: 6, EPOCH: 57, train_loss: 0.017125562073722962\n",
      "FOLD: 6, EPOCH: 57, valid_loss: 0.017745282610549647\n",
      "FOLD: 6, EPOCH: 58, train_loss: 0.01709268552161032\n",
      "FOLD: 6, EPOCH: 58, valid_loss: 0.01773228989366223\n",
      "FOLD: 6, EPOCH: 59, train_loss: 0.017040585828644615\n",
      "FOLD: 6, EPOCH: 59, valid_loss: 0.017706650144913617\n",
      "FOLD: 7, EPOCH: 0, train_loss: 0.6757628335106758\n",
      "FOLD: 7, EPOCH: 0, valid_loss: 0.35694783575394573\n",
      "FOLD: 7, EPOCH: 1, train_loss: 0.061805144709444815\n",
      "FOLD: 7, EPOCH: 1, valid_loss: 0.020439121653051937\n",
      "FOLD: 7, EPOCH: 2, train_loss: 0.023192926243908944\n",
      "FOLD: 7, EPOCH: 2, valid_loss: 0.018740942592129987\n",
      "FOLD: 7, EPOCH: 3, train_loss: 0.023062222294749753\n",
      "FOLD: 7, EPOCH: 3, valid_loss: 0.01851856357911054\n",
      "FOLD: 7, EPOCH: 4, train_loss: 0.02179688651475214\n",
      "FOLD: 7, EPOCH: 4, valid_loss: 0.01825876391547568\n",
      "FOLD: 7, EPOCH: 5, train_loss: 0.02318564465930385\n",
      "FOLD: 7, EPOCH: 5, valid_loss: 0.01808201357284013\n",
      "FOLD: 7, EPOCH: 6, train_loss: 0.021202762328809306\n",
      "FOLD: 7, EPOCH: 6, valid_loss: 0.018138494999969706\n",
      "FOLD: 7, EPOCH: 7, train_loss: 0.020831536970311596\n",
      "FOLD: 7, EPOCH: 7, valid_loss: 0.018046808812548134\n",
      "FOLD: 7, EPOCH: 8, train_loss: 0.020707739757434014\n",
      "FOLD: 7, EPOCH: 8, valid_loss: 0.017989626921275082\n",
      "FOLD: 7, EPOCH: 9, train_loss: 0.020639484435800583\n",
      "FOLD: 7, EPOCH: 9, valid_loss: 0.018019635559004897\n",
      "FOLD: 7, EPOCH: 10, train_loss: 0.020602903503083414\n",
      "FOLD: 7, EPOCH: 10, valid_loss: 0.017997466904275557\n",
      "FOLD: 7, EPOCH: 11, train_loss: 0.020601826870153026\n",
      "FOLD: 7, EPOCH: 11, valid_loss: 0.017933112295234904\n",
      "FOLD: 7, EPOCH: 12, train_loss: 0.020660014162140507\n",
      "FOLD: 7, EPOCH: 12, valid_loss: 0.018108762581558788\n",
      "FOLD: 7, EPOCH: 13, train_loss: 0.020702841913988513\n",
      "FOLD: 7, EPOCH: 13, valid_loss: 0.017936853911070264\n",
      "FOLD: 7, EPOCH: 14, train_loss: 0.020765469055021964\n",
      "FOLD: 7, EPOCH: 14, valid_loss: 0.018318597775171783\n",
      "FOLD: 7, EPOCH: 15, train_loss: 0.020686946184404434\n",
      "FOLD: 7, EPOCH: 15, valid_loss: 0.01808031659354182\n",
      "FOLD: 7, EPOCH: 16, train_loss: 0.020850880371947444\n",
      "FOLD: 7, EPOCH: 16, valid_loss: 0.018153773620724678\n",
      "FOLD: 7, EPOCH: 17, train_loss: 0.02074795219927065\n",
      "FOLD: 7, EPOCH: 17, valid_loss: 0.01799599563374239\n",
      "FOLD: 7, EPOCH: 18, train_loss: 0.02081690118197472\n",
      "FOLD: 7, EPOCH: 18, valid_loss: 0.01820225312429316\n",
      "FOLD: 7, EPOCH: 19, train_loss: 0.02086175646512739\n",
      "FOLD: 7, EPOCH: 19, valid_loss: 0.018077167298863914\n",
      "FOLD: 7, EPOCH: 20, train_loss: 0.02082000935990964\n",
      "FOLD: 7, EPOCH: 20, valid_loss: 0.018270657781292412\n",
      "FOLD: 7, EPOCH: 21, train_loss: 0.02080079919147876\n",
      "FOLD: 7, EPOCH: 21, valid_loss: 0.01821158793480957\n",
      "FOLD: 7, EPOCH: 22, train_loss: 0.020832944925754302\n",
      "FOLD: 7, EPOCH: 22, valid_loss: 0.018193940138992143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 7, EPOCH: 23, train_loss: 0.020828222447345335\n",
      "FOLD: 7, EPOCH: 23, valid_loss: 0.01812848963719957\n",
      "FOLD: 7, EPOCH: 24, train_loss: 0.02075563059939492\n",
      "FOLD: 7, EPOCH: 24, valid_loss: 0.01807088656898807\n",
      "FOLD: 7, EPOCH: 25, train_loss: 0.020784623488303153\n",
      "FOLD: 7, EPOCH: 25, valid_loss: 0.017846243346438688\n",
      "FOLD: 7, EPOCH: 26, train_loss: 0.020748439599429406\n",
      "FOLD: 7, EPOCH: 26, valid_loss: 0.0182794557117364\n",
      "FOLD: 7, EPOCH: 27, train_loss: 0.020716868136678973\n",
      "FOLD: 7, EPOCH: 27, valid_loss: 0.01811781372217571\n",
      "FOLD: 7, EPOCH: 28, train_loss: 0.020664076338852606\n",
      "FOLD: 7, EPOCH: 28, valid_loss: 0.01817984484574374\n",
      "FOLD: 7, EPOCH: 29, train_loss: 0.020535692608644886\n",
      "FOLD: 7, EPOCH: 29, valid_loss: 0.017797865630949244\n",
      "FOLD: 7, EPOCH: 30, train_loss: 0.020510178299680833\n",
      "FOLD: 7, EPOCH: 30, valid_loss: 0.017894168110454783\n",
      "FOLD: 7, EPOCH: 31, train_loss: 0.020492020790134707\n",
      "FOLD: 7, EPOCH: 31, valid_loss: 0.017646851675475344\n",
      "FOLD: 7, EPOCH: 32, train_loss: 0.02042762416024362\n",
      "FOLD: 7, EPOCH: 32, valid_loss: 0.017889433266485438\n",
      "FOLD: 7, EPOCH: 33, train_loss: 0.020314340041049064\n",
      "FOLD: 7, EPOCH: 33, valid_loss: 0.017748654765241286\n",
      "FOLD: 7, EPOCH: 34, train_loss: 0.020195107858988547\n",
      "FOLD: 7, EPOCH: 34, valid_loss: 0.017694161657024834\n",
      "FOLD: 7, EPOCH: 35, train_loss: 0.02010520557242055\n",
      "FOLD: 7, EPOCH: 35, valid_loss: 0.01767967707094024\n",
      "FOLD: 7, EPOCH: 36, train_loss: 0.020077004247615413\n",
      "FOLD: 7, EPOCH: 36, valid_loss: 0.017541789997588184\n",
      "FOLD: 7, EPOCH: 37, train_loss: 0.01994648604623733\n",
      "FOLD: 7, EPOCH: 37, valid_loss: 0.017620504778974196\n",
      "FOLD: 7, EPOCH: 38, train_loss: 0.019847766538300823\n",
      "FOLD: 7, EPOCH: 38, valid_loss: 0.01733286859577193\n",
      "FOLD: 7, EPOCH: 39, train_loss: 0.019689543701467974\n",
      "FOLD: 7, EPOCH: 39, valid_loss: 0.017617368961081785\n",
      "FOLD: 7, EPOCH: 40, train_loss: 0.019605475664138793\n",
      "FOLD: 7, EPOCH: 40, valid_loss: 0.017298020860728097\n",
      "FOLD: 7, EPOCH: 41, train_loss: 0.019426346341929128\n",
      "FOLD: 7, EPOCH: 41, valid_loss: 0.017367718083893553\n",
      "FOLD: 7, EPOCH: 42, train_loss: 0.01934141210250316\n",
      "FOLD: 7, EPOCH: 42, valid_loss: 0.017408540691522992\n",
      "FOLD: 7, EPOCH: 43, train_loss: 0.019178037177170478\n",
      "FOLD: 7, EPOCH: 43, valid_loss: 0.017364805728635368\n",
      "FOLD: 7, EPOCH: 44, train_loss: 0.01903173103928566\n",
      "FOLD: 7, EPOCH: 44, valid_loss: 0.017219200456405386\n",
      "FOLD: 7, EPOCH: 45, train_loss: 0.01885116829747154\n",
      "FOLD: 7, EPOCH: 45, valid_loss: 0.017238344723249182\n",
      "FOLD: 7, EPOCH: 46, train_loss: 0.01871626785685939\n",
      "FOLD: 7, EPOCH: 46, valid_loss: 0.01696157460922704\n",
      "FOLD: 7, EPOCH: 47, train_loss: 0.018570327254072313\n",
      "FOLD: 7, EPOCH: 47, valid_loss: 0.017155181123491597\n",
      "FOLD: 7, EPOCH: 48, train_loss: 0.01841377432067548\n",
      "FOLD: 7, EPOCH: 48, valid_loss: 0.017152890069958043\n",
      "FOLD: 7, EPOCH: 49, train_loss: 0.018180636166324537\n",
      "FOLD: 7, EPOCH: 49, valid_loss: 0.017071678303182125\n",
      "FOLD: 7, EPOCH: 50, train_loss: 0.018047512725235953\n",
      "FOLD: 7, EPOCH: 50, valid_loss: 0.01702034566551447\n",
      "FOLD: 7, EPOCH: 51, train_loss: 0.017903511442484393\n",
      "FOLD: 7, EPOCH: 51, valid_loss: 0.017044123316950658\n",
      "FOLD: 7, EPOCH: 52, train_loss: 0.01769283163932062\n",
      "FOLD: 7, EPOCH: 52, valid_loss: 0.017084388226708946\n",
      "FOLD: 7, EPOCH: 53, train_loss: 0.017577637065081825\n",
      "FOLD: 7, EPOCH: 53, valid_loss: 0.01707702168427846\n",
      "FOLD: 7, EPOCH: 54, train_loss: 0.017424950141820217\n",
      "FOLD: 7, EPOCH: 54, valid_loss: 0.017062787185696995\n",
      "FOLD: 7, EPOCH: 55, train_loss: 0.017326782475556097\n",
      "FOLD: 7, EPOCH: 55, valid_loss: 0.017038564033368054\n",
      "FOLD: 7, EPOCH: 56, train_loss: 0.01723050223963876\n",
      "FOLD: 7, EPOCH: 56, valid_loss: 0.017048821784555912\n",
      "FOLD: 7, EPOCH: 57, train_loss: 0.017129751559226743\n",
      "FOLD: 7, EPOCH: 57, valid_loss: 0.01705004373455749\n",
      "FOLD: 7, EPOCH: 58, train_loss: 0.0171011999009117\n",
      "FOLD: 7, EPOCH: 58, valid_loss: 0.017053078640909755\n",
      "FOLD: 7, EPOCH: 59, train_loss: 0.017093221266423504\n",
      "FOLD: 7, EPOCH: 59, valid_loss: 0.017067157992107028\n",
      "FOLD: 8, EPOCH: 0, train_loss: 0.6755769927655497\n",
      "FOLD: 8, EPOCH: 0, valid_loss: 0.3546735561556286\n",
      "FOLD: 8, EPOCH: 1, train_loss: 0.061393479005463665\n",
      "FOLD: 8, EPOCH: 1, valid_loss: 0.020311954327755503\n",
      "FOLD: 8, EPOCH: 2, train_loss: 0.023085674186868053\n",
      "FOLD: 8, EPOCH: 2, valid_loss: 0.01909027885024746\n",
      "FOLD: 8, EPOCH: 3, train_loss: 0.02215589235626882\n",
      "FOLD: 8, EPOCH: 3, valid_loss: 0.017970862953613203\n",
      "FOLD: 8, EPOCH: 4, train_loss: 0.02196367372788729\n",
      "FOLD: 8, EPOCH: 4, valid_loss: 0.017733812901294894\n",
      "FOLD: 8, EPOCH: 5, train_loss: 0.020524197744746363\n",
      "FOLD: 8, EPOCH: 5, valid_loss: 0.017653018805301852\n",
      "FOLD: 8, EPOCH: 6, train_loss: 0.021569539618588263\n",
      "FOLD: 8, EPOCH: 6, valid_loss: 0.020041779408024415\n",
      "FOLD: 8, EPOCH: 7, train_loss: 0.020665029604588787\n",
      "FOLD: 8, EPOCH: 7, valid_loss: 0.018004687709940806\n",
      "FOLD: 8, EPOCH: 8, train_loss: 0.02056041432003821\n",
      "FOLD: 8, EPOCH: 8, valid_loss: 0.017968487925827503\n",
      "FOLD: 8, EPOCH: 9, train_loss: 0.02052683866312427\n",
      "FOLD: 8, EPOCH: 9, valid_loss: 0.017584649432036612\n",
      "FOLD: 8, EPOCH: 10, train_loss: 0.02054990753531456\n",
      "FOLD: 8, EPOCH: 10, valid_loss: 0.01787616415984101\n",
      "FOLD: 8, EPOCH: 11, train_loss: 0.020587720349431037\n",
      "FOLD: 8, EPOCH: 11, valid_loss: 0.017922703383697405\n",
      "FOLD: 8, EPOCH: 12, train_loss: 0.020540926857821402\n",
      "FOLD: 8, EPOCH: 12, valid_loss: 0.017827512023763523\n",
      "FOLD: 8, EPOCH: 13, train_loss: 0.020549944764183415\n",
      "FOLD: 8, EPOCH: 13, valid_loss: 0.018100070922325056\n",
      "FOLD: 8, EPOCH: 14, train_loss: 0.020667848375535782\n",
      "FOLD: 8, EPOCH: 14, valid_loss: 0.018079592277192406\n",
      "FOLD: 8, EPOCH: 15, train_loss: 0.020678819055038114\n",
      "FOLD: 8, EPOCH: 15, valid_loss: 0.017964944450391665\n",
      "FOLD: 8, EPOCH: 16, train_loss: 0.02083613341373782\n",
      "FOLD: 8, EPOCH: 16, valid_loss: 0.01823091646656394\n",
      "FOLD: 8, EPOCH: 17, train_loss: 0.020776837078794356\n",
      "FOLD: 8, EPOCH: 17, valid_loss: 0.018079537846561935\n",
      "FOLD: 8, EPOCH: 18, train_loss: 0.020834368623552785\n",
      "FOLD: 8, EPOCH: 18, valid_loss: 0.01827530459397369\n",
      "FOLD: 8, EPOCH: 19, train_loss: 0.0208591538331201\n",
      "FOLD: 8, EPOCH: 19, valid_loss: 0.01799974088660545\n",
      "FOLD: 8, EPOCH: 20, train_loss: 0.020876506655927628\n",
      "FOLD: 8, EPOCH: 20, valid_loss: 0.017962917478548154\n",
      "FOLD: 8, EPOCH: 21, train_loss: 0.020830835089568168\n",
      "FOLD: 8, EPOCH: 21, valid_loss: 0.018433107528835535\n",
      "FOLD: 8, EPOCH: 22, train_loss: 0.020900132579188192\n",
      "FOLD: 8, EPOCH: 22, valid_loss: 0.017799609288987186\n",
      "FOLD: 8, EPOCH: 23, train_loss: 0.02081135207366559\n",
      "FOLD: 8, EPOCH: 23, valid_loss: 0.017861178558733728\n",
      "FOLD: 8, EPOCH: 24, train_loss: 0.020840629694923278\n",
      "FOLD: 8, EPOCH: 24, valid_loss: 0.0184320701389677\n",
      "FOLD: 8, EPOCH: 25, train_loss: 0.020809340981706496\n",
      "FOLD: 8, EPOCH: 25, valid_loss: 0.01777928213899334\n",
      "FOLD: 8, EPOCH: 26, train_loss: 0.02075774395658124\n",
      "FOLD: 8, EPOCH: 26, valid_loss: 0.018047446022844978\n",
      "FOLD: 8, EPOCH: 27, train_loss: 0.020738648695330465\n",
      "FOLD: 8, EPOCH: 27, valid_loss: 0.018023873265418742\n",
      "FOLD: 8, EPOCH: 28, train_loss: 0.020733892761411205\n",
      "FOLD: 8, EPOCH: 28, valid_loss: 0.017855573290338118\n",
      "FOLD: 8, EPOCH: 29, train_loss: 0.020606925290438435\n",
      "FOLD: 8, EPOCH: 29, valid_loss: 0.018109036195609305\n",
      "FOLD: 8, EPOCH: 30, train_loss: 0.020541951805353165\n",
      "FOLD: 8, EPOCH: 30, valid_loss: 0.01805432280525565\n",
      "FOLD: 8, EPOCH: 31, train_loss: 0.020472059759401504\n",
      "FOLD: 8, EPOCH: 31, valid_loss: 0.018032312496668763\n",
      "FOLD: 8, EPOCH: 32, train_loss: 0.020452647668219383\n",
      "FOLD: 8, EPOCH: 32, valid_loss: 0.01774659028483762\n",
      "FOLD: 8, EPOCH: 33, train_loss: 0.020333372477081516\n",
      "FOLD: 8, EPOCH: 33, valid_loss: 0.0178446256969538\n",
      "FOLD: 8, EPOCH: 34, train_loss: 0.020244845844084217\n",
      "FOLD: 8, EPOCH: 34, valid_loss: 0.017510959982044168\n",
      "FOLD: 8, EPOCH: 35, train_loss: 0.020167440151976\n",
      "FOLD: 8, EPOCH: 35, valid_loss: 0.01740312845342689\n",
      "FOLD: 8, EPOCH: 36, train_loss: 0.020060202515413683\n",
      "FOLD: 8, EPOCH: 36, valid_loss: 0.017526166513562202\n",
      "FOLD: 8, EPOCH: 37, train_loss: 0.019970612179848454\n",
      "FOLD: 8, EPOCH: 37, valid_loss: 0.01738085721929868\n",
      "FOLD: 8, EPOCH: 38, train_loss: 0.019791523817806474\n",
      "FOLD: 8, EPOCH: 38, valid_loss: 0.01747910010938843\n",
      "FOLD: 8, EPOCH: 39, train_loss: 0.019728088330837987\n",
      "FOLD: 8, EPOCH: 39, valid_loss: 0.017317511037819915\n",
      "FOLD: 8, EPOCH: 40, train_loss: 0.01959848375089707\n",
      "FOLD: 8, EPOCH: 40, valid_loss: 0.01732936304890447\n",
      "FOLD: 8, EPOCH: 41, train_loss: 0.01950824510666632\n",
      "FOLD: 8, EPOCH: 41, valid_loss: 0.017111216930465564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 8, EPOCH: 42, train_loss: 0.019337164790880296\n",
      "FOLD: 8, EPOCH: 42, valid_loss: 0.017162905540317297\n",
      "FOLD: 8, EPOCH: 43, train_loss: 0.01920184342851562\n",
      "FOLD: 8, EPOCH: 43, valid_loss: 0.017149380925628874\n",
      "FOLD: 8, EPOCH: 44, train_loss: 0.01906761333586708\n",
      "FOLD: 8, EPOCH: 44, valid_loss: 0.01722890531851186\n",
      "FOLD: 8, EPOCH: 45, train_loss: 0.018913430816704227\n",
      "FOLD: 8, EPOCH: 45, valid_loss: 0.017134802002045844\n",
      "FOLD: 8, EPOCH: 46, train_loss: 0.018737957524436136\n",
      "FOLD: 8, EPOCH: 46, valid_loss: 0.017407249400599137\n",
      "FOLD: 8, EPOCH: 47, train_loss: 0.018568944888970543\n",
      "FOLD: 8, EPOCH: 47, valid_loss: 0.01703945862957173\n",
      "FOLD: 8, EPOCH: 48, train_loss: 0.018398439679895677\n",
      "FOLD: 8, EPOCH: 48, valid_loss: 0.01697319730495413\n",
      "FOLD: 8, EPOCH: 49, train_loss: 0.018221941001472935\n",
      "FOLD: 8, EPOCH: 49, valid_loss: 0.017065870420386393\n",
      "FOLD: 8, EPOCH: 50, train_loss: 0.018041996766001947\n",
      "FOLD: 8, EPOCH: 50, valid_loss: 0.017023408216320805\n",
      "FOLD: 8, EPOCH: 51, train_loss: 0.017914542609885814\n",
      "FOLD: 8, EPOCH: 51, valid_loss: 0.0170577481492526\n",
      "FOLD: 8, EPOCH: 52, train_loss: 0.017731744002911352\n",
      "FOLD: 8, EPOCH: 52, valid_loss: 0.017067259694967005\n",
      "FOLD: 8, EPOCH: 53, train_loss: 0.017602777553181494\n",
      "FOLD: 8, EPOCH: 53, valid_loss: 0.017030093560202256\n",
      "FOLD: 8, EPOCH: 54, train_loss: 0.017450480962232236\n",
      "FOLD: 8, EPOCH: 54, valid_loss: 0.017060359267310962\n",
      "FOLD: 8, EPOCH: 55, train_loss: 0.01730084791779518\n",
      "FOLD: 8, EPOCH: 55, valid_loss: 0.017051047024627525\n",
      "FOLD: 8, EPOCH: 56, train_loss: 0.017273570212625686\n",
      "FOLD: 8, EPOCH: 56, valid_loss: 0.01704480964690447\n",
      "FOLD: 8, EPOCH: 57, train_loss: 0.017161300381825815\n",
      "FOLD: 8, EPOCH: 57, valid_loss: 0.017045530542317364\n",
      "FOLD: 8, EPOCH: 58, train_loss: 0.017132017473059317\n",
      "FOLD: 8, EPOCH: 58, valid_loss: 0.017046541027310822\n",
      "FOLD: 8, EPOCH: 59, train_loss: 0.01715083268861617\n",
      "FOLD: 8, EPOCH: 59, valid_loss: 0.017082745830218\n",
      "FOLD: 9, EPOCH: 0, train_loss: 0.6770975878161769\n",
      "FOLD: 9, EPOCH: 0, valid_loss: 0.38059546384546494\n",
      "FOLD: 9, EPOCH: 1, train_loss: 0.06512712211378159\n",
      "FOLD: 9, EPOCH: 1, valid_loss: 0.020794759711457625\n",
      "FOLD: 9, EPOCH: 2, train_loss: 0.023875850451088722\n",
      "FOLD: 9, EPOCH: 2, valid_loss: 0.02038391948574119\n",
      "FOLD: 9, EPOCH: 3, train_loss: 0.02410952168847284\n",
      "FOLD: 9, EPOCH: 3, valid_loss: 0.03207534831017256\n",
      "FOLD: 9, EPOCH: 4, train_loss: 0.023289805578608668\n",
      "FOLD: 9, EPOCH: 4, valid_loss: 0.028145964671340253\n",
      "FOLD: 9, EPOCH: 5, train_loss: 0.02153105423335106\n",
      "FOLD: 9, EPOCH: 5, valid_loss: 0.02105020224634144\n",
      "FOLD: 9, EPOCH: 6, train_loss: 0.020806715961906218\n",
      "FOLD: 9, EPOCH: 6, valid_loss: 0.01835889524469773\n",
      "FOLD: 9, EPOCH: 7, train_loss: 0.02053015746416584\n",
      "FOLD: 9, EPOCH: 7, valid_loss: 0.01790564672814475\n",
      "FOLD: 9, EPOCH: 8, train_loss: 0.020315300523033066\n",
      "FOLD: 9, EPOCH: 8, valid_loss: 0.017352708822323218\n",
      "FOLD: 9, EPOCH: 9, train_loss: 0.020201868419685673\n",
      "FOLD: 9, EPOCH: 9, valid_loss: 0.019161424910028774\n",
      "FOLD: 9, EPOCH: 10, train_loss: 0.0203345786419607\n",
      "FOLD: 9, EPOCH: 10, valid_loss: 0.018158487561676238\n",
      "FOLD: 9, EPOCH: 11, train_loss: 0.02048533194728436\n",
      "FOLD: 9, EPOCH: 11, valid_loss: 0.020262837720414\n",
      "FOLD: 9, EPOCH: 12, train_loss: 0.020548777895108346\n",
      "FOLD: 9, EPOCH: 12, valid_loss: 0.019656546413898468\n",
      "FOLD: 9, EPOCH: 13, train_loss: 0.020396390184760093\n",
      "FOLD: 9, EPOCH: 13, valid_loss: 0.017685108197232086\n",
      "FOLD: 9, EPOCH: 14, train_loss: 0.020371331508842207\n",
      "FOLD: 9, EPOCH: 14, valid_loss: 0.017435137803355854\n",
      "FOLD: 9, EPOCH: 15, train_loss: 0.02053716552834357\n",
      "FOLD: 9, EPOCH: 15, valid_loss: 0.017863179970946576\n",
      "FOLD: 9, EPOCH: 16, train_loss: 0.020469762156567265\n",
      "FOLD: 9, EPOCH: 16, valid_loss: 0.01763453572574589\n",
      "FOLD: 9, EPOCH: 17, train_loss: 0.02065395140239308\n",
      "FOLD: 9, EPOCH: 17, valid_loss: 0.018085244422157604\n",
      "FOLD: 9, EPOCH: 18, train_loss: 0.020576107201557007\n",
      "FOLD: 9, EPOCH: 18, valid_loss: 0.017969463641444843\n",
      "FOLD: 9, EPOCH: 19, train_loss: 0.020580214129820945\n",
      "FOLD: 9, EPOCH: 19, valid_loss: 0.01843268351836337\n",
      "FOLD: 9, EPOCH: 20, train_loss: 0.020568379916010366\n",
      "FOLD: 9, EPOCH: 20, valid_loss: 0.01853222803523143\n",
      "FOLD: 9, EPOCH: 21, train_loss: 0.020773077948439505\n",
      "FOLD: 9, EPOCH: 21, valid_loss: 0.018167707448204357\n",
      "FOLD: 9, EPOCH: 22, train_loss: 0.020907897201757276\n",
      "FOLD: 9, EPOCH: 22, valid_loss: 0.018778982054856088\n",
      "FOLD: 9, EPOCH: 23, train_loss: 0.02084096454744858\n",
      "FOLD: 9, EPOCH: 23, valid_loss: 0.017423607719441254\n",
      "FOLD: 9, EPOCH: 24, train_loss: 0.020579012447307185\n",
      "FOLD: 9, EPOCH: 24, valid_loss: 0.017627176000840135\n",
      "FOLD: 9, EPOCH: 25, train_loss: 0.020601149149719746\n",
      "FOLD: 9, EPOCH: 25, valid_loss: 0.017911457663608923\n",
      "FOLD: 9, EPOCH: 26, train_loss: 0.020559645239864626\n",
      "FOLD: 9, EPOCH: 26, valid_loss: 0.0180187506808175\n",
      "FOLD: 9, EPOCH: 27, train_loss: 0.020737633902219034\n",
      "FOLD: 9, EPOCH: 27, valid_loss: 0.017908309793306723\n",
      "FOLD: 9, EPOCH: 28, train_loss: 0.020771905900009217\n",
      "FOLD: 9, EPOCH: 28, valid_loss: 0.01731381110019154\n",
      "FOLD: 9, EPOCH: 29, train_loss: 0.020567018033996704\n",
      "FOLD: 9, EPOCH: 29, valid_loss: 0.01765683169166247\n",
      "FOLD: 9, EPOCH: 30, train_loss: 0.020684107813623644\n",
      "FOLD: 9, EPOCH: 30, valid_loss: 0.017430443006257217\n",
      "FOLD: 9, EPOCH: 31, train_loss: 0.020468728484645968\n",
      "FOLD: 9, EPOCH: 31, valid_loss: 0.01739575206819508\n",
      "FOLD: 9, EPOCH: 32, train_loss: 0.020398564985202206\n",
      "FOLD: 9, EPOCH: 32, valid_loss: 0.01722781825810671\n",
      "FOLD: 9, EPOCH: 33, train_loss: 0.020184133129735146\n",
      "FOLD: 9, EPOCH: 33, valid_loss: 0.017189883833958045\n",
      "FOLD: 9, EPOCH: 34, train_loss: 0.020101012463771526\n",
      "FOLD: 9, EPOCH: 34, valid_loss: 0.017219025279498763\n",
      "FOLD: 9, EPOCH: 35, train_loss: 0.02003011475166967\n",
      "FOLD: 9, EPOCH: 35, valid_loss: 0.017155804412646428\n",
      "FOLD: 9, EPOCH: 36, train_loss: 0.019932246027934936\n",
      "FOLD: 9, EPOCH: 36, valid_loss: 0.017131138334257737\n",
      "FOLD: 9, EPOCH: 37, train_loss: 0.020030319510448362\n",
      "FOLD: 9, EPOCH: 37, valid_loss: 0.01709865007756485\n",
      "FOLD: 9, EPOCH: 38, train_loss: 0.019816961523986633\n",
      "FOLD: 9, EPOCH: 38, valid_loss: 0.017160071060061455\n",
      "FOLD: 9, EPOCH: 39, train_loss: 0.02018226314215891\n",
      "FOLD: 9, EPOCH: 39, valid_loss: 0.017126362615575392\n",
      "FOLD: 9, EPOCH: 40, train_loss: 0.019855127964288958\n",
      "FOLD: 9, EPOCH: 40, valid_loss: 0.017112961504608393\n",
      "FOLD: 9, EPOCH: 41, train_loss: 0.01973685154751424\n",
      "FOLD: 9, EPOCH: 41, valid_loss: 0.016821274326907262\n",
      "FOLD: 9, EPOCH: 42, train_loss: 0.019554286630403612\n",
      "FOLD: 9, EPOCH: 42, valid_loss: 0.016830775576333206\n",
      "FOLD: 9, EPOCH: 43, train_loss: 0.019352129257975085\n",
      "FOLD: 9, EPOCH: 43, valid_loss: 0.01691772374841902\n",
      "FOLD: 9, EPOCH: 44, train_loss: 0.019328131983357092\n",
      "FOLD: 9, EPOCH: 44, valid_loss: 0.016809940803796053\n",
      "FOLD: 9, EPOCH: 45, train_loss: 0.019205397295375026\n",
      "FOLD: 9, EPOCH: 45, valid_loss: 0.016628769226372242\n",
      "FOLD: 9, EPOCH: 46, train_loss: 0.018941068697360255\n",
      "FOLD: 9, EPOCH: 46, valid_loss: 0.016713431674159236\n",
      "FOLD: 9, EPOCH: 47, train_loss: 0.018691406957805155\n",
      "FOLD: 9, EPOCH: 47, valid_loss: 0.016710030432376597\n",
      "FOLD: 9, EPOCH: 48, train_loss: 0.018543296745948252\n",
      "FOLD: 9, EPOCH: 48, valid_loss: 0.016759842065059476\n",
      "FOLD: 9, EPOCH: 49, train_loss: 0.01846547654319194\n",
      "FOLD: 9, EPOCH: 49, valid_loss: 0.016742137415955465\n",
      "FOLD: 9, EPOCH: 50, train_loss: 0.01834203460283818\n",
      "FOLD: 9, EPOCH: 50, valid_loss: 0.01666619659711917\n",
      "FOLD: 9, EPOCH: 51, train_loss: 0.018197518935607327\n",
      "FOLD: 9, EPOCH: 51, valid_loss: 0.01664476443289055\n",
      "FOLD: 9, EPOCH: 52, train_loss: 0.017913072940803344\n",
      "FOLD: 9, EPOCH: 52, valid_loss: 0.016777746689816315\n",
      "FOLD: 9, EPOCH: 53, train_loss: 0.017783583159888944\n",
      "FOLD: 9, EPOCH: 53, valid_loss: 0.016724437423464324\n",
      "FOLD: 9, EPOCH: 54, train_loss: 0.017630979635061755\n",
      "FOLD: 9, EPOCH: 54, valid_loss: 0.01665250201606088\n",
      "FOLD: 9, EPOCH: 55, train_loss: 0.017543273034595675\n",
      "FOLD: 9, EPOCH: 55, valid_loss: 0.016657120703409117\n",
      "FOLD: 9, EPOCH: 56, train_loss: 0.01734247533304076\n",
      "FOLD: 9, EPOCH: 56, valid_loss: 0.016738537285063002\n",
      "FOLD: 9, EPOCH: 57, train_loss: 0.017419858258818425\n",
      "FOLD: 9, EPOCH: 57, valid_loss: 0.016793999044845503\n",
      "FOLD: 9, EPOCH: 58, train_loss: 0.017267708468341057\n",
      "FOLD: 9, EPOCH: 58, valid_loss: 0.01669951921535863\n",
      "FOLD: 9, EPOCH: 59, train_loss: 0.017199839735704082\n",
      "FOLD: 9, EPOCH: 59, valid_loss: 0.016661688168015745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.6760243667710212\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.36722107143963084\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.06064366611742204\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02009215337388656\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.0230874857234378\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01937388552024084\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.022300643329658816\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.02529156087514232\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.023700130166065307\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.020008853801033077\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.0223258497253541\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018394989454570937\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.020945854881598103\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01810360951896976\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020803658748345992\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.018465381773079142\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020731335373655443\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01820944983731298\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020602211115821716\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.018441636005745214\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020576608205033885\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01830282829263631\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.020581453990551734\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.018271887236658263\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.020708572624191162\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018376659163657355\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.020649170322764303\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01834508086390355\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.020745253514858984\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.018178348484284738\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.02071522236351044\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.018626801231328177\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.02071871728666367\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.018301405889146468\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.020802569377326195\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01878254926379989\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.020723892195570852\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.018182216869557604\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.020829404181530398\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.018323487109121156\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.020864697269374323\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.018558325793813255\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.02086520190200498\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.018362484653206432\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.02079788009005208\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.018574346295174432\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.020857305812739556\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01804339381701806\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.02083476417728009\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01788055557100212\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.020836870564568427\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.018219290520338452\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.020774932277779424\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.017996108159422874\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.020710673663885362\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.018166555858710232\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.02067713413027025\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01814601679935175\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.02058899515578824\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.017964073840309593\n",
      "FOLD: 0, EPOCH: 30, train_loss: 0.020613966894245918\n",
      "FOLD: 0, EPOCH: 30, valid_loss: 0.01794981901698253\n",
      "FOLD: 0, EPOCH: 31, train_loss: 0.020405764697540192\n",
      "FOLD: 0, EPOCH: 31, valid_loss: 0.01820960618993815\n",
      "FOLD: 0, EPOCH: 32, train_loss: 0.020382926132409804\n",
      "FOLD: 0, EPOCH: 32, valid_loss: 0.01788319636355428\n",
      "FOLD: 0, EPOCH: 33, train_loss: 0.02032225297824029\n",
      "FOLD: 0, EPOCH: 33, valid_loss: 0.01800836732282358\n",
      "FOLD: 0, EPOCH: 34, train_loss: 0.020205160350568834\n",
      "FOLD: 0, EPOCH: 34, valid_loss: 0.01771837768747526\n",
      "FOLD: 0, EPOCH: 35, train_loss: 0.020124889982323493\n",
      "FOLD: 0, EPOCH: 35, valid_loss: 0.017660774947965845\n",
      "FOLD: 0, EPOCH: 36, train_loss: 0.02006421930366947\n",
      "FOLD: 0, EPOCH: 36, valid_loss: 0.017705593039007747\n",
      "FOLD: 0, EPOCH: 37, train_loss: 0.019913589437642404\n",
      "FOLD: 0, EPOCH: 37, valid_loss: 0.017726910903173333\n",
      "FOLD: 0, EPOCH: 38, train_loss: 0.01985417314835133\n",
      "FOLD: 0, EPOCH: 38, valid_loss: 0.017489984741105753\n",
      "FOLD: 0, EPOCH: 39, train_loss: 0.019729497343782456\n",
      "FOLD: 0, EPOCH: 39, valid_loss: 0.017505450995967668\n",
      "FOLD: 0, EPOCH: 40, train_loss: 0.019547287603059123\n",
      "FOLD: 0, EPOCH: 40, valid_loss: 0.017462275429245305\n",
      "FOLD: 0, EPOCH: 41, train_loss: 0.019454729737293334\n",
      "FOLD: 0, EPOCH: 41, valid_loss: 0.01744103924754788\n",
      "FOLD: 0, EPOCH: 42, train_loss: 0.019322176457893463\n",
      "FOLD: 0, EPOCH: 42, valid_loss: 0.017442888196776894\n",
      "FOLD: 0, EPOCH: 43, train_loss: 0.01918119122424433\n",
      "FOLD: 0, EPOCH: 43, valid_loss: 0.017388114870032844\n",
      "FOLD: 0, EPOCH: 44, train_loss: 0.019055460381411735\n",
      "FOLD: 0, EPOCH: 44, valid_loss: 0.017399574794313487\n",
      "FOLD: 0, EPOCH: 45, train_loss: 0.018916494946085636\n",
      "FOLD: 0, EPOCH: 45, valid_loss: 0.0172352629220661\n",
      "FOLD: 0, EPOCH: 46, train_loss: 0.018688014834638566\n",
      "FOLD: 0, EPOCH: 46, valid_loss: 0.01715516939978389\n",
      "FOLD: 0, EPOCH: 47, train_loss: 0.018567152681850618\n",
      "FOLD: 0, EPOCH: 47, valid_loss: 0.017162025960929254\n",
      "FOLD: 0, EPOCH: 48, train_loss: 0.018405239860857688\n",
      "FOLD: 0, EPOCH: 48, valid_loss: 0.017260056427296472\n",
      "FOLD: 0, EPOCH: 49, train_loss: 0.018222158402204515\n",
      "FOLD: 0, EPOCH: 49, valid_loss: 0.017242703805951512\n",
      "FOLD: 0, EPOCH: 50, train_loss: 0.018062666256821926\n",
      "FOLD: 0, EPOCH: 50, valid_loss: 0.017180533860536182\n",
      "FOLD: 0, EPOCH: 51, train_loss: 0.0178946370379098\n",
      "FOLD: 0, EPOCH: 51, valid_loss: 0.017211163580855903\n",
      "FOLD: 0, EPOCH: 52, train_loss: 0.01768634830631556\n",
      "FOLD: 0, EPOCH: 52, valid_loss: 0.017202710897168693\n",
      "FOLD: 0, EPOCH: 53, train_loss: 0.017587509294671396\n",
      "FOLD: 0, EPOCH: 53, valid_loss: 0.017185083206962135\n",
      "FOLD: 0, EPOCH: 54, train_loss: 0.017410241746373716\n",
      "FOLD: 0, EPOCH: 54, valid_loss: 0.017201203469406155\n",
      "FOLD: 0, EPOCH: 55, train_loss: 0.01727529529842638\n",
      "FOLD: 0, EPOCH: 55, valid_loss: 0.01723203660153291\n",
      "FOLD: 0, EPOCH: 56, train_loss: 0.01722102257152719\n",
      "FOLD: 0, EPOCH: 56, valid_loss: 0.01722453983829302\n",
      "FOLD: 0, EPOCH: 57, train_loss: 0.017129457465583278\n",
      "FOLD: 0, EPOCH: 57, valid_loss: 0.017212991712286192\n",
      "FOLD: 0, EPOCH: 58, train_loss: 0.017057452266735416\n",
      "FOLD: 0, EPOCH: 58, valid_loss: 0.017217565985286936\n",
      "FOLD: 0, EPOCH: 59, train_loss: 0.017083986427995468\n",
      "FOLD: 0, EPOCH: 59, valid_loss: 0.017251094364944625\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6757483761156758\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.3645973685714934\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.06062293339881205\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02011263235989544\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.022829822366756777\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.019503203841547172\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.02229677855728134\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01963652903214097\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.025050444973091925\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.020155719947069883\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.021777195098900026\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01918434129200048\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.021285828491372446\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.018570500270773966\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.020758793190602334\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.018166070597039327\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020657097920775414\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.018102491170995764\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.02055520677278119\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01822124354334341\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.020528961670014167\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01858162388412489\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020551773401037338\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.018410588200721476\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.020567360652550576\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01874453429546621\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.02047001255616065\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01867175992164347\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.020624836822671275\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.018389490226076707\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.020702228911461368\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.018357974166671436\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.020682959414778216\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01898132223221991\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.020683830207394015\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.018608100194897916\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.02074451696488165\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.019110762876354985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 19, train_loss: 0.020736314416412386\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.019778134766966105\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.020732465843039175\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01823298746926917\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.02079361873047967\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.018492180181460247\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.020752846041033345\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.018619185365322564\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.02079029017158093\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01851335105796655\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.0207991047972633\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.018402603040966723\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.020774574325450004\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.01834655599668622\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.0207164216786623\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.018626838663799897\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.020642493376808783\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.018329704387320414\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.020595953385195424\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01844978275605374\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.020642077261882445\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.01849325228896406\n",
      "FOLD: 1, EPOCH: 30, train_loss: 0.020467102563669605\n",
      "FOLD: 1, EPOCH: 30, valid_loss: 0.018429689937167697\n",
      "FOLD: 1, EPOCH: 31, train_loss: 0.02036213559969779\n",
      "FOLD: 1, EPOCH: 31, valid_loss: 0.018177717354976468\n",
      "FOLD: 1, EPOCH: 32, train_loss: 0.02035304252659121\n",
      "FOLD: 1, EPOCH: 32, valid_loss: 0.018243006482306454\n",
      "FOLD: 1, EPOCH: 33, train_loss: 0.020271270710133737\n",
      "FOLD: 1, EPOCH: 33, valid_loss: 0.018249177580906287\n",
      "FOLD: 1, EPOCH: 34, train_loss: 0.02021188132705227\n",
      "FOLD: 1, EPOCH: 34, valid_loss: 0.018321663089510467\n",
      "FOLD: 1, EPOCH: 35, train_loss: 0.02006283091200936\n",
      "FOLD: 1, EPOCH: 35, valid_loss: 0.017870942544605996\n",
      "FOLD: 1, EPOCH: 36, train_loss: 0.019976062892425445\n",
      "FOLD: 1, EPOCH: 36, valid_loss: 0.01790780770695872\n",
      "FOLD: 1, EPOCH: 37, train_loss: 0.019899496988904093\n",
      "FOLD: 1, EPOCH: 37, valid_loss: 0.017918164427909587\n",
      "FOLD: 1, EPOCH: 38, train_loss: 0.019775719484013896\n",
      "FOLD: 1, EPOCH: 38, valid_loss: 0.017575986321187682\n",
      "FOLD: 1, EPOCH: 39, train_loss: 0.019661385890456937\n",
      "FOLD: 1, EPOCH: 39, valid_loss: 0.01767196940879027\n",
      "FOLD: 1, EPOCH: 40, train_loss: 0.019541191862475486\n",
      "FOLD: 1, EPOCH: 40, valid_loss: 0.017773446316520374\n",
      "FOLD: 1, EPOCH: 41, train_loss: 0.019406349007641117\n",
      "FOLD: 1, EPOCH: 41, valid_loss: 0.017805553196618955\n",
      "FOLD: 1, EPOCH: 42, train_loss: 0.019299163885654943\n",
      "FOLD: 1, EPOCH: 42, valid_loss: 0.01763552836039\n",
      "FOLD: 1, EPOCH: 43, train_loss: 0.019161349811380908\n",
      "FOLD: 1, EPOCH: 43, valid_loss: 0.01759748574760225\n",
      "FOLD: 1, EPOCH: 44, train_loss: 0.01893729350018886\n",
      "FOLD: 1, EPOCH: 44, valid_loss: 0.017639455540726583\n",
      "FOLD: 1, EPOCH: 45, train_loss: 0.018858696724618634\n",
      "FOLD: 1, EPOCH: 45, valid_loss: 0.017472108722560935\n",
      "FOLD: 1, EPOCH: 46, train_loss: 0.018720011575327766\n",
      "FOLD: 1, EPOCH: 46, valid_loss: 0.017651293530232377\n",
      "FOLD: 1, EPOCH: 47, train_loss: 0.018579855627350268\n",
      "FOLD: 1, EPOCH: 47, valid_loss: 0.017591311130672693\n",
      "FOLD: 1, EPOCH: 48, train_loss: 0.01835843075307146\n",
      "FOLD: 1, EPOCH: 48, valid_loss: 0.017370704509731796\n",
      "FOLD: 1, EPOCH: 49, train_loss: 0.01819629728073074\n",
      "FOLD: 1, EPOCH: 49, valid_loss: 0.017503150169634156\n",
      "FOLD: 1, EPOCH: 50, train_loss: 0.017987574510757002\n",
      "FOLD: 1, EPOCH: 50, valid_loss: 0.017564776508758467\n",
      "FOLD: 1, EPOCH: 51, train_loss: 0.017818408771868674\n",
      "FOLD: 1, EPOCH: 51, valid_loss: 0.0174918032458259\n",
      "FOLD: 1, EPOCH: 52, train_loss: 0.017667366131659475\n",
      "FOLD: 1, EPOCH: 52, valid_loss: 0.017547591330690518\n",
      "FOLD: 1, EPOCH: 53, train_loss: 0.017495122996549452\n",
      "FOLD: 1, EPOCH: 53, valid_loss: 0.017505281708306737\n",
      "FOLD: 1, EPOCH: 54, train_loss: 0.017387818881580905\n",
      "FOLD: 1, EPOCH: 54, valid_loss: 0.017533255223598745\n",
      "FOLD: 1, EPOCH: 55, train_loss: 0.01725546402796622\n",
      "FOLD: 1, EPOCH: 55, valid_loss: 0.01750353780678577\n",
      "FOLD: 1, EPOCH: 56, train_loss: 0.017184431664645672\n",
      "FOLD: 1, EPOCH: 56, valid_loss: 0.017579352120972343\n",
      "FOLD: 1, EPOCH: 57, train_loss: 0.01712542345086413\n",
      "FOLD: 1, EPOCH: 57, valid_loss: 0.017537631560117006\n",
      "FOLD: 1, EPOCH: 58, train_loss: 0.017039593104873935\n",
      "FOLD: 1, EPOCH: 58, valid_loss: 0.0175461961577336\n",
      "FOLD: 1, EPOCH: 59, train_loss: 0.017037703349224984\n",
      "FOLD: 1, EPOCH: 59, valid_loss: 0.01757793231970734\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6753323256969452\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.3757345775763194\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.06080576209050994\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020524243410262797\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.022927297531597075\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019505070211986702\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.022922156727121723\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.019005679784135684\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.023050567135214806\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.021787737185756367\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.022872585394690115\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.018335994850430224\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.021022363932382677\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.02161530777812004\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.021690586149211852\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018389314826991823\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.0210374285737353\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.018699461232042976\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.02088383114145648\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.018695582170039415\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.020994125799305978\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.018411867630978424\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.020949123523408365\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018324946363766987\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.021021468456714383\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01885114661935303\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.021047306781814944\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01937311256511344\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.021291475634901753\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018322899834149413\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.02108109991156286\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.018350930677519903\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.021110608608972643\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01852694246917963\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.02107871964333519\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.018723302106890414\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.021073161209783246\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.018518377975043323\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.02116272433871223\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.0185785754583776\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.02112359516322613\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.018563273466295667\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.021140253531836694\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.018742316402494907\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.021093134473889105\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.018781550228595734\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.02102131736615012\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.018721893947157595\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.021044096002174963\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.018667313994632825\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.021063402523436855\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.018478790091143713\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.020971838192593666\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01849259456826581\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.020851617775136423\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.018422123769091234\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.020907644158409486\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.018380330513334937\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.02083480550396827\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.01844251931955417\n",
      "FOLD: 2, EPOCH: 30, train_loss: 0.020751141456346357\n",
      "FOLD: 2, EPOCH: 30, valid_loss: 0.01865899914668666\n",
      "FOLD: 2, EPOCH: 31, train_loss: 0.020696228213848606\n",
      "FOLD: 2, EPOCH: 31, valid_loss: 0.018197901805655822\n",
      "FOLD: 2, EPOCH: 32, train_loss: 0.020614370331168176\n",
      "FOLD: 2, EPOCH: 32, valid_loss: 0.017865010899388127\n",
      "FOLD: 2, EPOCH: 33, train_loss: 0.020553794527246105\n",
      "FOLD: 2, EPOCH: 33, valid_loss: 0.01776674896892574\n",
      "FOLD: 2, EPOCH: 34, train_loss: 0.020475201597136835\n",
      "FOLD: 2, EPOCH: 34, valid_loss: 0.017877551209595468\n",
      "FOLD: 2, EPOCH: 35, train_loss: 0.020328094401667194\n",
      "FOLD: 2, EPOCH: 35, valid_loss: 0.01795875384575791\n",
      "FOLD: 2, EPOCH: 36, train_loss: 0.02022555286605512\n",
      "FOLD: 2, EPOCH: 36, valid_loss: 0.017851210457997188\n",
      "FOLD: 2, EPOCH: 37, train_loss: 0.020139860301729172\n",
      "FOLD: 2, EPOCH: 37, valid_loss: 0.01772139562914769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 38, train_loss: 0.020041432976722718\n",
      "FOLD: 2, EPOCH: 38, valid_loss: 0.017640202306210995\n",
      "FOLD: 2, EPOCH: 39, train_loss: 0.019854399658018544\n",
      "FOLD: 2, EPOCH: 39, valid_loss: 0.0176213001832366\n",
      "FOLD: 2, EPOCH: 40, train_loss: 0.019748985767364502\n",
      "FOLD: 2, EPOCH: 40, valid_loss: 0.01747812506639295\n",
      "FOLD: 2, EPOCH: 41, train_loss: 0.01970011092001392\n",
      "FOLD: 2, EPOCH: 41, valid_loss: 0.017518534894204803\n",
      "FOLD: 2, EPOCH: 42, train_loss: 0.019526877674844956\n",
      "FOLD: 2, EPOCH: 42, valid_loss: 0.017439513829433255\n",
      "FOLD: 2, EPOCH: 43, train_loss: 0.019417173559627226\n",
      "FOLD: 2, EPOCH: 43, valid_loss: 0.01749684030397071\n",
      "FOLD: 2, EPOCH: 44, train_loss: 0.019240175247673064\n",
      "FOLD: 2, EPOCH: 44, valid_loss: 0.017574994048724573\n",
      "FOLD: 2, EPOCH: 45, train_loss: 0.019129026524962917\n",
      "FOLD: 2, EPOCH: 45, valid_loss: 0.017385830067925982\n",
      "FOLD: 2, EPOCH: 46, train_loss: 0.018986915472534394\n",
      "FOLD: 2, EPOCH: 46, valid_loss: 0.017287858968807593\n",
      "FOLD: 2, EPOCH: 47, train_loss: 0.01877926559818368\n",
      "FOLD: 2, EPOCH: 47, valid_loss: 0.017314579544795886\n",
      "FOLD: 2, EPOCH: 48, train_loss: 0.01863039090868927\n",
      "FOLD: 2, EPOCH: 48, valid_loss: 0.01727001674266325\n",
      "FOLD: 2, EPOCH: 49, train_loss: 0.01841362901632824\n",
      "FOLD: 2, EPOCH: 49, valid_loss: 0.01724375385998024\n",
      "FOLD: 2, EPOCH: 50, train_loss: 0.018251739935048163\n",
      "FOLD: 2, EPOCH: 50, valid_loss: 0.017245239733407896\n",
      "FOLD: 2, EPOCH: 51, train_loss: 0.01808259472731621\n",
      "FOLD: 2, EPOCH: 51, valid_loss: 0.017273245948470302\n",
      "FOLD: 2, EPOCH: 52, train_loss: 0.017889535252846058\n",
      "FOLD: 2, EPOCH: 52, valid_loss: 0.017217491649919085\n",
      "FOLD: 2, EPOCH: 53, train_loss: 0.017720542313350785\n",
      "FOLD: 2, EPOCH: 53, valid_loss: 0.017197377048432827\n",
      "FOLD: 2, EPOCH: 54, train_loss: 0.01758600105681727\n",
      "FOLD: 2, EPOCH: 54, valid_loss: 0.017219629863070116\n",
      "FOLD: 2, EPOCH: 55, train_loss: 0.017455689002188943\n",
      "FOLD: 2, EPOCH: 55, valid_loss: 0.017302299590988293\n",
      "FOLD: 2, EPOCH: 56, train_loss: 0.017288444762028034\n",
      "FOLD: 2, EPOCH: 56, valid_loss: 0.017271550993124645\n",
      "FOLD: 2, EPOCH: 57, train_loss: 0.017207720467159824\n",
      "FOLD: 2, EPOCH: 57, valid_loss: 0.017230857111927535\n",
      "FOLD: 2, EPOCH: 58, train_loss: 0.01712800108136669\n",
      "FOLD: 2, EPOCH: 58, valid_loss: 0.017268980853259563\n",
      "FOLD: 2, EPOCH: 59, train_loss: 0.01718778673319086\n",
      "FOLD: 2, EPOCH: 59, valid_loss: 0.017265441827476025\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6758067275247266\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.3777925984727012\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.06119087974150335\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020147811414466962\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.023135673795496265\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.020063917256063886\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.02255298748852745\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.019569167867302895\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.024735047139467732\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.018882003768036764\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.022472544627324228\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.018013099415434733\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020832963095557305\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017832339327368472\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02066202860686087\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01797702292808228\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.02053758041752923\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01786205369151301\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020501893794825\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017623062142067485\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.02045297633496023\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017843402611712616\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.020518556850091102\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.0178122586156759\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.020634820324278647\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017824678733530972\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.020564756818836735\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01792193938874536\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.02064589676597426\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01760959138886796\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.0206913809862829\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017846009228378534\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.020753647134669366\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.0179762443424099\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.02077437323187628\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.018053526834895212\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.020754160287399445\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01793009601533413\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.020841845653710826\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.017903258765323296\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.020784104242920876\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.018186226383679442\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.02088849208047313\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017959132221423917\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.02079543972447995\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01778016560193565\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.02084383051241598\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017773855788012344\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.02083184794793206\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017682569204933114\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.020800611424830653\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.018037905916571617\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.020692683479958965\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.017812039289209578\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.020719655410897347\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.01786003468765153\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.020692445349789434\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01797274039644334\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.020614689852922193\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.017763523384928703\n",
      "FOLD: 3, EPOCH: 30, train_loss: 0.020545428486601\n",
      "FOLD: 3, EPOCH: 30, valid_loss: 0.01764644444402721\n",
      "FOLD: 3, EPOCH: 31, train_loss: 0.020475374690947994\n",
      "FOLD: 3, EPOCH: 31, valid_loss: 0.01768663463493188\n",
      "FOLD: 3, EPOCH: 32, train_loss: 0.02047537433043603\n",
      "FOLD: 3, EPOCH: 32, valid_loss: 0.01763509146662222\n",
      "FOLD: 3, EPOCH: 33, train_loss: 0.020382065794640972\n",
      "FOLD: 3, EPOCH: 33, valid_loss: 0.017510174359712336\n",
      "FOLD: 3, EPOCH: 34, train_loss: 0.020294169925393596\n",
      "FOLD: 3, EPOCH: 34, valid_loss: 0.017440718598663807\n",
      "FOLD: 3, EPOCH: 35, train_loss: 0.02017941933966452\n",
      "FOLD: 3, EPOCH: 35, valid_loss: 0.017481173233439524\n",
      "FOLD: 3, EPOCH: 36, train_loss: 0.020023656564374125\n",
      "FOLD: 3, EPOCH: 36, valid_loss: 0.01708728711431225\n",
      "FOLD: 3, EPOCH: 37, train_loss: 0.019965227044397786\n",
      "FOLD: 3, EPOCH: 37, valid_loss: 0.017230324395414855\n",
      "FOLD: 3, EPOCH: 38, train_loss: 0.019797283783555032\n",
      "FOLD: 3, EPOCH: 38, valid_loss: 0.01743740231419603\n",
      "FOLD: 3, EPOCH: 39, train_loss: 0.019778385518058654\n",
      "FOLD: 3, EPOCH: 39, valid_loss: 0.017028734501865175\n",
      "FOLD: 3, EPOCH: 40, train_loss: 0.019552202510737603\n",
      "FOLD: 3, EPOCH: 40, valid_loss: 0.017049939630346164\n",
      "FOLD: 3, EPOCH: 41, train_loss: 0.019493561742767212\n",
      "FOLD: 3, EPOCH: 41, valid_loss: 0.017079037355466023\n",
      "FOLD: 3, EPOCH: 42, train_loss: 0.01931684130141812\n",
      "FOLD: 3, EPOCH: 42, valid_loss: 0.016863216128614213\n",
      "FOLD: 3, EPOCH: 43, train_loss: 0.019171239267433842\n",
      "FOLD: 3, EPOCH: 43, valid_loss: 0.016948759452336364\n",
      "FOLD: 3, EPOCH: 44, train_loss: 0.01905270016962482\n",
      "FOLD: 3, EPOCH: 44, valid_loss: 0.016900516373829708\n",
      "FOLD: 3, EPOCH: 45, train_loss: 0.018910439396577498\n",
      "FOLD: 3, EPOCH: 45, valid_loss: 0.016946177670939103\n",
      "FOLD: 3, EPOCH: 46, train_loss: 0.018703612390785447\n",
      "FOLD: 3, EPOCH: 46, valid_loss: 0.016797267210980255\n",
      "FOLD: 3, EPOCH: 47, train_loss: 0.01850886049289857\n",
      "FOLD: 3, EPOCH: 47, valid_loss: 0.016895687569760613\n",
      "FOLD: 3, EPOCH: 48, train_loss: 0.01834289524704218\n",
      "FOLD: 3, EPOCH: 48, valid_loss: 0.01677583158016205\n",
      "FOLD: 3, EPOCH: 49, train_loss: 0.01819137436367812\n",
      "FOLD: 3, EPOCH: 49, valid_loss: 0.01680194627907541\n",
      "FOLD: 3, EPOCH: 50, train_loss: 0.018009926625076802\n",
      "FOLD: 3, EPOCH: 50, valid_loss: 0.016906158532947302\n",
      "FOLD: 3, EPOCH: 51, train_loss: 0.017828706267379944\n",
      "FOLD: 3, EPOCH: 51, valid_loss: 0.01678428090073996\n",
      "FOLD: 3, EPOCH: 52, train_loss: 0.01767348068495912\n",
      "FOLD: 3, EPOCH: 52, valid_loss: 0.016766257325394288\n",
      "FOLD: 3, EPOCH: 53, train_loss: 0.017514451406896114\n",
      "FOLD: 3, EPOCH: 53, valid_loss: 0.01679787127715018\n",
      "FOLD: 3, EPOCH: 54, train_loss: 0.017345255955813394\n",
      "FOLD: 3, EPOCH: 54, valid_loss: 0.01681117568578985\n",
      "FOLD: 3, EPOCH: 55, train_loss: 0.0171898577001787\n",
      "FOLD: 3, EPOCH: 55, valid_loss: 0.016851571802463796\n",
      "FOLD: 3, EPOCH: 56, train_loss: 0.017123266039115768\n",
      "FOLD: 3, EPOCH: 56, valid_loss: 0.01681025026159154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 57, train_loss: 0.01704044316805178\n",
      "FOLD: 3, EPOCH: 57, valid_loss: 0.016837833863165643\n",
      "FOLD: 3, EPOCH: 58, train_loss: 0.016987123622769308\n",
      "FOLD: 3, EPOCH: 58, valid_loss: 0.016829758520341583\n",
      "FOLD: 3, EPOCH: 59, train_loss: 0.016967084366948375\n",
      "FOLD: 3, EPOCH: 59, valid_loss: 0.016840372027622327\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6755954869331852\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.37617448965708417\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.061340459736604847\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020082477894094255\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023230197508969614\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01957808600531684\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.02321918342382677\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.025236823078658845\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.022089057247484885\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017408255849861436\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.02106816344443829\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.019179772378669843\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02175638791053526\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017908931244164705\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.0206207814956865\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017895289386312168\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.02050220443596763\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017832785586102143\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.020446599587317437\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017708551190379593\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020629843889224914\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017617131479912333\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.020595151654654933\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01776593742478225\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.020584013397174496\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.018053934081561036\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.020663312137607606\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017377024412982993\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.020683767694619395\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01750896219164133\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.02073586293526234\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017629007601903543\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.02081661596894264\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01810674239984817\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.02088598255668917\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.018155409385346703\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.020864755215664065\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.017881078128185537\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.020904379950896387\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.017627539734045666\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.020866824734595515\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.018079958028263517\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.020926046972313234\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017769603317396507\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.020891730102800554\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01770984474569559\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.020997318565364808\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01794361002329323\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.020856975295370624\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.018349221700595483\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.020918539755286708\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.017438863766276173\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.020934380578898616\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.017758774001979165\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.020823128942039706\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.01783039586411582\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.020737065110475787\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.017571918562882476\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.020724771111722915\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.017545630017088518\n",
      "FOLD: 4, EPOCH: 30, train_loss: 0.020658959562499676\n",
      "FOLD: 4, EPOCH: 30, valid_loss: 0.017358184429920383\n",
      "FOLD: 4, EPOCH: 31, train_loss: 0.0206018585231035\n",
      "FOLD: 4, EPOCH: 31, valid_loss: 0.01759959990158677\n",
      "FOLD: 4, EPOCH: 32, train_loss: 0.02060154327942479\n",
      "FOLD: 4, EPOCH: 32, valid_loss: 0.01753272995766666\n",
      "FOLD: 4, EPOCH: 33, train_loss: 0.020440117714385832\n",
      "FOLD: 4, EPOCH: 33, valid_loss: 0.017095803490115538\n",
      "FOLD: 4, EPOCH: 34, train_loss: 0.020316834952081402\n",
      "FOLD: 4, EPOCH: 34, valid_loss: 0.01709310094722443\n",
      "FOLD: 4, EPOCH: 35, train_loss: 0.02027363582484184\n",
      "FOLD: 4, EPOCH: 35, valid_loss: 0.017471779241330095\n",
      "FOLD: 4, EPOCH: 36, train_loss: 0.020141121084170956\n",
      "FOLD: 4, EPOCH: 36, valid_loss: 0.017189767573856644\n",
      "FOLD: 4, EPOCH: 37, train_loss: 0.020090826492636434\n",
      "FOLD: 4, EPOCH: 37, valid_loss: 0.017421563983791404\n",
      "FOLD: 4, EPOCH: 38, train_loss: 0.019980554883518527\n",
      "FOLD: 4, EPOCH: 38, valid_loss: 0.017094952054321766\n",
      "FOLD: 4, EPOCH: 39, train_loss: 0.019810766666646926\n",
      "FOLD: 4, EPOCH: 39, valid_loss: 0.016975543461740017\n",
      "FOLD: 4, EPOCH: 40, train_loss: 0.019662429121953824\n",
      "FOLD: 4, EPOCH: 40, valid_loss: 0.017148886548562184\n",
      "FOLD: 4, EPOCH: 41, train_loss: 0.019592533008225502\n",
      "FOLD: 4, EPOCH: 41, valid_loss: 0.017009590441981953\n",
      "FOLD: 4, EPOCH: 42, train_loss: 0.019483251425047074\n",
      "FOLD: 4, EPOCH: 42, valid_loss: 0.016926752506858773\n",
      "FOLD: 4, EPOCH: 43, train_loss: 0.019293084157811058\n",
      "FOLD: 4, EPOCH: 43, valid_loss: 0.01675073429942131\n",
      "FOLD: 4, EPOCH: 44, train_loss: 0.019141590451040576\n",
      "FOLD: 4, EPOCH: 44, valid_loss: 0.016748995054513216\n",
      "FOLD: 4, EPOCH: 45, train_loss: 0.019022191904725566\n",
      "FOLD: 4, EPOCH: 45, valid_loss: 0.016648783555461302\n",
      "FOLD: 4, EPOCH: 46, train_loss: 0.01889051932000345\n",
      "FOLD: 4, EPOCH: 46, valid_loss: 0.016848074013574257\n",
      "FOLD: 4, EPOCH: 47, train_loss: 0.018686640557021864\n",
      "FOLD: 4, EPOCH: 47, valid_loss: 0.016766402766936354\n",
      "FOLD: 4, EPOCH: 48, train_loss: 0.018525949541118837\n",
      "FOLD: 4, EPOCH: 48, valid_loss: 0.016711115267955594\n",
      "FOLD: 4, EPOCH: 49, train_loss: 0.01835349820434086\n",
      "FOLD: 4, EPOCH: 49, valid_loss: 0.016566224499709077\n",
      "FOLD: 4, EPOCH: 50, train_loss: 0.018179940912992725\n",
      "FOLD: 4, EPOCH: 50, valid_loss: 0.016636054290251598\n",
      "FOLD: 4, EPOCH: 51, train_loss: 0.01799841016050308\n",
      "FOLD: 4, EPOCH: 51, valid_loss: 0.01660717563289735\n",
      "FOLD: 4, EPOCH: 52, train_loss: 0.01784580836012479\n",
      "FOLD: 4, EPOCH: 52, valid_loss: 0.01665571414762073\n",
      "FOLD: 4, EPOCH: 53, train_loss: 0.017720144398270115\n",
      "FOLD: 4, EPOCH: 53, valid_loss: 0.016660602038933173\n",
      "FOLD: 4, EPOCH: 54, train_loss: 0.01760065644498794\n",
      "FOLD: 4, EPOCH: 54, valid_loss: 0.016693115130894713\n",
      "FOLD: 4, EPOCH: 55, train_loss: 0.01749080311987669\n",
      "FOLD: 4, EPOCH: 55, valid_loss: 0.016682122006184526\n",
      "FOLD: 4, EPOCH: 56, train_loss: 0.017331254428192493\n",
      "FOLD: 4, EPOCH: 56, valid_loss: 0.016673307451936934\n",
      "FOLD: 4, EPOCH: 57, train_loss: 0.017286607436835764\n",
      "FOLD: 4, EPOCH: 57, valid_loss: 0.016662987880408764\n",
      "FOLD: 4, EPOCH: 58, train_loss: 0.01726409219085209\n",
      "FOLD: 4, EPOCH: 58, valid_loss: 0.016643339819792245\n",
      "FOLD: 4, EPOCH: 59, train_loss: 0.017214547326007197\n",
      "FOLD: 4, EPOCH: 59, valid_loss: 0.01665748857582609\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.675952793513575\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.3557862987120946\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.061457965510987464\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.020685729156765673\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.02334110119169758\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.021373605769541528\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.02269149036897767\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.020169858406815264\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.021346225385223665\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.13373610242787334\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.02646203248971893\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.01955034604503049\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.02198147760523904\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.01885314927332931\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.021502394565651492\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.01897469504425923\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.021373201726425078\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.01889719648493661\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.021120557441346107\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.02207174027959506\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.021070198570528338\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.018581819617085986\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.021026502465528826\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.019188171666529443\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.021018574831466522\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.01860918653094106\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.021007606074694665\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.019386189472344186\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.02095145197404969\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.01913277929027875\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.02097457688181631\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.018414597854846053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 5, EPOCH: 16, train_loss: 0.02092865687464514\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.018770918974445924\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.0210078073725585\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.018478364269766543\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.020990063214013654\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.018853151239454746\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.02093133970854744\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.01898873969912529\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.021019159473719136\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.019724585426350433\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.021190430344112457\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.018990802475147776\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.02098339848941372\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.01874460776646932\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.020915364882638378\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.019151796793772116\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.021015117930308466\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.018829929642379284\n",
      "FOLD: 5, EPOCH: 25, train_loss: 0.02096984880345483\n",
      "FOLD: 5, EPOCH: 25, valid_loss: 0.018647673746777907\n",
      "FOLD: 5, EPOCH: 26, train_loss: 0.020853710366833596\n",
      "FOLD: 5, EPOCH: 26, valid_loss: 0.018916107714176178\n",
      "FOLD: 5, EPOCH: 27, train_loss: 0.020892958571353266\n",
      "FOLD: 5, EPOCH: 27, valid_loss: 0.019453292712569237\n",
      "FOLD: 5, EPOCH: 28, train_loss: 0.02091818176690609\n",
      "FOLD: 5, EPOCH: 28, valid_loss: 0.018617005604836676\n",
      "FOLD: 5, EPOCH: 29, train_loss: 0.020811301469802857\n",
      "FOLD: 5, EPOCH: 29, valid_loss: 0.018693439041574795\n",
      "FOLD: 5, EPOCH: 30, train_loss: 0.020686246695057038\n",
      "FOLD: 5, EPOCH: 30, valid_loss: 0.01836952722320954\n",
      "FOLD: 5, EPOCH: 31, train_loss: 0.02057400125890009\n",
      "FOLD: 5, EPOCH: 31, valid_loss: 0.018334688618779182\n",
      "FOLD: 5, EPOCH: 32, train_loss: 0.020475502324200447\n",
      "FOLD: 5, EPOCH: 32, valid_loss: 0.01847875542524788\n",
      "FOLD: 5, EPOCH: 33, train_loss: 0.020370816751833883\n",
      "FOLD: 5, EPOCH: 33, valid_loss: 0.018294183123442862\n",
      "FOLD: 5, EPOCH: 34, train_loss: 0.020225603938583404\n",
      "FOLD: 5, EPOCH: 34, valid_loss: 0.018506549609204132\n",
      "FOLD: 5, EPOCH: 35, train_loss: 0.02016995761904024\n",
      "FOLD: 5, EPOCH: 35, valid_loss: 0.018261104201277096\n",
      "FOLD: 5, EPOCH: 36, train_loss: 0.02006642477166268\n",
      "FOLD: 5, EPOCH: 36, valid_loss: 0.018167387280199263\n",
      "FOLD: 5, EPOCH: 37, train_loss: 0.0199711688583897\n",
      "FOLD: 5, EPOCH: 37, valid_loss: 0.018060698898302183\n",
      "FOLD: 5, EPOCH: 38, train_loss: 0.019915372866295997\n",
      "FOLD: 5, EPOCH: 38, valid_loss: 0.017945336798826855\n",
      "FOLD: 5, EPOCH: 39, train_loss: 0.0197230976074934\n",
      "FOLD: 5, EPOCH: 39, valid_loss: 0.017993472050875425\n",
      "FOLD: 5, EPOCH: 40, train_loss: 0.019678946680599642\n",
      "FOLD: 5, EPOCH: 40, valid_loss: 0.017934929786456957\n",
      "FOLD: 5, EPOCH: 41, train_loss: 0.01954425546911455\n",
      "FOLD: 5, EPOCH: 41, valid_loss: 0.018035043341418106\n",
      "FOLD: 5, EPOCH: 42, train_loss: 0.01940332397578224\n",
      "FOLD: 5, EPOCH: 42, valid_loss: 0.017797270841482613\n",
      "FOLD: 5, EPOCH: 43, train_loss: 0.01923020977166391\n",
      "FOLD: 5, EPOCH: 43, valid_loss: 0.01798763136482901\n",
      "FOLD: 5, EPOCH: 44, train_loss: 0.019092265444417153\n",
      "FOLD: 5, EPOCH: 44, valid_loss: 0.017862702409426372\n",
      "FOLD: 5, EPOCH: 45, train_loss: 0.018981452875079647\n",
      "FOLD: 5, EPOCH: 45, valid_loss: 0.018161332752141688\n",
      "FOLD: 5, EPOCH: 46, train_loss: 0.018898611876272387\n",
      "FOLD: 5, EPOCH: 46, valid_loss: 0.01789002637896273\n",
      "FOLD: 5, EPOCH: 47, train_loss: 0.018672493682993997\n",
      "FOLD: 5, EPOCH: 47, valid_loss: 0.01780399799139963\n",
      "FOLD: 5, EPOCH: 48, train_loss: 0.018525368383815213\n",
      "FOLD: 5, EPOCH: 48, valid_loss: 0.017827125110973913\n",
      "FOLD: 5, EPOCH: 49, train_loss: 0.018347624328828627\n",
      "FOLD: 5, EPOCH: 49, valid_loss: 0.017743501760479476\n",
      "FOLD: 5, EPOCH: 50, train_loss: 0.018142357576758632\n",
      "FOLD: 5, EPOCH: 50, valid_loss: 0.01787035446614027\n",
      "FOLD: 5, EPOCH: 51, train_loss: 0.01797806944457754\n",
      "FOLD: 5, EPOCH: 51, valid_loss: 0.01780843734741211\n",
      "FOLD: 5, EPOCH: 52, train_loss: 0.017787598974762425\n",
      "FOLD: 5, EPOCH: 52, valid_loss: 0.017811300750407908\n",
      "FOLD: 5, EPOCH: 53, train_loss: 0.017644418061019913\n",
      "FOLD: 5, EPOCH: 53, valid_loss: 0.01781277922499511\n",
      "FOLD: 5, EPOCH: 54, train_loss: 0.017511346377432346\n",
      "FOLD: 5, EPOCH: 54, valid_loss: 0.01780527990518345\n",
      "FOLD: 5, EPOCH: 55, train_loss: 0.017348030047310937\n",
      "FOLD: 5, EPOCH: 55, valid_loss: 0.017802646642343864\n",
      "FOLD: 5, EPOCH: 56, train_loss: 0.017244777293695557\n",
      "FOLD: 5, EPOCH: 56, valid_loss: 0.01785104385473662\n",
      "FOLD: 5, EPOCH: 57, train_loss: 0.017211909471980986\n",
      "FOLD: 5, EPOCH: 57, valid_loss: 0.017836979331655636\n",
      "FOLD: 5, EPOCH: 58, train_loss: 0.017130843255548707\n",
      "FOLD: 5, EPOCH: 58, valid_loss: 0.01782485671962301\n",
      "FOLD: 5, EPOCH: 59, train_loss: 0.017152981760521088\n",
      "FOLD: 5, EPOCH: 59, valid_loss: 0.01781918594820632\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.67558729706272\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.35461244863622327\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.06006807932449925\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.02093913373263443\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.02303603906785288\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.020367271759930777\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.022684194135569758\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.020625313524814212\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.021255399755412532\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.019192064290537554\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.020981252830355398\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.018721961580655155\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.02113166266391354\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.018849535790436408\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.020469491255860176\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.01871422875453444\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.02036676956040244\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.018711372004712328\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.020349482194550576\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.018719875308520654\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.020362253979809824\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.01888694318340105\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.020483167421433232\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.018632367910707697\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.02049642691929494\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.018797221867477194\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.020563526824116708\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.018962468842373174\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.020598185675278786\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.019107092062340063\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.02064391054934071\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.01874580935520284\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.02070208641309892\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.01913264864946113\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.02068821911609942\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.01896324545583304\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.020740631535168617\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.018840765470967573\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.02070297168627862\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.01864324071828057\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.02085495616399473\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.01898002580684774\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.020797031252614912\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.0189039881395943\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.020818518126203167\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.018807705382213873\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.020770908964257085\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.0188822054906803\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.02077457779838193\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.019032894140657258\n",
      "FOLD: 6, EPOCH: 25, train_loss: 0.020745954181878797\n",
      "FOLD: 6, EPOCH: 25, valid_loss: 0.01908620841362897\n",
      "FOLD: 6, EPOCH: 26, train_loss: 0.020768504938290966\n",
      "FOLD: 6, EPOCH: 26, valid_loss: 0.018914632499217987\n",
      "FOLD: 6, EPOCH: 27, train_loss: 0.02071519471224277\n",
      "FOLD: 6, EPOCH: 27, valid_loss: 0.019013541038422024\n",
      "FOLD: 6, EPOCH: 28, train_loss: 0.02066144400065945\n",
      "FOLD: 6, EPOCH: 28, valid_loss: 0.018791965044596615\n",
      "FOLD: 6, EPOCH: 29, train_loss: 0.02061262881803897\n",
      "FOLD: 6, EPOCH: 29, valid_loss: 0.01835456085117424\n",
      "FOLD: 6, EPOCH: 30, train_loss: 0.020528340363694775\n",
      "FOLD: 6, EPOCH: 30, valid_loss: 0.018589014516157264\n",
      "FOLD: 6, EPOCH: 31, train_loss: 0.020433540137544753\n",
      "FOLD: 6, EPOCH: 31, valid_loss: 0.018762436092776412\n",
      "FOLD: 6, EPOCH: 32, train_loss: 0.020344529324962248\n",
      "FOLD: 6, EPOCH: 32, valid_loss: 0.0186321412158363\n",
      "FOLD: 6, EPOCH: 33, train_loss: 0.020306916811293173\n",
      "FOLD: 6, EPOCH: 33, valid_loss: 0.018257463186541024\n",
      "FOLD: 6, EPOCH: 34, train_loss: 0.020197496286803677\n",
      "FOLD: 6, EPOCH: 34, valid_loss: 0.0182610925506143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 6, EPOCH: 35, train_loss: 0.020064581726347248\n",
      "FOLD: 6, EPOCH: 35, valid_loss: 0.018386119976639748\n",
      "FOLD: 6, EPOCH: 36, train_loss: 0.01989614419158428\n",
      "FOLD: 6, EPOCH: 36, valid_loss: 0.018207470612490877\n",
      "FOLD: 6, EPOCH: 37, train_loss: 0.019861410389984808\n",
      "FOLD: 6, EPOCH: 37, valid_loss: 0.018443097853485274\n",
      "FOLD: 6, EPOCH: 38, train_loss: 0.01977636608625612\n",
      "FOLD: 6, EPOCH: 38, valid_loss: 0.01817048719043241\n",
      "FOLD: 6, EPOCH: 39, train_loss: 0.019615908375670833\n",
      "FOLD: 6, EPOCH: 39, valid_loss: 0.01808034579324372\n",
      "FOLD: 6, EPOCH: 40, train_loss: 0.01950929360764642\n",
      "FOLD: 6, EPOCH: 40, valid_loss: 0.01812888917458408\n",
      "FOLD: 6, EPOCH: 41, train_loss: 0.019377455812308098\n",
      "FOLD: 6, EPOCH: 41, valid_loss: 0.018161394578569075\n",
      "FOLD: 6, EPOCH: 42, train_loss: 0.01923542277466866\n",
      "FOLD: 6, EPOCH: 42, valid_loss: 0.018013137721401805\n",
      "FOLD: 6, EPOCH: 43, train_loss: 0.01912347345102218\n",
      "FOLD: 6, EPOCH: 43, valid_loss: 0.017906326910152155\n",
      "FOLD: 6, EPOCH: 44, train_loss: 0.01892851023904739\n",
      "FOLD: 6, EPOCH: 44, valid_loss: 0.017850012737600243\n",
      "FOLD: 6, EPOCH: 45, train_loss: 0.018768082979706027\n",
      "FOLD: 6, EPOCH: 45, valid_loss: 0.017880760571535897\n",
      "FOLD: 6, EPOCH: 46, train_loss: 0.018642458355715198\n",
      "FOLD: 6, EPOCH: 46, valid_loss: 0.017889183781602803\n",
      "FOLD: 6, EPOCH: 47, train_loss: 0.01851542116172852\n",
      "FOLD: 6, EPOCH: 47, valid_loss: 0.017929486327749843\n",
      "FOLD: 6, EPOCH: 48, train_loss: 0.01833040183109622\n",
      "FOLD: 6, EPOCH: 48, valid_loss: 0.017906538977780762\n",
      "FOLD: 6, EPOCH: 49, train_loss: 0.01812128301469549\n",
      "FOLD: 6, EPOCH: 49, valid_loss: 0.017815703307004535\n",
      "FOLD: 6, EPOCH: 50, train_loss: 0.017985179131069493\n",
      "FOLD: 6, EPOCH: 50, valid_loss: 0.01780520790420911\n",
      "FOLD: 6, EPOCH: 51, train_loss: 0.017812686251296152\n",
      "FOLD: 6, EPOCH: 51, valid_loss: 0.01784225120483076\n",
      "FOLD: 6, EPOCH: 52, train_loss: 0.017663842385574696\n",
      "FOLD: 6, EPOCH: 52, valid_loss: 0.017818001701551324\n",
      "FOLD: 6, EPOCH: 53, train_loss: 0.017472406530812862\n",
      "FOLD: 6, EPOCH: 53, valid_loss: 0.017779014237663326\n",
      "FOLD: 6, EPOCH: 54, train_loss: 0.017310237554052185\n",
      "FOLD: 6, EPOCH: 54, valid_loss: 0.017817934208056507\n",
      "FOLD: 6, EPOCH: 55, train_loss: 0.01721648154479842\n",
      "FOLD: 6, EPOCH: 55, valid_loss: 0.0177797736490474\n",
      "FOLD: 6, EPOCH: 56, train_loss: 0.017104007838474166\n",
      "FOLD: 6, EPOCH: 56, valid_loss: 0.017804110915783572\n",
      "FOLD: 6, EPOCH: 57, train_loss: 0.017037041293036553\n",
      "FOLD: 6, EPOCH: 57, valid_loss: 0.017779833801528987\n",
      "FOLD: 6, EPOCH: 58, train_loss: 0.017011595601516386\n",
      "FOLD: 6, EPOCH: 58, valid_loss: 0.017802767784279937\n",
      "FOLD: 6, EPOCH: 59, train_loss: 0.016974058747291566\n",
      "FOLD: 6, EPOCH: 59, valid_loss: 0.017792431254159\n",
      "FOLD: 7, EPOCH: 0, train_loss: 0.6752314465661202\n",
      "FOLD: 7, EPOCH: 0, valid_loss: 0.3557784995611976\n",
      "FOLD: 7, EPOCH: 1, train_loss: 0.06026037258486594\n",
      "FOLD: 7, EPOCH: 1, valid_loss: 0.019784651258412528\n",
      "FOLD: 7, EPOCH: 2, train_loss: 0.02285698623426499\n",
      "FOLD: 7, EPOCH: 2, valid_loss: 0.018815361730316105\n",
      "FOLD: 7, EPOCH: 3, train_loss: 0.022440605790865036\n",
      "FOLD: 7, EPOCH: 3, valid_loss: 0.02116699330508709\n",
      "FOLD: 7, EPOCH: 4, train_loss: 0.02247730361357812\n",
      "FOLD: 7, EPOCH: 4, valid_loss: 0.0179562364869258\n",
      "FOLD: 7, EPOCH: 5, train_loss: 0.02212806313989624\n",
      "FOLD: 7, EPOCH: 5, valid_loss: 0.017880627447191405\n",
      "FOLD: 7, EPOCH: 6, train_loss: 0.020683910217015974\n",
      "FOLD: 7, EPOCH: 6, valid_loss: 0.017810630447724286\n",
      "FOLD: 7, EPOCH: 7, train_loss: 0.02041108194858797\n",
      "FOLD: 7, EPOCH: 7, valid_loss: 0.017879539771991616\n",
      "FOLD: 7, EPOCH: 8, train_loss: 0.020330698499756474\n",
      "FOLD: 7, EPOCH: 8, valid_loss: 0.01794459977570702\n",
      "FOLD: 7, EPOCH: 9, train_loss: 0.02036355348123658\n",
      "FOLD: 7, EPOCH: 9, valid_loss: 0.01794800896416692\n",
      "FOLD: 7, EPOCH: 10, train_loss: 0.02045951068641678\n",
      "FOLD: 7, EPOCH: 10, valid_loss: 0.017847264842951998\n",
      "FOLD: 7, EPOCH: 11, train_loss: 0.020474105220167866\n",
      "FOLD: 7, EPOCH: 11, valid_loss: 0.018053646911593044\n",
      "FOLD: 7, EPOCH: 12, train_loss: 0.020498488506963175\n",
      "FOLD: 7, EPOCH: 12, valid_loss: 0.01798862317467437\n",
      "FOLD: 7, EPOCH: 13, train_loss: 0.020618968324795844\n",
      "FOLD: 7, EPOCH: 13, valid_loss: 0.01790724804296213\n",
      "FOLD: 7, EPOCH: 14, train_loss: 0.020598880225612272\n",
      "FOLD: 7, EPOCH: 14, valid_loss: 0.018169635797248167\n",
      "FOLD: 7, EPOCH: 15, train_loss: 0.0207629686521907\n",
      "FOLD: 7, EPOCH: 15, valid_loss: 0.018458377241211778\n",
      "FOLD: 7, EPOCH: 16, train_loss: 0.020774493186223892\n",
      "FOLD: 7, EPOCH: 16, valid_loss: 0.018233537016546026\n",
      "FOLD: 7, EPOCH: 17, train_loss: 0.02078412544102438\n",
      "FOLD: 7, EPOCH: 17, valid_loss: 0.018438489669386077\n",
      "FOLD: 7, EPOCH: 18, train_loss: 0.020783564544493153\n",
      "FOLD: 7, EPOCH: 18, valid_loss: 0.01838973635698066\n",
      "FOLD: 7, EPOCH: 19, train_loss: 0.020916656188426478\n",
      "FOLD: 7, EPOCH: 19, valid_loss: 0.01795942018575528\n",
      "FOLD: 7, EPOCH: 20, train_loss: 0.02081171345085867\n",
      "FOLD: 7, EPOCH: 20, valid_loss: 0.018017412108533522\n",
      "FOLD: 7, EPOCH: 21, train_loss: 0.020898917053015\n",
      "FOLD: 7, EPOCH: 21, valid_loss: 0.017790876548079884\n",
      "FOLD: 7, EPOCH: 22, train_loss: 0.020811947314969954\n",
      "FOLD: 7, EPOCH: 22, valid_loss: 0.018017816740800354\n",
      "FOLD: 7, EPOCH: 23, train_loss: 0.02089857632114041\n",
      "FOLD: 7, EPOCH: 23, valid_loss: 0.01817153799621498\n",
      "FOLD: 7, EPOCH: 24, train_loss: 0.02085529712419356\n",
      "FOLD: 7, EPOCH: 24, valid_loss: 0.018009256681098658\n",
      "FOLD: 7, EPOCH: 25, train_loss: 0.020812839558047632\n",
      "FOLD: 7, EPOCH: 25, valid_loss: 0.01802819945356425\n",
      "FOLD: 7, EPOCH: 26, train_loss: 0.020818119784516673\n",
      "FOLD: 7, EPOCH: 26, valid_loss: 0.01818343558732201\n",
      "FOLD: 7, EPOCH: 27, train_loss: 0.020731576664313193\n",
      "FOLD: 7, EPOCH: 27, valid_loss: 0.01804707254118779\n",
      "FOLD: 7, EPOCH: 28, train_loss: 0.020697355282402807\n",
      "FOLD: 7, EPOCH: 28, valid_loss: 0.017986270763418254\n",
      "FOLD: 7, EPOCH: 29, train_loss: 0.020635575152212572\n",
      "FOLD: 7, EPOCH: 29, valid_loss: 0.017849403707420126\n",
      "FOLD: 7, EPOCH: 30, train_loss: 0.020563994552339277\n",
      "FOLD: 7, EPOCH: 30, valid_loss: 0.018013361293603394\n",
      "FOLD: 7, EPOCH: 31, train_loss: 0.02056191675364971\n",
      "FOLD: 7, EPOCH: 31, valid_loss: 0.017738385399913088\n",
      "FOLD: 7, EPOCH: 32, train_loss: 0.020469923173227617\n",
      "FOLD: 7, EPOCH: 32, valid_loss: 0.01775987698313068\n",
      "FOLD: 7, EPOCH: 33, train_loss: 0.02035866802738559\n",
      "FOLD: 7, EPOCH: 33, valid_loss: 0.01765316938433577\n",
      "FOLD: 7, EPOCH: 34, train_loss: 0.020276325616625047\n",
      "FOLD: 7, EPOCH: 34, valid_loss: 0.01771878998945741\n",
      "FOLD: 7, EPOCH: 35, train_loss: 0.020148345347373715\n",
      "FOLD: 7, EPOCH: 35, valid_loss: 0.017553175196928138\n",
      "FOLD: 7, EPOCH: 36, train_loss: 0.01998720482712792\n",
      "FOLD: 7, EPOCH: 36, valid_loss: 0.01761549524962902\n",
      "FOLD: 7, EPOCH: 37, train_loss: 0.019934158303564594\n",
      "FOLD: 7, EPOCH: 37, valid_loss: 0.01744486057363889\n",
      "FOLD: 7, EPOCH: 38, train_loss: 0.019810758170581633\n",
      "FOLD: 7, EPOCH: 38, valid_loss: 0.017387367401491192\n",
      "FOLD: 7, EPOCH: 39, train_loss: 0.0197274521594086\n",
      "FOLD: 7, EPOCH: 39, valid_loss: 0.01756532468339976\n",
      "FOLD: 7, EPOCH: 40, train_loss: 0.019604506812268687\n",
      "FOLD: 7, EPOCH: 40, valid_loss: 0.01727789530859274\n",
      "FOLD: 7, EPOCH: 41, train_loss: 0.019491130534198976\n",
      "FOLD: 7, EPOCH: 41, valid_loss: 0.017370708505896962\n",
      "FOLD: 7, EPOCH: 42, train_loss: 0.019346104958845724\n",
      "FOLD: 7, EPOCH: 42, valid_loss: 0.01714752461103832\n",
      "FOLD: 7, EPOCH: 43, train_loss: 0.019213327657311194\n",
      "FOLD: 7, EPOCH: 43, valid_loss: 0.017335409079404437\n",
      "FOLD: 7, EPOCH: 44, train_loss: 0.019106857983335373\n",
      "FOLD: 7, EPOCH: 44, valid_loss: 0.017231835600207832\n",
      "FOLD: 7, EPOCH: 45, train_loss: 0.018921197422089114\n",
      "FOLD: 7, EPOCH: 45, valid_loss: 0.01725733099395738\n",
      "FOLD: 7, EPOCH: 46, train_loss: 0.01873579069731697\n",
      "FOLD: 7, EPOCH: 46, valid_loss: 0.017202036838759396\n",
      "FOLD: 7, EPOCH: 47, train_loss: 0.0186050814666575\n",
      "FOLD: 7, EPOCH: 47, valid_loss: 0.0172204972956987\n",
      "FOLD: 7, EPOCH: 48, train_loss: 0.01841052587955229\n",
      "FOLD: 7, EPOCH: 48, valid_loss: 0.017136247445117023\n",
      "FOLD: 7, EPOCH: 49, train_loss: 0.018238739308811005\n",
      "FOLD: 7, EPOCH: 49, valid_loss: 0.017145204960423356\n",
      "FOLD: 7, EPOCH: 50, train_loss: 0.018064539104459747\n",
      "FOLD: 7, EPOCH: 50, valid_loss: 0.017138543757883942\n",
      "FOLD: 7, EPOCH: 51, train_loss: 0.01789621088293291\n",
      "FOLD: 7, EPOCH: 51, valid_loss: 0.017102425315362567\n",
      "FOLD: 7, EPOCH: 52, train_loss: 0.017787070716581036\n",
      "FOLD: 7, EPOCH: 52, valid_loss: 0.01710611998158343\n",
      "FOLD: 7, EPOCH: 53, train_loss: 0.017580192067450092\n",
      "FOLD: 7, EPOCH: 53, valid_loss: 0.017121673178146866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 7, EPOCH: 54, train_loss: 0.017473405942080484\n",
      "FOLD: 7, EPOCH: 54, valid_loss: 0.017113897730322444\n",
      "FOLD: 7, EPOCH: 55, train_loss: 0.017310734922366757\n",
      "FOLD: 7, EPOCH: 55, valid_loss: 0.01709349869805224\n",
      "FOLD: 7, EPOCH: 56, train_loss: 0.01723312897187087\n",
      "FOLD: 7, EPOCH: 56, valid_loss: 0.017097363631953213\n",
      "FOLD: 7, EPOCH: 57, train_loss: 0.017152420233093924\n",
      "FOLD: 7, EPOCH: 57, valid_loss: 0.017105504213010565\n",
      "FOLD: 7, EPOCH: 58, train_loss: 0.017107765809182197\n",
      "FOLD: 7, EPOCH: 58, valid_loss: 0.017111860489582315\n",
      "FOLD: 7, EPOCH: 59, train_loss: 0.01711736175441934\n",
      "FOLD: 7, EPOCH: 59, valid_loss: 0.017120561014641735\n",
      "FOLD: 8, EPOCH: 0, train_loss: 0.6758094708765706\n",
      "FOLD: 8, EPOCH: 0, valid_loss: 0.3549552410840988\n",
      "FOLD: 8, EPOCH: 1, train_loss: 0.06033824683437424\n",
      "FOLD: 8, EPOCH: 1, valid_loss: 0.01983783430316382\n",
      "FOLD: 8, EPOCH: 2, train_loss: 0.02318322795533365\n",
      "FOLD: 8, EPOCH: 2, valid_loss: 0.01886819965309567\n",
      "FOLD: 8, EPOCH: 3, train_loss: 0.022247767135981592\n",
      "FOLD: 8, EPOCH: 3, valid_loss: 0.018169572266439598\n",
      "FOLD: 8, EPOCH: 4, train_loss: 0.023362005105422388\n",
      "FOLD: 8, EPOCH: 4, valid_loss: 0.017737913462850783\n",
      "FOLD: 8, EPOCH: 5, train_loss: 0.021955613912113252\n",
      "FOLD: 8, EPOCH: 5, valid_loss: 0.017975400150236156\n",
      "FOLD: 8, EPOCH: 6, train_loss: 0.020954964646408634\n",
      "FOLD: 8, EPOCH: 6, valid_loss: 0.018134581959909864\n",
      "FOLD: 8, EPOCH: 7, train_loss: 0.020676511694346703\n",
      "FOLD: 8, EPOCH: 7, valid_loss: 0.017863864441298775\n",
      "FOLD: 8, EPOCH: 8, train_loss: 0.020526753173720453\n",
      "FOLD: 8, EPOCH: 8, valid_loss: 0.017983346039222345\n",
      "FOLD: 8, EPOCH: 9, train_loss: 0.020556420003694873\n",
      "FOLD: 8, EPOCH: 9, valid_loss: 0.017899369562251702\n",
      "FOLD: 8, EPOCH: 10, train_loss: 0.02057749734770867\n",
      "FOLD: 8, EPOCH: 10, valid_loss: 0.017936457103739183\n",
      "FOLD: 8, EPOCH: 11, train_loss: 0.02060727993807485\n",
      "FOLD: 8, EPOCH: 11, valid_loss: 0.017990544645322695\n",
      "FOLD: 8, EPOCH: 12, train_loss: 0.020629353508833916\n",
      "FOLD: 8, EPOCH: 12, valid_loss: 0.0179109419696033\n",
      "FOLD: 8, EPOCH: 13, train_loss: 0.02061458314138074\n",
      "FOLD: 8, EPOCH: 13, valid_loss: 0.0176943634222779\n",
      "FOLD: 8, EPOCH: 14, train_loss: 0.02070163590533118\n",
      "FOLD: 8, EPOCH: 14, valid_loss: 0.01779245864599943\n",
      "FOLD: 8, EPOCH: 15, train_loss: 0.020712915603672305\n",
      "FOLD: 8, EPOCH: 15, valid_loss: 0.01811809242806501\n",
      "FOLD: 8, EPOCH: 16, train_loss: 0.02075285602721476\n",
      "FOLD: 8, EPOCH: 16, valid_loss: 0.0181155681817068\n",
      "FOLD: 8, EPOCH: 17, train_loss: 0.020805117632112194\n",
      "FOLD: 8, EPOCH: 17, valid_loss: 0.018853301285869546\n",
      "FOLD: 8, EPOCH: 18, train_loss: 0.02088696187542331\n",
      "FOLD: 8, EPOCH: 18, valid_loss: 0.017906871831251517\n",
      "FOLD: 8, EPOCH: 19, train_loss: 0.020785949727700603\n",
      "FOLD: 8, EPOCH: 19, valid_loss: 0.017653184322019417\n",
      "FOLD: 8, EPOCH: 20, train_loss: 0.0208701518514464\n",
      "FOLD: 8, EPOCH: 20, valid_loss: 0.017849927198969655\n",
      "FOLD: 8, EPOCH: 21, train_loss: 0.020845741321963648\n",
      "FOLD: 8, EPOCH: 21, valid_loss: 0.017976902994430728\n",
      "FOLD: 8, EPOCH: 22, train_loss: 0.02090952301458005\n",
      "FOLD: 8, EPOCH: 22, valid_loss: 0.018099277642452054\n",
      "FOLD: 8, EPOCH: 23, train_loss: 0.020799496938144008\n",
      "FOLD: 8, EPOCH: 23, valid_loss: 0.018089244918276865\n",
      "FOLD: 8, EPOCH: 24, train_loss: 0.020780830409738327\n",
      "FOLD: 8, EPOCH: 24, valid_loss: 0.018331959791895416\n",
      "FOLD: 8, EPOCH: 25, train_loss: 0.020891663251865294\n",
      "FOLD: 8, EPOCH: 25, valid_loss: 0.017803365209450323\n",
      "FOLD: 8, EPOCH: 26, train_loss: 0.020817053209870092\n",
      "FOLD: 8, EPOCH: 26, valid_loss: 0.017816196144041088\n",
      "FOLD: 8, EPOCH: 27, train_loss: 0.02076850396490866\n",
      "FOLD: 8, EPOCH: 27, valid_loss: 0.018199067666298814\n",
      "FOLD: 8, EPOCH: 28, train_loss: 0.02075709063679941\n",
      "FOLD: 8, EPOCH: 28, valid_loss: 0.017642088182684448\n",
      "FOLD: 8, EPOCH: 29, train_loss: 0.020599295427241635\n",
      "FOLD: 8, EPOCH: 29, valid_loss: 0.018191002412802644\n",
      "FOLD: 8, EPOCH: 30, train_loss: 0.020585010236790102\n",
      "FOLD: 8, EPOCH: 30, valid_loss: 0.017940292755762737\n",
      "FOLD: 8, EPOCH: 31, train_loss: 0.020486166051799252\n",
      "FOLD: 8, EPOCH: 31, valid_loss: 0.017647873299817245\n",
      "FOLD: 8, EPOCH: 32, train_loss: 0.020432951866138367\n",
      "FOLD: 8, EPOCH: 32, valid_loss: 0.017772141533593338\n",
      "FOLD: 8, EPOCH: 33, train_loss: 0.020332444699541215\n",
      "FOLD: 8, EPOCH: 33, valid_loss: 0.017546141985803843\n",
      "FOLD: 8, EPOCH: 34, train_loss: 0.020295422728503903\n",
      "FOLD: 8, EPOCH: 34, valid_loss: 0.017509721943901643\n",
      "FOLD: 8, EPOCH: 35, train_loss: 0.020152279169809433\n",
      "FOLD: 8, EPOCH: 35, valid_loss: 0.017366679437044594\n",
      "FOLD: 8, EPOCH: 36, train_loss: 0.02003975418065825\n",
      "FOLD: 8, EPOCH: 36, valid_loss: 0.01734867293594612\n",
      "FOLD: 8, EPOCH: 37, train_loss: 0.019938738379747637\n",
      "FOLD: 8, EPOCH: 37, valid_loss: 0.01756033461747898\n",
      "FOLD: 8, EPOCH: 38, train_loss: 0.0198356872003886\n",
      "FOLD: 8, EPOCH: 38, valid_loss: 0.0171938249323931\n",
      "FOLD: 8, EPOCH: 39, train_loss: 0.019705309238164655\n",
      "FOLD: 8, EPOCH: 39, valid_loss: 0.0171930810643567\n",
      "FOLD: 8, EPOCH: 40, train_loss: 0.019570772349834443\n",
      "FOLD: 8, EPOCH: 40, valid_loss: 0.01722852306233512\n",
      "FOLD: 8, EPOCH: 41, train_loss: 0.01954688540389461\n",
      "FOLD: 8, EPOCH: 41, valid_loss: 0.017264427668932412\n",
      "FOLD: 8, EPOCH: 42, train_loss: 0.019343589811075118\n",
      "FOLD: 8, EPOCH: 42, valid_loss: 0.017097437754273415\n",
      "FOLD: 8, EPOCH: 43, train_loss: 0.019207206746983913\n",
      "FOLD: 8, EPOCH: 43, valid_loss: 0.017307609785348177\n",
      "FOLD: 8, EPOCH: 44, train_loss: 0.019039111896868674\n",
      "FOLD: 8, EPOCH: 44, valid_loss: 0.01719625677085585\n",
      "FOLD: 8, EPOCH: 45, train_loss: 0.019003264251495563\n",
      "FOLD: 8, EPOCH: 45, valid_loss: 0.017068355499456327\n",
      "FOLD: 8, EPOCH: 46, train_loss: 0.018770667838473473\n",
      "FOLD: 8, EPOCH: 46, valid_loss: 0.017091099379791155\n",
      "FOLD: 8, EPOCH: 47, train_loss: 0.018582937728253104\n",
      "FOLD: 8, EPOCH: 47, valid_loss: 0.017096566760705575\n",
      "FOLD: 8, EPOCH: 48, train_loss: 0.01846103007274289\n",
      "FOLD: 8, EPOCH: 48, valid_loss: 0.017170070877505675\n",
      "FOLD: 8, EPOCH: 49, train_loss: 0.018323463982632085\n",
      "FOLD: 8, EPOCH: 49, valid_loss: 0.017129397640625637\n",
      "FOLD: 8, EPOCH: 50, train_loss: 0.018167528329837708\n",
      "FOLD: 8, EPOCH: 50, valid_loss: 0.017038363135523267\n",
      "FOLD: 8, EPOCH: 51, train_loss: 0.01791586689050159\n",
      "FOLD: 8, EPOCH: 51, valid_loss: 0.017001333594736125\n",
      "FOLD: 8, EPOCH: 52, train_loss: 0.01777101889132492\n",
      "FOLD: 8, EPOCH: 52, valid_loss: 0.017098190418134134\n",
      "FOLD: 8, EPOCH: 53, train_loss: 0.017643182694671616\n",
      "FOLD: 8, EPOCH: 53, valid_loss: 0.017033356034921274\n",
      "FOLD: 8, EPOCH: 54, train_loss: 0.01747453661575433\n",
      "FOLD: 8, EPOCH: 54, valid_loss: 0.017035460099577904\n",
      "FOLD: 8, EPOCH: 55, train_loss: 0.017367203281291068\n",
      "FOLD: 8, EPOCH: 55, valid_loss: 0.017018349582536355\n",
      "FOLD: 8, EPOCH: 56, train_loss: 0.0172701949193593\n",
      "FOLD: 8, EPOCH: 56, valid_loss: 0.01706231463079651\n",
      "FOLD: 8, EPOCH: 57, train_loss: 0.01717834946729483\n",
      "FOLD: 8, EPOCH: 57, valid_loss: 0.017023644047892757\n",
      "FOLD: 8, EPOCH: 58, train_loss: 0.017101364300375985\n",
      "FOLD: 8, EPOCH: 58, valid_loss: 0.01706940530695849\n",
      "FOLD: 8, EPOCH: 59, train_loss: 0.017134670510647758\n",
      "FOLD: 8, EPOCH: 59, valid_loss: 0.017041252615551155\n",
      "FOLD: 9, EPOCH: 0, train_loss: 0.6755765091988348\n",
      "FOLD: 9, EPOCH: 0, valid_loss: 0.36500103771686554\n",
      "FOLD: 9, EPOCH: 1, train_loss: 0.06208799730145162\n",
      "FOLD: 9, EPOCH: 1, valid_loss: 0.019804189395573404\n",
      "FOLD: 9, EPOCH: 2, train_loss: 0.023652146516307707\n",
      "FOLD: 9, EPOCH: 2, valid_loss: 0.022741675687332947\n",
      "FOLD: 9, EPOCH: 3, train_loss: 0.02341481031429383\n",
      "FOLD: 9, EPOCH: 3, valid_loss: 0.04069346386111445\n",
      "FOLD: 9, EPOCH: 4, train_loss: 0.027504042391815493\n",
      "FOLD: 9, EPOCH: 4, valid_loss: 0.019433684647083282\n",
      "FOLD: 9, EPOCH: 5, train_loss: 0.022715706432298307\n",
      "FOLD: 9, EPOCH: 5, valid_loss: 0.01856231792933411\n",
      "FOLD: 9, EPOCH: 6, train_loss: 0.02139979242797821\n",
      "FOLD: 9, EPOCH: 6, valid_loss: 0.01851996996750434\n",
      "FOLD: 9, EPOCH: 7, train_loss: 0.02126563322399893\n",
      "FOLD: 9, EPOCH: 7, valid_loss: 0.019520242388049763\n",
      "FOLD: 9, EPOCH: 8, train_loss: 0.02131038249259995\n",
      "FOLD: 9, EPOCH: 8, valid_loss: 0.019934488460421562\n",
      "FOLD: 9, EPOCH: 9, train_loss: 0.021016986127341947\n",
      "FOLD: 9, EPOCH: 9, valid_loss: 0.0179312816924519\n",
      "FOLD: 9, EPOCH: 10, train_loss: 0.020930236758243653\n",
      "FOLD: 9, EPOCH: 10, valid_loss: 0.021407385563684836\n",
      "FOLD: 9, EPOCH: 11, train_loss: 0.020995094506971297\n",
      "FOLD: 9, EPOCH: 11, valid_loss: 0.017764756456017494\n",
      "FOLD: 9, EPOCH: 12, train_loss: 0.020687008564991335\n",
      "FOLD: 9, EPOCH: 12, valid_loss: 0.019823638618820243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 9, EPOCH: 13, train_loss: 0.020675271172677315\n",
      "FOLD: 9, EPOCH: 13, valid_loss: 0.01786959802524911\n",
      "FOLD: 9, EPOCH: 14, train_loss: 0.020669905769248164\n",
      "FOLD: 9, EPOCH: 14, valid_loss: 0.01859853251112832\n",
      "FOLD: 9, EPOCH: 15, train_loss: 0.020673594671872353\n",
      "FOLD: 9, EPOCH: 15, valid_loss: 0.017988905724551942\n",
      "FOLD: 9, EPOCH: 16, train_loss: 0.021014503293460416\n",
      "FOLD: 9, EPOCH: 16, valid_loss: 0.022399566343261137\n",
      "FOLD: 9, EPOCH: 17, train_loss: 0.021344929536984813\n",
      "FOLD: 9, EPOCH: 17, valid_loss: 0.019270812678668234\n",
      "FOLD: 9, EPOCH: 18, train_loss: 0.021560025888104593\n",
      "FOLD: 9, EPOCH: 18, valid_loss: 0.019824980965091124\n",
      "FOLD: 9, EPOCH: 19, train_loss: 0.021505530022325053\n",
      "FOLD: 9, EPOCH: 19, valid_loss: 0.020638613340755303\n",
      "FOLD: 9, EPOCH: 20, train_loss: 0.0212573014800587\n",
      "FOLD: 9, EPOCH: 20, valid_loss: 0.019517432070440717\n",
      "FOLD: 9, EPOCH: 21, train_loss: 0.021321231643519095\n",
      "FOLD: 9, EPOCH: 21, valid_loss: 0.018134994225369558\n",
      "FOLD: 9, EPOCH: 22, train_loss: 0.02098258642419692\n",
      "FOLD: 9, EPOCH: 22, valid_loss: 0.0176914447090692\n",
      "FOLD: 9, EPOCH: 23, train_loss: 0.020835883014144435\n",
      "FOLD: 9, EPOCH: 23, valid_loss: 0.019117272976371977\n",
      "FOLD: 9, EPOCH: 24, train_loss: 0.020827927539545682\n",
      "FOLD: 9, EPOCH: 24, valid_loss: 0.017488357921441395\n",
      "FOLD: 9, EPOCH: 25, train_loss: 0.020802150979157417\n",
      "FOLD: 9, EPOCH: 25, valid_loss: 0.017880029665927093\n",
      "FOLD: 9, EPOCH: 26, train_loss: 0.020840130001306533\n",
      "FOLD: 9, EPOCH: 26, valid_loss: 0.018249638482100435\n",
      "FOLD: 9, EPOCH: 27, train_loss: 0.020827229200832305\n",
      "FOLD: 9, EPOCH: 27, valid_loss: 0.017154548627634842\n",
      "FOLD: 9, EPOCH: 28, train_loss: 0.02069549228875868\n",
      "FOLD: 9, EPOCH: 28, valid_loss: 0.017370079540544085\n",
      "FOLD: 9, EPOCH: 29, train_loss: 0.020670425639517844\n",
      "FOLD: 9, EPOCH: 29, valid_loss: 0.017548229752315417\n",
      "FOLD: 9, EPOCH: 30, train_loss: 0.02072292830674879\n",
      "FOLD: 9, EPOCH: 30, valid_loss: 0.01737742115639978\n",
      "FOLD: 9, EPOCH: 31, train_loss: 0.020778512209653856\n",
      "FOLD: 9, EPOCH: 31, valid_loss: 0.01758658606559038\n",
      "FOLD: 9, EPOCH: 32, train_loss: 0.020706432925597314\n",
      "FOLD: 9, EPOCH: 32, valid_loss: 0.017370765407880146\n",
      "FOLD: 9, EPOCH: 33, train_loss: 0.020643820036803522\n",
      "FOLD: 9, EPOCH: 33, valid_loss: 0.01733866985887289\n",
      "FOLD: 9, EPOCH: 34, train_loss: 0.020351550896321572\n",
      "FOLD: 9, EPOCH: 34, valid_loss: 0.01722464689777957\n",
      "FOLD: 9, EPOCH: 35, train_loss: 0.02035967110385818\n",
      "FOLD: 9, EPOCH: 35, valid_loss: 0.01721038053640061\n",
      "FOLD: 9, EPOCH: 36, train_loss: 0.020221205848839977\n",
      "FOLD: 9, EPOCH: 36, valid_loss: 0.01685340226524406\n",
      "FOLD: 9, EPOCH: 37, train_loss: 0.020070445285208762\n",
      "FOLD: 9, EPOCH: 37, valid_loss: 0.016976478406124644\n",
      "FOLD: 9, EPOCH: 38, train_loss: 0.01991832941289871\n",
      "FOLD: 9, EPOCH: 38, valid_loss: 0.01699717974083291\n",
      "FOLD: 9, EPOCH: 39, train_loss: 0.019880264084185324\n",
      "FOLD: 9, EPOCH: 39, valid_loss: 0.016936717917107873\n",
      "FOLD: 9, EPOCH: 40, train_loss: 0.019685754985097916\n",
      "FOLD: 9, EPOCH: 40, valid_loss: 0.016872559311903186\n",
      "FOLD: 9, EPOCH: 41, train_loss: 0.019728576644293724\n",
      "FOLD: 9, EPOCH: 41, valid_loss: 0.016820452486475308\n",
      "FOLD: 9, EPOCH: 42, train_loss: 0.019581919199516698\n",
      "FOLD: 9, EPOCH: 42, valid_loss: 0.016765585272676416\n",
      "FOLD: 9, EPOCH: 43, train_loss: 0.019356452349212863\n",
      "FOLD: 9, EPOCH: 43, valid_loss: 0.016770305681145854\n",
      "FOLD: 9, EPOCH: 44, train_loss: 0.01921108630636046\n",
      "FOLD: 9, EPOCH: 44, valid_loss: 0.016754822702043586\n",
      "FOLD: 9, EPOCH: 45, train_loss: 0.019124215769190944\n",
      "FOLD: 9, EPOCH: 45, valid_loss: 0.016744485228425927\n",
      "FOLD: 9, EPOCH: 46, train_loss: 0.01900659660177846\n",
      "FOLD: 9, EPOCH: 46, valid_loss: 0.016744875969986122\n",
      "FOLD: 9, EPOCH: 47, train_loss: 0.018989025428891183\n",
      "FOLD: 9, EPOCH: 47, valid_loss: 0.016714979118357103\n",
      "FOLD: 9, EPOCH: 48, train_loss: 0.018892971714658122\n",
      "FOLD: 9, EPOCH: 48, valid_loss: 0.016706814679006737\n",
      "FOLD: 9, EPOCH: 49, train_loss: 0.018582651499778995\n",
      "FOLD: 9, EPOCH: 49, valid_loss: 0.016743781459000375\n",
      "FOLD: 9, EPOCH: 50, train_loss: 0.018429727437755755\n",
      "FOLD: 9, EPOCH: 50, valid_loss: 0.016656035660869546\n",
      "FOLD: 9, EPOCH: 51, train_loss: 0.01821788277837538\n",
      "FOLD: 9, EPOCH: 51, valid_loss: 0.016607158869091008\n",
      "FOLD: 9, EPOCH: 52, train_loss: 0.018197163747202965\n",
      "FOLD: 9, EPOCH: 52, valid_loss: 0.016661425535049703\n",
      "FOLD: 9, EPOCH: 53, train_loss: 0.017998428702835113\n",
      "FOLD: 9, EPOCH: 53, valid_loss: 0.016658312796304624\n",
      "FOLD: 9, EPOCH: 54, train_loss: 0.01782955533914989\n",
      "FOLD: 9, EPOCH: 54, valid_loss: 0.0166794311048256\n",
      "FOLD: 9, EPOCH: 55, train_loss: 0.017712832752975725\n",
      "FOLD: 9, EPOCH: 55, valid_loss: 0.016650492894566722\n",
      "FOLD: 9, EPOCH: 56, train_loss: 0.01750884029353338\n",
      "FOLD: 9, EPOCH: 56, valid_loss: 0.016668745316565037\n",
      "FOLD: 9, EPOCH: 57, train_loss: 0.01752663293793317\n",
      "FOLD: 9, EPOCH: 57, valid_loss: 0.01673998926869697\n",
      "FOLD: 9, EPOCH: 58, train_loss: 0.01745905490411866\n",
      "FOLD: 9, EPOCH: 58, valid_loss: 0.016646821258796587\n",
      "FOLD: 9, EPOCH: 59, train_loss: 0.01736898928760521\n",
      "FOLD: 9, EPOCH: 59, valid_loss: 0.016655014000005193\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\\n       'acat_inhibitor', 'acetylcholine_receptor_agonist',\\n       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\\n       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\\n       'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist',\\n       ...\\n       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\\n       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\\n       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\\n       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\\n      dtype='object', length=206)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-78e5ec42192e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2933\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2934\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2935\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2964\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2965\u001b[0m                 indexer = self.loc._get_listlike_indexer(\n\u001b[1;32m-> 2966\u001b[1;33m                     \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2967\u001b[0m                 )[1]\n\u001b[0;32m   2968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\\n       'acat_inhibitor', 'acetylcholine_receptor_agonist',\\n       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\\n       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\\n       'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist',\\n       ...\\n       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\\n       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\\n       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\\n       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\\n      dtype='object', length=206)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "SEED = [0, 1, 2, 3, 4, 5]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.load('moa_oof_01844.npy')\n",
    "pred2 = np.load('model_oof_01840.npy')\n",
    "pred3 = np.load('moa_oof_01858.npy')\n",
    "pred4 = np.load('moa_oof_xgb.npy')\n",
    "pred5 = np.load('model_newcv_oof_01835.npy')\n",
    "pred6 = np.load('moa_oof_newcv_01844.npy')\n",
    "pred7= np.load('moa_oof_newcv_01858_opt.npy')\n",
    "\n",
    "pred8 = np.load('model_newcv_oof_01835.npy')\n",
    "pred9 = np.load('moa_oof_newcv_01858_7folds.npy')\n",
    "pred10 = np.load('moa_oof_newcv_01838_7folds.npy')\n",
    "pred11 = np.load('moa_oof_newcv_01858.npy')\n",
    "pred12 = np.load('moa_oof_newcv_01858_label.npy')\n",
    "pred13 = np.load('moa_10folds.npy')\n",
    "pred14 = np.load('model_newcv_oof_01838_5folds.npy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from time import time\n",
    "# from autograd import grad\n",
    "# import autograd.numpy as np\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from scipy.optimize import minimize, fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPMP's logloss from https://www.kaggle.com/c/lish-moa/discussion/183010\n",
    "def log_loss_numpy(y_pred):\n",
    "    y_true_ravel = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = np.where(y_true_ravel == 1, - np.log(y_pred), - np.log(1 - y_pred))\n",
    "    return loss.mean()\n",
    "\n",
    "def func_numpy_metric(weights):\n",
    "    oof_blend = np.tensordot(weights, oof, axes = ((0), (0)))\n",
    "    return log_loss_numpy(oof_blend)\n",
    "\n",
    "def grad_func(weights):\n",
    "    oof_clip = np.clip(oof, 1e-15, 1 - 1e-15)\n",
    "    gradients = np.zeros(oof.shape[0])\n",
    "    for i in range(oof.shape[0]):\n",
    "        a, b, c = y_true, oof_clip[i], np.zeros((oof.shape[1], oof.shape[2]))\n",
    "        for j in range(oof.shape[0]):\n",
    "            if j != i:\n",
    "                c += weights[j] * oof_clip[j]\n",
    "        gradients[i] = -np.mean((-a*b+(b**2)*weights[i]+b*c)/((b**2)*(weights[i]**2)+2*b*c*weights[i]-b*weights[i]+(c**2)-c))\n",
    "    return gradients\n",
    "@njit(nopython=True)\n",
    "def grad_func_jit(weights):\n",
    "    oof_clip = np.minimum(1 - 1e-15, np.maximum(oof, 1e-15))\n",
    "    gradients = np.zeros(oof.shape[0])\n",
    "    for i in range(oof.shape[0]):\n",
    "        a, b, c = y_true, oof_clip[i], np.zeros((oof.shape[1], oof.shape[2]))\n",
    "        for j in range(oof.shape[0]):\n",
    "            if j != i:\n",
    "                c += weights[j] * oof_clip[j]\n",
    "        gradients[i] = -np.mean((-a*b+(b**2)*weights[i]+b*c)/((b**2)*(weights[i]**2)+2*b*c*weights[i]-b*weights[i]+(c**2)-c))\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\train_targets_scored.csv', index_col = 'sig_id').values\n",
    "\n",
    "oof_dict = {'Model 1': 'model_newcv_oof_01835.npy', \n",
    "            'Model 2': 'moa_oof_newcv_01858_label.npy', \n",
    "            'Model 3': 'model_newcv_oof_01838_5folds.npy'\n",
    "           }\n",
    "\n",
    "oof = np.zeros((len(oof_dict), train.shape[0], len(target_cols)))\n",
    "for i in range(oof.shape[0]):\n",
    "    oof[i] = np.load(list(oof_dict.values())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = target.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 CV:\t 0.017073878563896246\n",
      "Model 2 CV:\t 0.01713246054364053\n",
      "Model 3 CV:\t 0.017330495549518366\n",
      "--------------------------------------------------\n",
      "Wall time: 656 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_loss_scores = {}\n",
    "for n, key in enumerate(oof_dict.keys()):\n",
    "    score_oof = log_loss_numpy(oof[n])\n",
    "    log_loss_scores[key] = score_oof\n",
    "    print(f'{key} CV:\\t', score_oof)\n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = np.array([1 / oof.shape[0]] * oof.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27 s ± 12.4 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 10 grad_func(test_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 ms ± 5.65 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 10 grad_func_jit(test_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital Blend OOF: 0.017019816066787135\n",
      "[00:11] Optimised Blend OOF: 0.016994478723817687\n",
      "Optimised Weights: [0.52035188 0.41286638 0.06678174]\n"
     ]
    }
   ],
   "source": [
    "tol = 1e-10\n",
    "init_guess = [1 / oof.shape[0]] * oof.shape[0]\n",
    "bnds = [(0, 1) for _ in range(oof.shape[0])]\n",
    "cons = {'type': 'eq', \n",
    "        'fun': lambda x: np.sum(x) - 1, \n",
    "        'jac': lambda x: [1] * len(x)}\n",
    "\n",
    "print('Inital Blend OOF:', func_numpy_metric(init_guess))\n",
    "start_time = time()\n",
    "res_scipy = minimize(fun = func_numpy_metric, \n",
    "                     x0 = init_guess, \n",
    "                     method = 'SLSQP', \n",
    "                     jac = grad_func_jit, # grad_func \n",
    "                     bounds = bnds, \n",
    "                     constraints = cons, \n",
    "                     tol = tol)\n",
    "print(f'[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] Optimised Blend OOF:', res_scipy.fun)\n",
    "print('Optimised Weights:', res_scipy.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the sum of all weights: 1.0\n",
      "Great! The sum of all weights equals to 1!\n"
     ]
    }
   ],
   "source": [
    "print('Check the sum of all weights:', np.sum(res_scipy.x))\n",
    "if np.sum(res_scipy.x) - 1 <= tol:\n",
    "    print('Great! The sum of all weights equals to 1!')\n",
    "else:\n",
    "    print('Manual adjustion is needed to modify the weights.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[target_cols] = (pred8 * 0.45728174 + pred12 * 0.27524878 + pred1 * 0.26746948)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[target_cols] = ((pred8 * 0.45728174 + pred12 * 0.27524878 + pred1 * 0.26746948) * 5 + (pred13))/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[target_cols] = (pred8 * 5 + pred12 * 4 + pred14)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.015594240552897484\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.load('moa_01844.npy')\n",
    "pred2 = np.load('model_newcv_01835.npy')\n",
    "pred3 = np.load('moa_01844.npy')\n",
    "pred4 = np.load('model_01840.npy')\n",
    "pred5 = np.load('moa_01858.npy')\n",
    "pred6 = np.load('moa_xgb.npy')\n",
    "pred7 = np.load('moa_newcv_01844.npy')\n",
    "#np.save('moa_oof_newcv_01858',oof)\n",
    "\n",
    "pred8 = np.load('moa_newcv_01858.npy')\n",
    "\n",
    "pred9 = np.load('model_newcv_01835_7folds.npy')\n",
    "pred10 = np.load('model_newcv_01835.npy')\n",
    "pred11 = np.load('moa_newcv_01858_7folds.npy')\n",
    "pred12 = np.load('moa_newcv_01858_label.npy')\n",
    "pred13 = np.load('moa_10folds_preds_1.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in target_cols:\n",
    "    test[i]=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target_cols] = (pred10 * 0.45728174 + pred12 * 0.27524878 + pred1 * 0.26746948)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target_cols] = ((pred10 * 0.45728174 + pred12 * 0.27524878 + pred1 * 0.26746948) *5 + (pred13))/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('D:\\\\Dataset\\\\MOA\\\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission_24_11_2020_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00103485, 0.00147651, 0.00094714, ..., 0.00162948, 0.00064708,\n",
       "        0.00183387],\n",
       "       [0.00094011, 0.0006696 , 0.00304768, ..., 0.0045382 , 0.00178554,\n",
       "        0.00376633],\n",
       "       [0.00163513, 0.00370731, 0.00093928, ..., 0.00069495, 0.00061159,\n",
       "        0.00132486],\n",
       "       ...,\n",
       "       [0.00070007, 0.00109894, 0.00218864, ..., 0.00166229, 0.00682262,\n",
       "        0.00189743],\n",
       "       [0.00068031, 0.00054134, 0.00110733, ..., 0.0004013 , 0.00048773,\n",
       "        0.00112408],\n",
       "       [0.0004891 , 0.00121476, 0.00145994, ..., 0.00062922, 0.00065504,\n",
       "        0.00024006]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('moa_oof_newcv_01858_label',oof)\n",
    "np.save('moa_newcv_01858_label',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
